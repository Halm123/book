% Possible use http://www.latextemplates.com/template/the-legrand-orange-book as template? See https://www.overleaf.com/9174958nyjxxdxbchks#/33024595/

\documentclass[11pt,letterpaper,fleqn]{memoir} % Default font size and left-justified equations

\input{formatting} % Loads the book formatting

\begin{document}
	
% Set theory (expected) \in, \subset, injective/surjective, cartesian product

% Closure of a set under an operation

% Need examples of topology and sigma algebra

% Note that sigma algebra are also closed under intersections

\frontmatter
\thispagestyle{empty}

~

\vspace{20pt}

{\large \noindent Gabriele Carcassi, Christine Aidala }

\vspace{60pt}

{\Huge \noindent \textbf{Assumptions of physics}}

\vspace{30pt}

{\large \noindent Working DRAFT 0.1 - \today}

\vfill

%\chapter*{Assumptions of physics}

\noindent \textbf{This book is a work in progress}. This draft is a development copy built on \today. You can get the latest version from http://assumptionsofphysics.org/book. It is provided as-is for the purpose of early review and feedback. 

\newpage
~\vfill
\thispagestyle{empty}

% Copyright notice
\noindent Copyright \copyright\ 2018 Gabriele Carcassi, Christine Aidala

\vspace{12pt}

% Link to website
\noindent \textsc{assumptionsofphysics.org/book}

\vspace{12pt}

% License
\noindent Licensed under the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) (the ``License"). You may not use this file except in compliance with the License. You may obtain a copy of the License at https://creativecommons.org/licenses/by-nc-sa/4.0/. This work is distributed under the License ``as is'', without warranties or conditions of any kind, either express or implied.

\chapter{Preface}

The main point you should be aware before reading this work at this stage is that it is a work in progress and it will be for a few years to come. If you only want to read the definitive version, you will have to wait.

\section*{Aim}

The aim of this work is to answer the following question: what do the laws of physics represent? What do they describe? Under what conditions are they valid? The way we approach the problem is to find the minimal set of physical assumptions that are necessary and sufficient to derive them. If we are able to do so, then we know that all that the laws of physics say is encoded in those assumptions.

By doing this, we also receive a great deal of new insights into the physics, the math and the philosophy of both. We get a more precise sense why some mathematical structures are pervasive in science and we can finally understand what they are meant to represent. We clear up misconceptions. The downside is that we have to touch many subjects in math (logic, topological spaces, measure theory, group theory, vector spaces, differential geometry, symplectic geometry, statistics, probability theory, ...), physics (Hamiltonian mechanics, Lagrangian mechanics, thermodynamics, quantum mechanics, electromagnetism, ...) and science in general (computer science theory, information theory, system theory, ...).

While the topic is necessarily inter-disciplinary, this is still first and foremost a scientific book. The material should be accessible to the mathematician and philosopher, but understand that it needs to resonate first and foremost with the physicist and the engineer. The mathematical definitions and derivations are there to make the science precise, but they are not the main focus. In fact, the book is designed so that the mathematical definitions and proofs, highlighted with a green side bar, can be skipped altogether without loss of the big picture and the important details. Along the same line, the foundational discussions are there to articulate more precisely what it means to do science, so they will not indulge in other questions which may be of interest to the philosopher but not to the scientist.

\section*{Release early, release often}

While it may be unusual in academia to circulate work in such early stages, it is established practice in open source/free software communities. For this project to be successful we need to pool expertise and ideas from a wide range of disciplines, therefore it is useful for us to work as openly as possible to foster reviews and discussions from people with significantly different backgrounds and at different stages of expertise. This means the content may change, even significantly, as problems are discovered and addressed.

We understand that this way of operating is not for everybody. To those who are not interested in seeing or participating in the development of the ideas, we suggest to wait for the final edition which, however, won't come for probably a couple of years. To the others, we encourage you to get familiar with the work and style and hope we may find points of collaboration to help push it forward. 

\section*{Overview}

In broad strokes, the work will be divided into five sections, each identifying and expanding on a single idea.

\begin{itemize}
	\item The principle of scientific objectivity: ``Science is universal, non-contradictory and evidence based." From this we'll derive the basic requirement for scientific investigation that has to be present no matter what. We will have statements of fact and a way to verify their truth experimentally. Mathematically, this requirement will be captured by topologies and sigma-algebras. We will also have distributions and, in particular, statistical distributions. Mathematically, this will require our topological spaces to be differentiable, to be equipped with a canonical measure and that each distribution be a differentiable function defined on the aforementioned differentiable structure and measure.
	\item The assumption of determinism and reversibility: ``The system under study undergoes deterministic and reversible evolution." From this we'll define the idea of a state and a law of evolution. Mathematically, the physical properties of the system determine which category is used to describe the state space and deterministic and reversible evolution will be an isomorphism in the category (i.e. a bijective map that preserves the physical properties of the system).
	\item The assumption of infinitesimal reducibility: ``Knowing the state of the whole system is equivalent to knowing the state of all its infinitesimal parts." For example, we can study the motion of a cannonball, but we can also mark a spot in red and study the motion of the mark. Knowing the evolution of the whole cannonball means knowing the evolution of any arbitrary spot and vice-versa. Mathematically, the state of the whole will be a distribution over the state space of the parts. It will need to be a distribution whose value is invariant under coordinate transformations. The state space of the infinitesimal parts, then, comes equipped with an invariant two-form upon which we can define such a distribution. The state space is therefore a symplectic manifold and the deteministic and reversible evolution is a symplectomorphism. That is: the infinitesimal parts follow classical Hamiltonian mechanics. Proper handling of the time variable will give us a relativistic version of the framework without extra assumptions. 
	\item The assumption of irreducibility: ``Knowing the state of the whole system tells us nothing about its infinitesimal parts." For example, we can study the state of an electron by scattering photons off of it. But whenever a photon interacts with the electron, it interacts with the whole electron. There is no way to mark a part of an electron and study it independently from the rest. Mathematically, the state of the electron will be a distribution that evolves deterministically where the motion of each infinitesimal part evolves randomly. A complex vector space will be the appropriate tool to keep track of the internal chaotic motion leading to quantum mechanics.
	\item The assumption of kinematic equivalence: ``Knowing the state of the system is equivalent to knowing its trajectory and vice-versa." This means that we'll have to be able to transfer a distribution over state variables (i.e. position and momentum) into a distribution over kinematic variables (i.e. position and velocity). Mathematically, the symplectic two-form will induce a symmetric tensor over the tangent space for position. This will give us a metric and will also allow us to reformulate the laws of motion according to Lagrangian mechanics. Because the transformation is linear, we are able to constrain the Hamiltonian to the one for massive particles under scalar and vector potential forces.
\end{itemize}

\section*{Current plan and status}

The goal for version 0.1 is to consolidate the first two chapters of the first section. These will develop the basic framework right up to distributions. Status is as follows:

\begin{description}
	\item First chapter - stable
	\item Second chapter - beta
\end{description}


%\pagestyle{empty} % No headers

\cleardoublepage % Forces the first chapter to start on an odd page so it's on the right

\tableofcontents* % Print the table of contents itself

\cleardoublepage % Forces the first chapter to start on an odd page so it's on the right

%\pagestyle{fancy} % Print headers again

\mainmatter

\chapter{Verifiable statements and experimental domains}

In this chapter we lay the foundations for our general mathematical theory of experimental science: a formalism that is broad enough to be applied to any area of scientific investigation. It is based on the idea of \textbf{verifiable statements}, assertions that are either true or false and that can be validated experimentally. Whether it is physics or chemistry, economics or psychology, medicine or biology, the goal is always to find some objective truth about the natural world that is supported by experimental data.

We group verifiable statements into \textbf{experimental domains} which represent the list of all possible testable answers to a particular scientific question. From those, we define \textbf{theoretical domains} which add those statements that, though not directly testable, can be used to describe predictions. Within each theoretical domain, we find those particular statements that, if true, predict the truthfulness or falsehood of all other statements. We call these the \textbf{possibilities} of the domain as they identify the complete descriptions that are admissible. To answer a scientific question, then, is to find which possibility is consistent with experimental data: the one that correctly predicts the result of all experimental tests.

We'll see how the above organization always exists on any given set of verifiable statements. That is, it is a fundamental structure for all sciences. We'll also see that these concepts are deeply intertwined with fundamental mathematical tools: experimental domains map to topologies while theoretical domains map to $\sigma$-algebras. These two core mathematical structures provide the foundation for differential geometry, Lie algebras, measure theory, probability theory and other mathematical branches that are heavily used in physics and other sciences.

As a consequence of this connection, we can build a more precise, intuitive and insightful understanding of what these mathematical structures are meant to represent in the scientific world. It also reveals why these mathematical tools are so pervasive and successful in science.

\section{Statements}

Statements, like \statement{the mass of the electron is $511 \pm 0.5$ keV} or \statement{that animal is a cat}, will be the cornerstone of our general mathematical theory of experimental science. In this section we will outline the basic definitions that allow us to combine statements into other statements (e.g. \statement{that animal is black} and \statement{that animal a cat} gives \statement{that animal is a black cat}) and to compare their content (e.g. \statement{the mass of the electron is $511 \pm 0.5$ keV} and \statement{the mass of the electron is $0.511 \pm 0.0005$ MeV} are equivalent).

We will start from a somewhat different starting point than what is customary in order to address a few issues. The first is that we need to develop a formal framework to handle the relationship of statements that are not themselves formally defined.\footnote{This is the main reason we cannot simply use the tools of mathematical logic.} The second issue is that the truth values in our context are in general found experimentally, not through deduction. The role of the logic framework is to keep track of the consistency between the possible hypothetical cases. That is, we need relationships that capture the idea of causal relationship, that one is true because the other is true, and not merely because they both happen to be true.\footnote{For example, in standard logic the material condition is defined as the truth function $p \to q = \NOT( p \AND \NOT q)$. This means that the proposition ``pi is transcendental" $\to$ ``5 is prime" is true.} We remind the reader that the mathematical sections, highlighted with a green bar on the side, can be skipped without loss of conceptual understanding in case one is not interested in all the details. 

As a starting point, we need to define what science is: the systematic study of the physical world through observation and experimentation. We therefore introduce the principle of scientific objectivity that will guide us throughout this work. This states that science is universal, non-contradictory and evidence based.

\begin{mathSection}
	\textbf{Principle of scientific objectivity}.
		Science is universal, non-contradictory and evidence based.
\end{mathSection}

Consider assertions like \statement{jazz is marvelous} or \statement{green and red go well together}. These are not objective: there is no agreed upon definition or procedure for what constitutes marvelous music or good color combination. Because of their nature, they can't be the subject of scientific inquiry. This does not mean that marvelous music or good color combinations do not exist or are not worth studying.\footnote{In fact, one can argue that most of the things that make life worth living (e.g. love, friendship, arts, purpose and so on) defy objective characterization and, therefore, that science gives us certain truth about trifling matters.} What the principle tells us is simply that if we choose to do science, we are limiting ourselves to those assertions that are either true or false (i.e. non-contradictory) for everybody (i.e. universal): assertions that have a single truth value. We call these assertions statements: they are the basic building blocks of a scientific description as only these can be studied scientifically.

\begin{mathSection}
\begin{defn}
	The \textbf{Boolean domain} is the set $\mathbb{B} = \{\FALSE, \TRUE\}$ of all possible truth values.
\end{defn}


\begin{axiom}\label{ax_statement}
	A \textbf{statement} $\stmt$ is an assertion that is either true or false. Formally, a statement is an element of the set $\mathcal{S}$ of all statements upon which is defined a function $\truth: \mathcal{S} \to \mathbb{B}$ that returns the truth value for each element.
\end{axiom}

\end{mathSection}

The idea of statements has their origin in the philosophical tradition of classical logic, \statement{Socrates is a man} being a classic example. Any language can be used to form them, formal or natural, as indeed any language is used in practice. This means we are not going to care what particular syntax (i.e. symbols and grammar rules) is used.\footnote{In general, statements in this context are not necessarily well formed formulas, predicates or similar concepts in the context of mathematical or propositional logic. Scientific investigation in the broad sense of learning from experimentation predates math and formal languages: information about agriculture, astronomy, metallurgy, botany and the like were collected and used even before the written word. Moreover, cognitive scientists have shown that children start using deliberate experimentation at a very young age to understand the world around them, even before their speech is fully developed. Ultimately, that knowledge is encoded in the language of electrical and biochemical signals. Formal languages are indeed extremely helpful in that they allow us to be more precise and to better keep track of possible inconsistencies, but ultimately one always needs natural language to give meaning and context to the mathematical symbols.} In fact, even a grammatically incorrect statement is fine as long as the intent is clear. On the other hand, we are going to care about the semantics of the statements (i.e. their content and meaning). Therefore we will consider \statement{Socrates is a man} and \statement{Socrate e' un uomo} to be the same statement because they provide the same assertion but in different languages.

Moreover, when we say \statement{Socrates is a man} it has to be clear who is Socrates and what a man is. If it weren't, we would have no idea what to experimentally test and how. This is also important because the mere content of a set of statements puts constraints on what can be found to be true or false. Consider the statement \statement{that cat is a swan}. There is nothing to experimentally test here: based on the definitions of cat and swan we know the statement can never be true, no matter what particular cat we are considering. The statement provides no new information. Consider, instead, the statements \statement{that animal is a mammal} and \statement{that animal is a bird}. Based on the content, each of the statements can be found true or false separately, but they can't be found true together.

To keep track of this sort of situation, each statement in our framework not only has a truth value but also a set of possibilities: the set of possible truth values the statement is allowed to take based on its content. We expect the truth value to be one of these possible values. We also expect that in every context, for every set of statements, each possible value can be hypothetically assigned to that statement in a way that does not lead to any logical inconsistencies (i.e. a paradox, a statement that is both true and false).

Some statements will only be allowed one truth value. We will call a tautology a statement, like \statement{that cat is an animal}, that can only be true and a contradiction a statement, \statement{that cat is a swan}, that can only be false.

\begin{mathSection}
	\begin{defn}
	Given a collection of statements $\{\stmt_i\}^n_{i=1}$, a \textbf{consistent truth assignment} is a collection of truth values $\{t_i\}^n_{i=1}$ such that it is logically consistent to simultaneously suppose that $\truth(\stmt_i) = t_i$ for all $1 \leq i \leq n$. That is, from those assumptions it cannot be proven that $\truth(\stmt_i) \neq t_i$ for any $1 \leq i \leq n$.  This definition generalizes to the case of infinite, possibly uncountable, collections.
\end{defn}
	
\begin{axiom}\label{ax_possibilities}
	The \textbf{possibilities} of a statement $\stmt$ are the possible truth values allowed by the content of the statement. Formally, on the set $\mathcal{S}$ of all statements is also defined a function $\possFn: \mathcal{S} \to \{\{\FALSE, \TRUE\},\{\FALSE\},\{\TRUE\}\}$ such that:
	\begin{itemize}
		\item $\truth(\stmt) \in \possFn(\stmt)$ for all $\stmt \in \mathcal{S}$. This remains valid in every consistent truth assignment.
		\item for any collection of statements $\{\stmt_i\}^n_{i=1}$, for any $1 \leq j \leq n$ and for any $t \in \possFn(\stmt_j)$ there exists a consistent truth assignment $\{t_i\}^n_{i=1}$ such that $t_j = t$. This generalizes to the case of infinite, possibly uncountable, indexed families.
	\end{itemize}
\end{axiom}

\begin{coro}
	If $\{t_i\}^n_{i=1}$ is a possible truth assignment for $\{\stmt_i\}^n_{i=1}$, then $t_i \in \possFn(\stmt_i)$ for all $1 \leq i \leq n$.
\end{coro}
\begin{proof}
	Since $\{t_i\}^n_{i=1}$ is a possible truth assignment for $\{\stmt_i\}^n_{i=1}$, we can let $\truth(\stmt_i) = t_i$ for all $1 \leq i \leq n$. Since $\truth(\stmt_i) \in \possFn(\stmt_i)$ for all $\stmt_i$, then it must also be that $t_i \in \possFn(\stmt_i)$ for all $1 \leq i \leq n$.
\end{proof}

	\begin{defn}
		A \textbf{tautology} $\tautology$ is a statement that must be true simply because of its content. That is, $\possFn(\stmt) = \{\TRUE\}$.
	\end{defn}
	
	\begin{defn}
		A \textbf{contradiction} $\contradiction$ is a statement that must be false simply because of its content. That is, $\possFn(\stmt) = \{\FALSE\}$.
	\end{defn}
	
\end{mathSection}

Next we want to keep track of statements whose truths are a function of the truth of other statements. Consider \statement{that animal is a cat} and \statement{that animal is not a cat}: if the first one is true then the second is false and vice-versa. In this sense, the second statement is a function of the first. Therefore, in general, a statement is a function of other statements if its truth is determined by the truth values of the other statements.

Since statements are intangible, there are no limits to the number of arguments one statement may depend on. For example, consider the statement \statement{the mass of the electron is $511 \pm 0.5$ keV} and the set of all the statements of the form \statement{the mass of the electron is exactly $x$ keV} with $510.5 < x < 511.5$. If any of the latter is true then the original statement is true as well. Given that $x$ is a real number, that is uncountably many statements so the original statement can be seen as a function of uncountably many statements.

At first one may expect that the possibilities of the final statement will be determined by the possibilities of the original statement, but this is not the case in general. Consider the following statements: \statement{Felix is a cat}, \statement{Felix is black} and \statement{Felix is a dog}. All three can independently be true or false. But just knowing that does not allow us to know whether they can be true at the same time. It is because we know the meaning of cat, black and dog that we know that \statement{Felix is a cat and a dog} is a contradiction while \statement{Felix is a cat and black} is not. If the statements were written in a language we didn't understand, we would have no clue. In fact, in our framework, it is by looking at the possibilities of \statement{Felix is a cat and a dog} that we learn it is a contradiction and deduce that \statement{Felix is a cat} and \statement{Felix is a dog} cannot both be true, as that does not allow a consistent truth assignment. That is: the possibilities combined with truth functions allow us to capture the semantic relationships of our informal statements.

\begin{mathSection}

	\begin{axiom}\label{ax_functions_of_statement}
		We can always construct a statement whose truth value arbitrarily depends on an arbitrary set of statements. Formally: given an arbitrary truth function $f_{\mathbb{B}} : \mathbb{B}^n \to \mathbb{B}$ there exists a function $f : \mathcal{S}^n \to \mathcal{S}$ such that
		$$\truth(f(\stmt_1, ..., \stmt_n)) = f_{\mathbb{B}}(\truth(\stmt_1), ..., \truth(\stmt_n))$$
		and the same relationship remains valid in every consistent truth assignment. This also holds in the case of infinite, possibly uncountable, arguments.
	\end{axiom}
\end{mathSection}

To better characterize truth functions, we borrow ideas and definitions from Boolean algebra which is the branch of algebra that operates on truth values. Boolean algebra is fundamental in logic and computer science, since every digital circuit ultimately is implemented on two-state systems (e.g. high/low voltage, up/down magnetization).  The most fundamental elements in that algebra are the following three simple operations: negation (i.e. logical NOT), conjunction (i.e. logical AND) and disjunction (i.e. logical OR).

Suppose $\stmt_1$ = \emph{``the sauce is sweet"} and $\stmt_2$ = \emph{``the sauce is sour"}. We can apply the three operations to make this table:

\begin{table}[h]
	\centering
	\begin{tabular}{p{0.2\textwidth} p{0.1\textwidth} p{0.1\textwidth} p{0.5\textwidth}}
		Operator & Gate & Symbol & Example \\ 
		\hline 
		Negation & NOT & $\NOT \stmt_1$ &  \emph{``the sauce is not sweet"} \\ 
		Conjunction & AND & $\stmt_1 \AND \stmt_2$ & \emph{``the sauce is sweet and sour"} \\ 
		Disjunction & OR & $\stmt_1 \OR \stmt_2$ & \emph{``the sauce is at least sweet or sour"}
	\end{tabular} 
	\caption{Boolean operations on statements.}
\end{table}

Most languages typically already provide similar operations, as the examples show. Technically, though, we should consider the ones defined here as meta-operations that are defined outside the language of the statements. For example, \statement{x is the position of a ball}$\AND$\statement{$\,\frac{d^2 x}{dt^2} = - g$} stitches together an English statement with a calculus statement into a new statement that is neither. This kind of mix should be allowed as it does happen in practice.

\begin{mathSection}
	\begin{defn}
		The \textbf{negation or logical NOT} is the function $\NOT : \mathbb{B} \to \mathbb{B}$ that takes a truth value and returns its opposite. That is: $\NOT \TRUE = \FALSE$ and $\NOT \FALSE = \TRUE$. We also call negation $\NOT: \mathcal{S} \to \mathcal{S}$ the related function on statements.
	\end{defn}
	
	\begin{defn}
		The \textbf{conjunction or logical AND} is the function $\AND : \mathbb{B} \times \mathbb{B} \to \mathbb{B}$ that returns $\TRUE$ only if all the arguments are $\TRUE$. That is: $\TRUE \AND \TRUE = \TRUE$ and $\TRUE \AND \FALSE =\FALSE \AND \TRUE =\FALSE \AND \FALSE = \FALSE$. We also call conjunction $\AND : \mathcal{S} \times \mathcal{S} \to \mathcal{S}$ the related function on statements.
	\end{defn}
	
	\begin{defn}
		The \textbf{disjunction or logical OR} is the function $\OR : \mathbb{B} \times \mathbb{B} \to \mathbb{B}$ that returns $\FALSE$ only if all the arguments are $\FALSE$. That is: $\FALSE \OR \FALSE = \FALSE$ and $\TRUE \OR \FALSE =\FALSE \OR \TRUE =\TRUE \OR \TRUE = \TRUE$.  We also call disjunction $\OR : \mathcal{S} \times \mathcal{S} \to \mathcal{S}$ the related function on statements.
	\end{defn}

	\begin{prop}
	The set of all statements $\mathcal{S}$ is closed under negation, arbitrary conjunction and arbitrary disjunction.
\end{prop}
\begin{proof}
	Negation, arbitrary conjunction and arbitrary disjunction are particular truth functions. Their output always exists by axiom \eqref{ax_functions_of_statement}.
\end{proof}\end{mathSection}

Now we have all the elements to define when two statements have the same logical content. Consider the two statements \statement{that animal is a bird} and \statement{that animal has feathers}: since all birds and only birds have feathers they give us the same information. Consider \statement{the mass of the electron is $511 \pm 0.5$ keV} and \statement{the mass of the electron is $0.511 \pm 0.0005$ MeV}: they represent the same measurement but in different units. So, how can we express the fact that two statements $\stmt_1$ and $\stmt_2$ mean the same thing? The idea is that they can never be assigned opposite truth values. If we assigned true to the first, then the second must be true as well. If we assigned false to the first, then the second must be false. That is: either $\stmt_1 \AND \stmt_2$ is true or $\NOT\stmt_1 \AND \NOT\stmt_2$ is true for all consistent truth assignments. In other words $(\stmt_1 \AND \stmt_2) \OR (\NOT\stmt_1 \AND \NOT\stmt_2)$ can only be true: it's a tautology.\footnote{This technique allows us to do something analogous to model theory. Two statements are equivalent if their truth is equal for all consistent truth assignments, which in our framework play the part of the models of model theory. But in our context the assignments are only hypothetical: there isn't a model in which \statement{this is a cat} and another in which \statement{this is a dog}. There is only one truth value, the one we find experimentally.}

\begin{mathSection}

\begin{defn}
	Two statements $\stmt_1$ and $\stmt_2$ are \textbf{equivalent} $\stmt_1 \equiv \stmt_2$ if they must be equally true or false simply because of their content. Formally, $\stmt_1 \equiv \stmt_2$ if and only if $(\stmt_1 \AND \stmt_2) \OR (\NOT\stmt_1 \AND \NOT\stmt_2)$ is a tautology.
\end{defn}

\begin{coro}
	If $\stmt_1 \equiv \stmt_2$ then $\truth(\stmt_1) = \truth(\stmt_2)$ and $\possFn(\stmt_1) = \possFn(\stmt_2)$.
\end{coro}

\begin{proof}
	If $\stmt_1 \equiv \stmt_2$, then $\truth((\stmt_1 \AND \stmt_2) \OR (\NOT\stmt_1 \AND \NOT\stmt_2)) \in \possFn((\stmt_1 \AND \stmt_2) \OR (\NOT\stmt_1 \AND \NOT\stmt_2)) = \{\TRUE\}$. By \ref{ax_functions_of_statement} $\truth((\stmt_1 \AND \stmt_2) \OR (\NOT\stmt_1 \AND \NOT\stmt_2))= (\truth(\stmt_1) \AND \truth(\stmt_2) ) \OR (\NOT\truth(\stmt_1) \AND \NOT\truth(\stmt_2)) = \TRUE$. This is true if and only if $\truth(\stmt_1) = \truth(\stmt_2)$.
	
	Consider a consistent truth assignment $\{t_1, t_2\}$ for the sequence of two equivalent statements $\{\stmt_1, \stmt_2\}$. We have $t_1=t_2$ since the truth values are the same. We also have $t_1 \in \possFn(\stmt_1)$ and $t_2 \in \possFn(\stmt_2)$. Since every possibility must be part of a consistent truth assignment, we must have $\possFn(\stmt_1) = \possFn(\stmt_2)$.
\end{proof}

\end{mathSection}

Again, we want to stress that this notion of equivalence is not based on the truth value (i.e. whether the statements happen to be both true or false) or on whether they are the same statement (i.e. whether they assert the same thing): it is based on the possibilities (i.e. whether the two statements can possibly have a different truth) and therefore on the content of the statements. We sum up the difference in the following table.


\begin{table}[h]
	\centering
	%	\begin{tabular}{p{0.2\textwidth} p{0.1\textwidth} p{0.1\textwidth} p{0.5\textwidth}}
	\begin{tabular}{p{0.12\textwidth} c p{0.2\textwidth} p{0.25\textwidth}}
		Equivalence & Symbol & First statement & Second statement \\ 
		\hline 
		Semantic & $\stmt_1 = \stmt_2$ & \statement{Swans are birds} & \statement{I cigni sono uccelli} \\ 
		Logical & $\stmt_1 \equiv \stmt_2$ & \statement{Swans are birds}  & \statement{Swans have feathers} \\ 
		Material & $\truth(\stmt_1) = \truth(\stmt_2)$ & \statement{Swans are birds}  & \statement{The earth is round} \\ 
	\end{tabular}
	\caption{Different types of statement equivalences.}
\end{table}


Also note that the semantics defines the possibilities but not the truth value, unless the statement is a tautology or a contradiction. For example, even if the meaning of \statement{the next race is going to be won by Secretariat} is clear, and so is its relationship to \statement{the next race is going to be lost by Secretariat}, we may be none the wiser about its truthfulness. Intuitively, the equivalence we defined here answers the question: do these two statements carry the same information? Is experimentally testing the first the same as experimentally testing the second? If that's the case, they are essentially equivalent to us. So much so, that from now on we will implicitly assume two different statements to be inequivalent.\footnote{Technically, when we'll say that $\stmt$ is a statement we actually mean $\stmt$ is an equivalence class of statements. We are not going to be explicit about the distinction, though, as we feel it simply distracts without adding greater clarity. We'll let the context determine what is meant.}

There are a number of useful properties that statement equivalence satisfies.

\begin{mathSection}

\begin{prop}
	All tautologies are equivalent. All contradictions are equivalent.
\end{prop}
\begin{proof}
	Let $\tautology_1, \tautology_2 \in \mathcal{S}$ be two tautologies. The only consistent truth assignment for the sequence of statements $\{\tautology_1, \tautology_2, (\tautology_1 \AND \tautology_2) \OR (\NOT\tautology_1 \AND \NOT\tautology_2)\}$ is $\{\TRUE, \TRUE, \TRUE \}$. Therefore $\possFn((\tautology_1 \AND \tautology_2) \OR (\NOT\tautology_1 \AND \NOT\tautology_2)) = \{\TRUE\}$ and $\tautology_1 \equiv \tautology_2$.
	
	Let $\contradiction_1, \contradiction_2 \in \mathcal{S}$ be two contradictions. The only consistent truth assignment for the sequence of statements $\{\contradiction_1, \contradiction_2, (\contradiction_1 \AND \contradiction_2) \OR (\NOT\contradiction_1 \AND \NOT\contradiction_2)\}$ is $\{\FALSE, \FALSE, \TRUE \}$. Therefore $\possFn((\contradiction_1 \AND \contradiction_2) \OR (\NOT\contradiction_1 \AND \NOT\contradiction_2)) = \{\TRUE\}$ and $\contradiction_1 \equiv \contradiction_2$.
\end{proof}

\begin{prop}\label{prop_equivalent_is_iff}
	Let $\stmt_1, \stmt_2 \in \mathcal{S}$ be two statements such that it can be formally proven that $\truth(\stmt_1) = \TRUE$ if and only if $\truth(\stmt_2) = \TRUE$. Then $\stmt_1 \equiv \stmt_2$.
\end{prop}

\begin{proof}
	Consider a consistent truth assignment $\{t_1, t_2, t_3\}$ for the sequence of statements $\{\stmt_1, \stmt_2, (\stmt_1 \AND \stmt_2) \OR (\NOT\stmt_1 \AND \NOT\stmt_2)\}$. Since it can be proven that $\truth(\stmt_1) = \TRUE$ if and only if $\truth(\stmt_2) = \TRUE$ we must have that $t_1=t_2$. Since $t_3$ can be calculated from $t_1$ and $t_2$, the consistent truth assignment is either $\{\TRUE, \TRUE, \TRUE\}$ or $\{\FALSE, \FALSE, \TRUE\}$. As there is no assignment for $t_3=\FALSE$, then $\possFn((\stmt_1 \AND \stmt_2) \OR (\NOT\stmt_1 \AND \NOT\stmt_2)) = \{\TRUE\}$. Therefore $\stmt_1 \equiv \stmt_2$ by definition.
\end{proof}

\begin{coro}
	Statement equivalence satisfies the following properties:
	\begin{itemize}
		\item reflexivity: $\stmt \equiv \stmt$
		\item symmetry: if $\stmt_1 \equiv \stmt_2$ then $\stmt_2 \equiv \stmt_1$
		\item transitivity: if $\stmt_1 \equiv \stmt_2$ and $\stmt_2 \equiv \stmt_3$ then $\stmt_1 \equiv \stmt_3$
	\end{itemize}
	and is therefore an \textbf{equivalence relationship}.
\end{coro}
\begin{proof}
	Because statement equivalence implies truth equivalence, in all three cases the left side is true if and only if the right side is true. Therefore the statements are equivalent by \ref{prop_equivalent_is_iff}.
\end{proof}

	\begin{coro}\label{boolean_properties}
		The set of all statements $\mathcal{S}$ satisfies the following properties:
		\begin{itemize}
			\item associativity: $a \OR (b \OR c) \equiv (a \OR b) \OR c$, $a \AND (b \AND c) \equiv (a \AND b) \AND c$
			\item commutativity: $a \OR b \equiv b \OR a$, $a \AND b \equiv b \AND a$
			\item absorption: $a \OR (a \AND b) \equiv a$, $a \AND (a \OR b) \equiv a$
			\item identity: $a \OR \contradiction \equiv a
			$, $a \AND \tautology \equiv a$
			\item distributivity: $a \OR (b \AND c) \equiv (a \OR b) \AND (a \OR c)$, $a \AND (b \OR c) \equiv (a \AND b) \OR (a \AND c)$
			\item complements: $a \OR \NOT a \equiv \tautology$, $a \AND \NOT a \equiv \contradiction$
			\item De Morgan: $\NOT a \OR \NOT b \equiv \NOT (a \AND b)$, $\NOT a \AND \NOT b \equiv \NOT (a \OR b)$
		\end{itemize}
		This, by definition, means $\mathcal{S}$ is a \textbf{Boolean algebra}.
	\end{coro}
	\begin{proof}
		The left and right expressions for each equivalence correspond to the same truth function applied to the same statements. Therefore, the left side is true if and only if the right side is true and they are therefore equivalent by \eqref{prop_equivalent_is_iff}.
	\end{proof}
\end{mathSection}

These operations and properties define the \textbf{algebra of statements}. While we started from a slightly different premise, the relationships we found are the logical identities of classical logic. These are exactly what we need to make sure the truth values of all our statements are consistent.

Equivalence is not the only semantic relationship that we want to capture. Consider the contents of the following:
\begin{description}
	\item $\stmt_1=$\statement{that animal is a cat}
	\item $\stmt_2=$\statement{that animal is a mammal}
	\item $\stmt_3=$\statement{that animal is a dog}
	\item $\stmt_4=$\statement{that animal is black}
\end{description}
The second will be true whenever the first is true. In this case we say the first statement is narrower than the second ($\stmt_1$ $\narrower$ $\stmt_2$) because \statement{that animal is a cat} is more specific than \statement{that animal is a mammal}. The third will be false whenever the first is true. In this case we say that they are incompatible ($\stmt_1$ $\ncomp$ $\stmt_3$) because \statement{that animal is a dog} and \statement{that animal is a cat} can never be true at the same time. The fourth will be true or false regardless of whether the first is true. In this case we say that they are independent ($\stmt_1$ $\indep$ $\stmt_4$) because knowing whether \statement{that animal is a cat} tells us nothing about whether \statement{that animal is black}. As for equivalence, we can define these relationships upon the previous definitions.

\begin{mathSection}

\begin{defn}
	Given two statement $\stmt_1$ and $\stmt_2$, we say that:
	\begin{itemize}
		\item $\stmt_1$ \textbf{is narrower than} $\stmt_2$ (noted $\stmt_1 \narrower \stmt_2$) if $\stmt_2$ is true whenever $\stmt_1$ is true simply because of their content. That is, $\stmt_1 \AND \NOT \stmt_2 \equiv \contradiction$.
		\item $\stmt_1$ \textbf{is broader than} $\stmt_2$ (noted $\stmt_1 \broader \stmt_2$) if $\stmt_2 \narrower \stmt_1$.
		\item $\stmt_1$ \textbf{is compatible to} $\stmt_2$ (noted $\stmt_1 \comp \stmt_2$) if their content allows them to be true at the same time. That is, $\stmt_1 \AND \stmt_2 \nequiv \contradiction$.

	\end{itemize}
	The negation of these properties will be noted by $\nnarrower$, $\nbroader$ , $\ncomp$ respectively.
\end{defn}
\begin{defn}
	The elements of a set of statements $S \subseteq \mathcal{S}$ are said to be \textbf{independent} (noted $\stmt_1 \indep \stmt_2$ for a set of two) if their content is such that any combination of their possibilities is allowed. That is, $\possFn(f(S)) = f(\bigtimes\limits_{\stmt \in S} \possFn(\stmt))$ for any truth function $f : \mathbb{B}^{|S|} \to \mathbb{B}$. The negation of independence, will be noted by $\nindep$.
\end{defn}

\begin{prop}\label{prop_narrowness_properties}
	The above operations obey the following relationships:
	\begin{enumerate}[label=(\roman*)]
		\item 	$\stmt_1 \narrower \stmt_2$ if and only if $\stmt_1 \AND \stmt_2 \equiv \stmt_1$
		\item 	$\stmt_1 \narrower \stmt_2$ if and only if $\stmt_1 \OR \stmt_2 \equiv \stmt_2$
		\item 	$\stmt_1 \ncomp \stmt_2$ if and only if $\stmt_1 \AND \NOT \stmt_2 \equiv \stmt_1$
		\item 	$\stmt_1 \narrower \stmt_1 \OR \stmt_2$
		\item 	$\stmt_1 \AND \stmt_2 \narrower \stmt_1$
	\end{enumerate}	
\end{prop}

\begin{proof}
	For (i), consider $\stmt_1 \AND \stmt_2 \equiv \stmt_1 \AND \stmt_2 \OR \contradiction$. Since $\stmt_1 \narrower \stmt_2$, $\stmt_1 \AND \NOT \stmt_2 \equiv \contradiction$. We have $\stmt_1 \AND \stmt_2 \OR \contradiction \equiv ( \stmt_1 \AND \stmt_2 ) \OR (\stmt_1 \AND \NOT \stmt_2) \equiv \stmt_1 \AND (\stmt_2 \OR \NOT \stmt_2) \equiv \stmt_1 \AND \tautology \equiv \stmt_1$. Therefore $\stmt_1 \AND \stmt_2 \equiv \stmt_1$. The same logic can be applied in reverse.
	
	For (ii), consider $\stmt_1 \OR \stmt_2 \equiv \stmt_1 \OR \stmt_2 \AND \tautology \equiv (\stmt_1 \OR \stmt_2) \AND (\NOT \stmt_2 \OR \stmt_2) \equiv (\stmt_1 \AND \NOT \stmt_2) \OR \stmt_2$. Since $\stmt_1 \narrower \stmt_2$, $\stmt_1 \AND \NOT \stmt_2 \equiv \contradiction$. We have $(\stmt_1 \AND \NOT \stmt_2) \OR \stmt_2 \equiv \contradiction \OR \stmt_2 \equiv \stmt_2$. Therefore $\stmt_1 \AND \stmt_2 \equiv \stmt_2$. The same logic can be applied in reverse.

	For (iii), consider $\stmt_1 \AND \NOT \stmt_2 \equiv \stmt_1 \AND \NOT \stmt_2 \OR \contradiction$. Since $\stmt_1 \ncomp \stmt_2$, $\stmt_1 \AND \stmt_2 \equiv \contradiction$. We have $\stmt_1 \AND \NOT \stmt_2 \OR \contradiction \equiv ( \stmt_1 \AND \NOT \stmt_2 ) \OR (\stmt_1 \AND \stmt_2) \equiv \stmt_1 \AND (\NOT \stmt_2 \OR \stmt_2) \equiv \stmt_1 \AND \tautology \equiv \stmt_1$. Therefore $\stmt_1 \AND \NOT \stmt_2 \equiv \stmt_1$. The same logic can be applied in reverse.
	
	For (iv), we have $\stmt_1 \AND \NOT (\stmt_1 \OR \stmt_2) \equiv \stmt_1 \AND \NOT \stmt_1 \AND \NOT \stmt_2 \equiv \contradiction \AND \NOT \stmt_2 \equiv \contradiction$. Therefore $\stmt_1 \narrower \stmt_1 \OR \stmt_2$.
	
	For (v), we have $\stmt_1 \AND \stmt_2 \AND \NOT \stmt_1 \equiv \stmt_1 \AND \NOT \stmt_1 \AND \stmt_2 \equiv \contradiction \AND \stmt_2 \equiv \contradiction$. Therefore $\stmt_1 \AND \stmt_2 \narrower \stmt_1$.
\end{proof}

\begin{prop}\label{prop_narrowness_is_if}
	Let $\stmt_1, \stmt_2 \in \mathcal{S}$ be two statements such that it can be formally proven that if $\truth(\stmt_1) = \TRUE$ then $\truth(\stmt_2) = \TRUE$. Then $\stmt_1 \narrower \stmt_2$.
\end{prop}

\begin{proof}
	Consider a consistent truth assignment $\{t_1, t_2, t_3\}$ for the sequence of statements $\{\stmt_1, \stmt_2, \stmt_1 \AND \NOT\stmt_2\}$. Since it can be proven that if $\truth(\stmt_1) = \TRUE$ then $\truth(\stmt_2) = \TRUE$, and since $t_3$ can be calculated from $t_1$ and $t_2$, the consistent truth assignment is either $\{\TRUE, \TRUE, \FALSE\}$, $\{\FALSE, \TRUE, \FALSE\}$ or $\{\FALSE, \FALSE, \FALSE\}$. As there is no assignment for $t_3=\TRUE$, then $\possFn(\stmt_1 \AND \NOT\stmt_2) = \{\FALSE\}$. Therefore $\stmt_1 \narrower \stmt_2$ by definition.
\end{proof}

\begin{prop}
	Statement narrowness satisfies the following properties:
	\begin{itemize}
		\item reflexivity: $s \narrower s$
		\item antisymmetry: if $s_1 \narrower s_2$ and  $s_2 \narrower s_1$ then $s_1 \equiv s_2$
		\item transitivity: if $s_1 \narrower s_2$ and $s_2 \narrower s_3$ then $s_1 \narrower s_3$
	\end{itemize}
	and is therefore a \textbf{partial order}.
\end{prop}
\begin{proof}
	For reflexivity, since if $\truth(\stmt) = \TRUE$ then we must have $\truth(\stmt) = \TRUE$ then $s \narrower s$ by \eqref{prop_narrowness_is_if}.
	
	For antisymmetry, suppose $\stmt_1 \narrower \stmt_2$ and $\stmt_1 \broader \stmt_2$. Then $\stmt_1 \AND \stmt_2 \equiv \stmt_1$ since $\stmt_1 \narrower \stmt_2$ and $\stmt_1 \AND \stmt_2 \equiv \stmt_2$ since $\stmt_2 \narrower \stmt_1$. Therefore $\stmt_1 \equiv \stmt_2$. Conversely, suppose $\stmt_1 \equiv \stmt_2$. Then $\stmt_1 \AND \stmt_2 \equiv \stmt_1 \equiv \stmt_2$. Therefore $\stmt_1 \narrower \stmt_2$ and $\stmt_1 \broader \stmt_2$.
	
	For transitivity, let $\{t_1, t_2, t_3, t_4\}$ be a consistent truth assignment for the sequence of statements $\{\stmt_1, \stmt_2, \stmt_3, \stmt_1 \AND \NOT\stmt_3\}$.  Since $s_1 \narrower s_2$ and $s_2 \narrower s_3$, the consistent truth assignment must be one of the following: $\{\TRUE, \TRUE, \TRUE, \FALSE\}$, $\{\FALSE, \TRUE, \TRUE, \FALSE\}$, $\{\FALSE, \FALSE, \TRUE, \FALSE\}$, $\{\FALSE, \FALSE, \FALSE, \FALSE\}$.
	Since in all cases $t_4=\FALSE$ then $\possFn(\stmt_1 \AND \NOT\stmt_3) = \{\FALSE\}$. Therefore $\stmt_1 \narrower \stmt_3$ by definition.
\end{proof}

\begin{prop}
	Every subset $S \subseteq \stmtSet$ of statements has a supremum. That is, there exists an element $\bar{\stmt} \in \stmtSet$ such that $\stmt \narrower \bar{\stmt}$ for all $\stmt \in S$. This, by definition, means the $\stmtSet$ is a \textbf{complete} Boolean algebra and, as a consequence, that the distributivity and De Morgan laws in \ref{boolean_properties} hold in the infinite case.
\end{prop}

\begin{proof}
	Let $S \subseteq \stmtSet$ be an arbitrary set of statements. Consider $\bar{\stmt}=\bigOR\limits_{\stmt[e] \in S} \stmt[e]$. This statement exists by \ref{ax_functions_of_statement}. Let $\stmt \in S$. Using the properties in \ref{boolean_properties} we have $\stmt \OR \bar{\stmt} \equiv \stmt \OR \big(\bigOR\limits_{\stmt[e] \in S} \stmt[e] \big) \equiv \stmt \OR \stmt \OR \big(\bigOR\limits_{\stmt[e] \in (S \setminus \{\stmt\})} \stmt[e] \big) \equiv \stmt \OR \big(\bigOR\limits_{\stmt[e] \in (S \setminus \{\stmt\})} \stmt[e] \big) \equiv \bigOR\limits_{\stmt[e] \in S} \stmt[e] = \bar{\stmt}$. By \ref{prop_narrowness_properties} we have $\stmt \narrower \bar{\stmt}$ for any $\stmt \in S$. Therefore any $S \subseteq \stmtSet$ admits a supremum $\bar{\stmt}$.
	
	A complete Boolean algebra is one such that every subset admits a supremum, therefore the algebra of statements is complete by definition. For a complete Boolean algebra infinite distributivity and De Morgan laws hold, therefore they will hold in the algebra of statements as well.
\end{proof}

\end{mathSection}

It should be noted that statement narrowness captures more than just the idea of one statement being more specific than another. Consider \statement{this harp seal is white} and \statement{this harp seal is less than one year old}. Since harp seals have white fur only for their first month, the first one can never be true while the second is not. Therefore \statement{this harp seal is white} $\narrower$ \statement{this harp seal is less than one year old}. By the same token, we also have \statement{I lighted the fuse} $\narrower$ \statement{the bomb will go off}. That is, narrowness can also capture causal relationships, which is essential if we want to develop a basic theory of scientific investigation.\footnote{We considered using the term implication directly, but it seems that it leads to confusion. Implication in classical logic is something different: it is simply another truth function. Moreover, saying that a contradiction is narrower than all other statements sounds better than saying that a contradiction implies all other statements.} Intuitively, a statement is narrower than another if it provides more information when true. If we experimenally verified the narrower statement, then we already know that the broader one is also verified.

It should also be noted that independence is not transitive and pair-wise independence is not sufficient. Consider the following statements for an ideal gas:
\begin{enumerate}
	\item \statement{the pressure is $101\pm1$ kPa}
	\item \statement{the volume is $1\pm0.1$ $m^3$}
	\item \statement{the temperature is $293\pm1$ Kelvin}
\end{enumerate}
Since the three quantities are linked by the equation of state $PV=nRT$, any two statements are independent but the three together aren't. This notion of independence is similar, and in fact related, to statistical independence and linear independence.

We finish this section by showing how every truth function can be naturally expressed in terms of negation, conjunction and disjunction. Consider the statement $\stmt=$\statement{the sauce is sweet and sour or it is neither}. This is a function of the two statements $\stmt_1=$\statement{the sauce is sweet} and $\stmt_2=$\statement{the sauce is sour} defined before: if we know whether $\stmt_1$ and $\stmt_2$ are true, we can tell whether $\stmt$ is true as well. The idea is that we can express the function as all possible truth assignments that make the result true. For example, $\stmt$ will be true if the sauce is sweet and sour or if it is not sweet and not sour. That is: $(\stmt_1 \AND \stmt_2) \OR (\NOT \stmt_1 \AND \NOT \stmt_2)$. Similarly, the statement \statement{the sauce is not sweet and sour} can be expressed as $(\stmt_1 \AND \NOT \stmt_2) \OR (\NOT \stmt_1 \AND \stmt_2) \OR (\NOT \stmt_1 \AND \NOT \stmt_2)$ since it is going to be true in all cases except the one where the sauce is sweet and sour.

Each of the cases is the conjunction of all arguments where each one appears only once, negated or not. We call these expressions minterms. A function can always be expressed as the disjunction of all the minterms for which the function is true. This is called its disjunctive normal form because it is a canonical way to express the function in terms of disjunctions.

\begin{mathSection}
	\begin{defn}\label{def_minterm}
		Let $\{t_1, ..., t_n\} \subseteq \mathbb{B}^n$ be a set of truth values. A \textbf{minterm} of $\{t_1, ..., t_n\}$ is a conjunction where each element appears only once, either negated or not. That is, it can be written as $m = \bigAND \limits_{i=1}^n (\NOT)^{a_{i}} \, t_i$ where $a_{i} \in \mathbb{B}$, $\NOT ^ \TRUE \, t_i = t_i$ and $\NOT ^ \FALSE \, t_i = \NOT t_i$. In this notation, $m = \TRUE$ if and only if $t_i = a_i$ for all $i=1...n$. This extends to arbitrary sets of truth values. Similarly, we call a minterm of a set of statements a conjunction where each statement appears only once, either negated or not.
	\end{defn}
	
	\begin{prop}\label{prop_disjunctive_normal_form}
		Any function $f : \mathbb{B}^n \to \mathbb{B}$ that takes $n$ truth values and returns a truth value, which we call a \textbf{truth function}, can be expressed in its \textbf{disjunctive normal form} as a disjuction of minterms of the arguments. Formally, $f(t_1, ..., t_n) =\bigOR \limits_{i=1}^m \left( \bigAND \limits_{j=1}^n (\NOT)^{a_{ij}} \, t_j \right)$ where $m \in \mathbb{N}$ and  $a_{ij} \in \mathbb{B}$. This extends to functions of arbitrary arguments. Similarly, we call disjunctive normal form of a function of statements the analogous construction in terms of statements.
	\end{prop}
	\begin{proof}
		We first show that this can be done for a function that returns $\TRUE$ for a unique combination of values. Let $a_1, ..., a_n \in \mathbb{B}$ be $n$ truth values. Let $f_1: \mathbb{B}^n \to \mathbb{B}$ be a function such that $f_1(t_1, ..., t_n) = \TRUE$ if and only if $t_j = a_j$ for all $j=1...n$. Consider the minterm $\bigAND \limits_{j=1}^n (\NOT)^{a_{j}} \, t_j$. It will be $\TRUE$ if and only if $t_j \equal a_j$ for all $j=1...n$. Then we have $f_1(t_1, ..., t_n) = \bigAND \limits_{j=1}^n (\NOT)^{a_{j}} \, t_j$ since both functions return the same values for the same arguments.
		
		Now we generalize the result for arbitrary functions. Let $f : \mathbb{B}^n \to \mathbb{B}$ be a truth function. Let $m \in \mathbb{N}$ be the number of value combinations for which $f(t_1, ..., t_n) = \TRUE$. For each value combination $i=1...m$ let $a_{ij} \in \mathbb{B}$ be the sequence of values. Then $f_i = \bigAND \limits_{j=1}^n (\NOT)^{a_{ij}} \, t_j$ is the minterm for each value combination. Consider $\bigOR \limits_{i=1}^m f_i$. This function returns $\TRUE$ if and only if the arguments match one of the value combinations for which $f$ returns $\TRUE$. Then we have $f(t_1, ..., t_n) =\bigOR \limits_{i=1}^m \left( \bigAND \limits_{j=1}^n (\NOT)^{a_{ij}} \, t_j \right)$ since they return the same values for the same arguments.
		
		This procedure can be generalized to the case where the number of arguments of $f$ and the number of minterms is infinite.
	\end{proof}
\end{mathSection}

With these tools in place we are in a position to formulate models that are universal and non-contradictory. These models will be a collection of statements with a well defined content, whose truth value will be discovered experimentally.

\section{Verifiable statements and experimental domains}

We now focus on those statements that are verifiable: we have a way to experimentally confirm that the statement is true. The main result of this section is that not all functions of verifiable statements are verifiable statements. For example, since a test has to finish in a finite amount of time we are not going to be able to verify a statement that is the conjunction (i.e. logical AND) of infinitely many statements. We are also going to group verifiable statements into experimental domains which represent all the experimental evidence about a scientific subject that can be acquired in an indefinite amount of time.

The previous section took care of universality and non-contradiction, but the principle of scientific objectivity requires science to be evidence based. Consider the statements \statement{the square of the hypotenuse is equal to the sum of the squares of the other two sides} or \statement{God is eternal}. They deal with abstract concepts that cannot solely be defined experimentally and therefore cannot be experimentally verified conclusively. Again, this does not mean these concepts are of less significance, just that they cannot be the subject of scientific inquiry.\footnote{In fact, one may be more interested in them precisely because of their abstract, and therefore less transient, nature.}

Limiting the scope of our discussion to objects and properties that are well defined physically is also not enough. For example, \emph{``the electron is green"} or \emph{``1 meter is equal to 5 Kelvin"} are still not suitable scientific statements as the relationships established are not physically meaningful. Even when the relationship is meaningful, we may still not be able to validate it experimentally. For example, \emph{``there is no extra-terrestrial life"} or \emph{``the mass of the electron is exactly $9.109 \times 10^{-31}$ kg"} are not statements that can be verified in practice. In the first case, we would need to check every corner of the universe and find none, with the closest galaxy like ours, Andromeda, being 2.5 million light-years away; in the second case, we will always have an uncertainty associated with the measurement, however small.

So we have to narrow the scope to those and only those statements that can be verified experimentally. That is, we have to provide an experimental test: a repeatable experimental procedure (i.e. evidence based) that anyone (i.e. universal) can in principle execute and obtain consistent results (i.e. non-contradictory). This is both the power and the limit of scientific inquiry: it gives us a way to construct a coherent description of the physical world but it is limited to those aspects that can be reliably studied experimentally.

\begin{mathSection}
\begin{axiom}\label{ax_verifiable_statements}
	A \textbf{verifiable statement} is a statement that can be shown to be true experimentally. Formally, a statement $\stmt$ is verifiable if it is part of the subset $\stmt \in \vstmtSet \subset \stmtSet$ of all verifiable statements.
\end{axiom}
\begin{justification}
	To give a better justification for this and later axioms, we introduce the following pseudo-mathematical concepts. An \textbf{experimental test} $\expt$ is a repeatable procedure (i.e. it can be restarted and stopped at any time) that anybody can execute and will always either terminate successfully, terminate unsuccessfully or never terminate. We can assume it to be an element of the set $\mathcal{E}$ of all experimental tests upon which is defined a function $\result: \mathcal{E} \to \{\SUCCESS, \FAILURE, \UNDEF\}$. The idea is that if a statement is verifiable we can find an experimental test $\expt$ that always succeeds if the statement is true, and the statement is true if the experiment always succeeds.
	
	To precisely define this relationship, we would have to link the possible truth of the statements with possible results of the experimental tests. This would not provide additional insight so we leave the idea of experimental tests informal and we use them only as part of the justifications.
\end{justification}
\end{mathSection}

Experimental tests are the second and last building block of our general mathematical theory of experimental science. As with statements, any language (e.g. natural, formal, engineering drawings, computer programs, ...) can in principle be used to describe the procedure, which can be arbitrarily complicated. It may require building detectors, gathering large amounts of data and performing complicated computations. We are not going to care how these procedures are described, just that it is done in a way that allows us to execute the test.\footnote{Trying to formalize a universal language for experimental tests is not only impractical but also conceptually problematic. To know what we can test experimentally is to know what is physically possible, which is equivalent to knowing the laws of physics, which is what we are trying to construct a framework for.}

As an example, consider the following procedure:
\begin{enumerate}
	\item find a swan
	\item if it's black terminate successfully
	\item go to step 1
\end{enumerate}
If a black swan exists, at some point we'll find it and the test will be successful. If a black swan does not exist, then the procedure will never terminate and the result is undefined. This is something anybody can do and will always provide the same result: it is an experimental test. It also terminates successfully if and only if a black swan exists, so the statement \statement{black swans exist} is verifiable.

Note that, in principle, science can also study statements that can be refuted experimentally. But the negation of those is a statement that can be verified experimentally. Therefore we lose nothing by only focusing on verification.\footnote{Mathematically, the spaces of verifiable statements and refutable statements are dual to each other.}

In the previous section we saw that we can combine statements into new statements. How about verifiable statements? Can we always combine verifiable statements into other verifiable statements? Since all truth functions can be constructed from the three basic Boolean operations, the question becomes: can we construct experimental tests for the negation, conjunction and disjunction of verifiable statements?

The first important result is that the negation of an experimental test, an experimental test that is successful when the first is not successful, does not necessarily exist. Consider our black swan example, an experimental test for the negation would be a procedure that terminates successfully if black swans do not exist. But the given procedure never finishes in that case, so it is not just a matter of switching success with failure. Because of non-termination, not-successful does not necessarily mean failure.\footnote{In this case, the old adage ``absence of evidence is not evidence of absence" applies.} Moreover, it is a result of computability theory that some problems are undecidable: they do not allow the construction of an algorithm that always terminates with a correct yes-or-no answer. So we know that in some cases this is not actually possible.

In the same vein we are able to confirm experimentally that \statement{the mass of this particle is not zero} but not that \statement{the mass of this particle is exactly zero} since we always have uncertainty in our measurements of mass. Even if we could continue shrinking the uncertainty arbitrarily, we would ideally need infinite time to shrink it to zero. What this means is that not all answers to the same question can be equally verified. Is the mass of the photon exactly zero? We can either give a precise ``no" or an imprecise ``it's within this range." Is there extra-terrestrial life? We can either give a precise ``yes" or an imprecise ``we haven't found it so far."\footnote{Note that we are on purpose avoiding induction. It does not play any role in our general mathematical theory of experimental science since the decision of when and how to apply induction violates the principle of scientific objectivity.}

\begin{mathSection}
	\emph{Remark}. The \textbf{negation or logical NOT} of a verifiable statement is not necessarily a verifiable statement.
\end{mathSection}

While this is true in general, we can still test the negation of many verifiable statements. Consider the statement \statement{this swan is black}. It allows the following experimental test:
\begin{enumerate}
	\item look at the swan
	\item if it's black terminate successfully
	\item terminate unsuccessfully
\end{enumerate}
Note that, since the test always terminates, we can switch failure to success and vice-versa. In this case we can test the negation and we say that the statement is decidable: we can decide experimentally whether it is true or false. It is precisely when and only when the test is guaranteed to terminate, that we can test the negation.

\begin{mathSection}
	\begin{defn}
		A \textbf{decidable statement} is a statement that can be shown to be either true or false experimentally. Formally, a statement $\stmt$ is decidable if $\stmt \in \vstmtSet$ and $\NOT\stmt \in \vstmtSet$. We note $\dstmtSet$ the set of all decidable statements.
	\end{defn}
	\begin{justification}
		Note that the informal definition is slightly different from the formal one. In the first one we have a single statement associated with a single experimental test that always terminates, either successfully or unsuccessfully depending on the truth of the statement. In the second we have two statements, one the negation of the other, and two experimental tests, each of them only guaranteed to terminate successfully if the respective statement is true. We can give a pseudo-proof, though, to show that these are equivalent.

		Let $\stmt \in \mathcal{S}$ be a decidable statement and $\expt \in \mathcal{E}$ an experimental test that verifies whether the statement is true or false. Consider the procedure $\expt_\NOT(\expt)$ defined as follows:
		\begin{enumerate}
			\item run test $\expt$
			\item if $\expt$ is unsuccessful terminate successfully
			\item if $\expt$ is successful terminate unsuccessfully.
		\end{enumerate}
		Since $\expt$ is repeatable and can be executed by anybody, $\expt_\NOT(\expt)$ is also repeatable and can be executed by anybody. Since $\stmt$ is decidable, $\expt$ always terminates and therefore $\expt_\NOT(\expt)$ always terminates.  Therefore $\expt_\NOT(\expt)$ is an experimental test such that $\truth(\stmt)=\FALSE$ if and only if $\result(\expt_\NOT(\expt))=\SUCCESS$. Which means $\truth(\NOT\stmt)=\TRUE$ if and only if $\result(\expt_\NOT(\expt))=\SUCCESS$ and $\NOT\stmt$ is verifiable.
		
		Let $\stmt \in \mathcal{S}$ be a verifiable statement such that $\NOT\stmt$ is also verifiable. Let $\expt, \expt_\NOT \in \mathcal{E}$ be their respective experimental tests. We have to be careful as $\expt$ and $\expt_\NOT$ may not terminate. Consider the procedure $\hat{\expt}$ defined as follows:
		\begin{enumerate}
			\item initialize $n$ to 1
			\item for each $i=1..n$
			\begin{enumerate}
				\item run the test $\expt$ for $n$ seconds
				\item if $\expt$ is successful, return successfully
				\item run the test $\expt_\NOT$ for $n$ seconds
				\item if $\expt_\NOT$ is successful, return unsuccessfully
			\end{enumerate}
			\item increment $n$ and go to step 2
		\end{enumerate}
	    The procedure is repeatable and can be executed by anybody. Both $\expt$ and $\expt_\NOT$ are eventually run an arbitrarily long amount of time. If $\stmt$ is true, $\expt$ will eventually terminate successfully and $\hat{\expt}$ will do so as well. If $\stmt$ is false, $\expt_\NOT$ will eventually terminate successfully making $\hat{\expt}$ terminate unsuccessfully. Therefore $\stmt$ is decidable.
	\end{justification}

\end{mathSection}

Decidable statements are not critical elements of our theory. We introduce them here because their definition and related axiom clarify what happens during negation. They will be used again only much later when talking about discrete quantities.

Combining verifiable statements with conjunction (i.e. the logical AND) is more straightforward. If we are able to verify that \emph{``that animal is a swan"} and that \emph{``that animal is black"}, we can verify that \emph{``that animal is a black swan"} by verifying both. If the tests for both are successful, then the test for the conjunction is successful. That is, if we have two or more verifiable statements, we can always construct an experimental test for the logical AND by running all tests one at a time and check if they are successful. Yet, the number of tests needs to be finite or we would never terminate, so we are limited to the conjunction of a finite number of verifiable statements.

\begin{mathSection}
	\begin{axiom}\label{ax_verifiable_AND}
	The conjunction of a finite collection of verifiable statements is a verifiable statement. Formally, let $\{\stmt_i\}_{i=1}^{n} \subseteq \vstmtSet$ be a finite collection of verifiable statements. Then the conjunction $\bigAND\limits_{i=1}^{n} \stmt_i \in \vstmtSet$ is a verifiable statement.
	\end{axiom}
	\begin{justification}
		Mathematically, we are simply assuming that the finite conjunction exists, so in principle there is nothing to prove. However, we want to show that the axiom is well justified in practice.
		
		Let $\{\stmt_i\}_{i=1}^{n} \subseteq \vstmtSet$ be a finite collection of verifiable statements. Then we can find a corresponding set of experimental tests $\{\expt_i\}_{i=1}^{n} \subseteq \exptSet$ that terminate successfully if and only if the statements are true. Let $\bigAND\limits_{i=1}^{n} \expt_i$ be the experimental procedure defined as follows:
		\begin{enumerate}
			\item for each $i=1..n$ run the test $\mathsf{e}_i$
			\item if all tests terminate successfully then terminate successfully.
		\end{enumerate}
		The experimental procedure so defined is repeatable, can be executed by anybody and terminates successfully if and only if all $\mathsf{e}_i$ terminate successfully. This means it terminates successfully if and only if all $\{\stmt_i\}_{i=1}^{n}$ are true, which is when $\bigAND\limits_{i=1}^{n} \stmt_i$ is true. This means the experimental procedure defined above is a suitable test for the conjunction so the conjunction is verifiable.
		
		Note that this cannot be generalized to infinite collections as the procedure would not be guaranteed to terminate.
	\end{justification}
\end{mathSection}	

Combining verifiable statements with disjunction (i.e. the logical OR) is also straightforward. To verify that \emph{``the swan is black or white"} we can first test that \emph{``the swan is black"}. If that is verified that's enough: the swan is black or white. If not, we test that \emph{``the swan is white"}. That is, if we have two or more verifiable statements we can always construct an experimental test for the logical OR by running all tests and stopping at the first one that is successful. Because we stop at the first success, the number of tests can be countably infinite. As long as one test succeeds, which will always be the case when the overall test succeeds, it does not matter how many elements we are not going to verify later. But it cannot be more than countably infinite since the only way we have to find if one experimental test in the set is successful is testing them all one by one. Therefore we are limited to the disjunction of a countable number of verifiable statements.

\begin{mathSection}
	\begin{axiom}\label{ax_verifiable_OR}
	The disjunction of a countable collection of verifiable statements is a verifiable statement. Formally, let $\{\stmt_i\}_{i=1}^{\infty} \subseteq \vstmtSet$ be a countable collection of verifiable statements. Then the disjunction $\bigOR\limits_{i=1}^{\infty} \stmt_i \in \vstmtSet$ is a verifiable statement.
	\end{axiom}
	\begin{justification}
		Mathematically, we are simply assuming that the countable disjunction exists, so in principle there is nothing to prove. However, we want to show that the axiom is well justified in practice.
		
		In this case, we have to be careful to handle tests that may not terminate. Let $\{\stmt_i\}_{i=1}^{\infty} \subseteq \vstmtSet$ be a countable collection of verifiable statements. Then we can find a corresponding set of experimental tests $\{\expt_i\}_{i=1}^{\infty} \subseteq \exptSet$ that terminate successfully if and only if the statements are true.
		Let $\bigOR\limits_{i=1}^{\infty} \expt_i$ be the experimental procedure defined as follows:
		\begin{enumerate}
			\item initialize $n$ to 1
			\item for each $i=1..n$
			\begin{enumerate}
				\item run the test $\mathsf{e}_i$ for $n$ seconds
				\item if $\mathsf{e}_i$ terminates successfully then terminate successfully
			\end{enumerate}
			\item increment $n$ and go to step 2
		\end{enumerate}
		The procedure will eventually run all tests for an arbitrarily long amount of time. Suppose there exists an $i \geq 1$ such that $\mathsf{e}_i$ will terminate successfully. Then the above procedure will eventually run that test for a time long enough and terminate successfully. This means the procedure will terminate if and only if at least one of $\{\stmt_i\}_{i=1}^{\infty}$ is true, which is when $\bigOR\limits_{i=1}^{\infty} \stmt_i$ is true. This means the experimental procedure defined above is a suitable test for the disjunction so the disjunction is verifiable. 

		Note that this cannot be generalized to more than countable infinity as the procedure would not be guaranteed to eventually run all tests.
	\end{justification}
	\begin{prop}\label{prop_decidable_AND_OR}
		The conjunction and disjunction of a finite collection of decidable statements is decidable. Formally, let $\{\stmt_i\}_{i=1}^{n} \subseteq \dstmtSet$ be a finite collection of decidable statements. Then the conjunction $\bigAND\limits_{i=1}^{n} \stmt_i \in \dstmtSet$ and the disjuction $\bigOR\limits_{i=1}^{n} \stmt_i \in \dstmtSet$ are decidable statements.
	\end{prop}
\begin{proof}
	Let $\{\stmt_i\}_{i=1}^{n} \subseteq \dstmtSet$ be a finite collection of decidable statements. Then $\{\stmt_i\}_{i=1}^{n} \subseteq \vstmtSet$ and $\{\NOT\stmt_i\}_{i=1}^{n} \subseteq \vstmtSet$ are verifiable. Consider $\bigAND\limits_{i=1}^{n} \stmt_i$: this is the finite conjunction of verifiable statements and is therefore a verifiable statement by \ref{ax_verifiable_AND}. Consider its negation $\NOT \bigAND\limits_{i=1}^{n} \stmt_i \equiv \bigOR\limits_{i=1}^{n} \NOT \stmt_i$: this is the finite disjunction of verifiable statements and is therefore a verifiable statement by \ref{ax_verifiable_OR}. The finite conjunction of decidable statements is decidable by definition.
	
	Similarly, consider $\bigOR\limits_{i=1}^{n} \stmt_i$: this is the finite disjunction of verifiable statements and is therefore a verifiable statement by \ref{ax_verifiable_OR}. Consider its negation $\NOT \bigOR\limits_{i=1}^{n} \stmt_i \equiv \bigAND\limits_{i=1}^{n} \NOT \stmt_i$: this is the finite conjunction of verifiable statements and is therefore a verifiable statement by \ref{ax_verifiable_AND}. The finite disjunction of decidable statements is decidable by definition.
	
	Note that this cannot be generalized to infinite collection as it would require closure under infinite conjunction. Also note that this result is consistent with the experimental tests given in \ref{ax_verifiable_AND} and \ref{ax_verifiable_OR}.
\end{proof}
\end{mathSection}

Taken as a whole, finite conjunction and countable disjunction define the \textbf{algebra of verifiable statements}. It is limited compared to the algebra of statements and it tells us that, in practice, we are not going to be able in general to construct an experimental test whose success is an arbitrary function of the success of other tests.

\begin{table}[h]
	\centering
\begin{tabular}{p{0.14\textwidth} p{0.08\textwidth} p{0.13\textwidth} p{0.22\textwidth} p{0.23\textwidth}}
	Operator & Gate & Statement & Verifiable Statement & Decidable Statement  \\ 
	\hline 
	Negation & NOT & allowed & disallowed & allowed \\ 
	Conjunction & AND & arbitrary  & finite & finite \\ 
	Disjunction & OR & arbitrary  & countable & finite \\ 
\end{tabular}
	\caption{Comparing algebras of statements.}
\end{table}

Before we continue, it is interesting and useful to stop and understand the interplay between scientific and mathematical constructs.\footnote{It took us many many confusing years to fully understand where the scientific argument ends and the mathematical argument begins, what makes sense to assume physically and what makes sense to prove rigorously. Part of the confusion is that this line is not objective but it is based on what is considered ``precise" by a mathematician, which has evolved considerably through the centuries. The rule we follow is: in the mathematical formalism the only objects that can be left unspecified are the elements of a set.} Technically, definitions \ref{ax_statement}, \ref{ax_possibilities}, \ref{ax_functions_of_statement}, \ref{ax_verifiable_statements}, \ref{ax_verifiable_AND} and \ref{ax_verifiable_OR} are the axioms of our mathematical formalism for statements. Note that the actual content of the statements and the procedure for their verification are not formally defined: the math treats them simply as a label that we use for identification. The only assumptions are that statements exist (each with a set of possible truth values and an actual truth value), that some of them are verifiable and that they both admit the associated algebra. The mathematical formalism does not know what these objects actually are: they may as well be pieces of cardboard painted black or white. Therefore the math does not know whether the properties we assigned make actual sense: it can only guarantee their non-contradiction. In other words, the way that we are making the framework precise is not by making everything precise: it is by omitting the details that are not amenable to a precise specification.

We should stress this for a couple of reasons. First, the part that is not formalized is \emph{the most important part}. Discovering new science is exactly finding new things to study (i.e. new statements) or devising new measurement techniques (i.e. new experimental tests). The content of the statements and the procedure of the experimental tests \emph{is} the actual science. Everything that follows is, in a sense, the trivial bit and that is why it can be done generally. Which leads to the second reason: understanding whether statements and verifiable statements \emph{actually} follow the algebras we defined is crucial. The math just takes it at face value, it does not prove it. The justifications for our axioms, then, are the most critical part of this work and they are not mathematical proofs. If we botch them, we'll have a nice, consistent, rich but meaningless mathematical framework. Lastly, it has to be clear that something gets lost in the formalization. The mathematical framework cannot carry all the physics content: we removed the most important part! Different systems may have the same mathematical description, so the scientific content can never be entirely reconstructed from the math. That is why we always have to carefully bring it along.

Now that we have characterized verifiable statements we want to understand how to characterize groups of them. Consider the verifiable statements
\begin{description}
	\item \statement{that animal is a duck}
	\item \statement{that animal is a swan}
	\item \statement{that animal is white}
	\item \statement{that animal is black}
	\item \statement{that animal is a black swan}
	\item \statement{that animal is a white duck}
	\item \statement{that animal is a duck or a swan}
\end{description}
Since some are functions of others, we do not need to actually run all the tests. Once we have tested the first four we have gathered enough information for the others. We call this set a basis.\footnote{The term basis is used in general to define a set of objects from which, through a series of operations, one can construct the full space. It is the same for a vector space: from a basis one can construct any other vector through linear combination. What changes is what objects are combined and what operations are used.}

\begin{mathSection}
	\begin{defn}
		Given a set $\edomain$ of verifiable statements, $\basis \subseteq \edomain$ is a \textbf{basis} if the truth values of $\basis$ are enough to deduce the truth values of the set. Formally, all elements of $\edomain$ can be generated from $\basis$ using finite conjunction and countable disjunction.
	\end{defn}
\end{mathSection}

Note that once we have tested the basis, we have tested any other verifiable statement that can be constructed from it. In the example before, once we tested the first four we have implicitly tested \statement{that animal is a black duck}. It is also true that contradictions and tautologies don't really need to be tested. We already know that \statement{that animal is a duck and a swan} is false. The idea, then, is to group verifiable statements into experimental domains that can be seen as all the experimental information one can gather for a particular subject. These will include the tautology, the contradiction and any other verifiable statement that can be constructed from a basis. The basis, though, has to be countable so that, by running one test at a time, we can hope to eventually reach any element.

\begin{mathSection}
\begin{defn}
	An \textbf{experimental domain} $\edomain$ represents all the experimental evidence that can be acquired about a scientific subject in an indefinite amount of time. Formally, it is a set of statements, closed under finite conjunction and countable disjunction, that includes precisely the tautology, the contradiction, and a set of verifiable statements that can be generated from a countable basis.
\end{defn}
\begin{justification}
	As usual, let's make sure the formal definition is consistent with the informal one. The set consists only of verifiable statements, which can be tested experimentally, and the tautology and contradiction, which don't need to be verified experimentally. Functions of verifiable statements represent experimental evidence about the same subject, therefore it is appropriate that the experimental domain is closed under finite conjunction and countable disjunction. Given that each test terminates successfully in a finite amount of time, we can only test a countable set in an indefinite amount of time. Therefore, if the experimental domain didn't allow for a countable basis, we would always have verifiable statements we would never be able to test.
\end{justification}
\end{mathSection}

We can think of an experimental domain as the enumeration of all possible verifiable answers to a scientific question. For example, the domain related to the question ``what is that animal?" would include \emph{``it is a mammal"}, \emph{``it is a dog"}, \emph{``it is an animal with feathers"} and so on. If two statements are possible answers to that question, then their conjunction and disjunction will also be possible answers. For example: \emph{``it is a dog or a cat"} or \emph{``it is a mammal and it lays eggs"}.

While each statement only needs finite time to be verified, we allow indefinite time for the domain because we want to capture those questions that can be answered only approximately. The idea is that, given more time, we can always get a better answer so, in principle, we have an infinite sequence of tests to perform and continue indefinitely.

The basis not only serves as a way to constrain the size of the experimental domain, but most of the time it will also serve to define the experimental domain itself. We will typically start by characterizing a set of verifiable statements (e.g. a set of characteristics of animals and how to identify them) and then consider the domain of all the verifiable statements that can be constructed from them (e.g. the set of all animals and groups of animals we can identify).

\section{Theoretical domains and possibilities}

The basis for an experimental domain allows us to create a procedure that will eventually test any verifiable statement. But to fully characterize a domain we want to find those statements, like \statement{that animal is a cat} or \statement{the mass of the photon is exactly 0 eV}, that, if true, determine the truth value of all other verifiable statements in the domain. The main result of this section is that these statements, which we call possibilities for the domain, are not necessarily verifiable themselves. We will therefore need to introduce theoretical domains which consist of those statements we can use to give predictions for an experimental domain. We will also be able to conclude that the set of possibilities for an arbitrary experimental domain has at most the cardinality of the continuum, thus putting a hard constraint on what type of mathematical objects are useful in science.

Suppose $\edomain_X$ is the domain of animal species identification. It will contain verifiable statements such as \statement{that animal has feathers}, \statement{that animal has claws}, \statement{that animal has paws}. Some statements are broader and some are narrower. But some statements, like \statement{that animal is a swan} or \statement{that animal is a duck}, are special because if we verify those then we are able to know which other statements are true or false. Once we verify those we are essentially done. These are what we call the possibilities of the domain and enumerating them means characterizing the experimental domain.

Unfortunately, not all possibilities are verifiable statements. Consider the statements $s_1=$\statement{there is extra-terrestrial life} and $s_2$=\statement{there is no extra-terrestrial life}. We can create an experimental test for the first (i.e. find extra-terrestrial life somewhere) but not for the second (it would require us to check every place in the universe which is something we cannot do). So, for this question, the experimental domain $\edomain_X = \{s_1, \tautology, \contradiction\}$ is composed of the first statement, the tautology and the contradiction. But $s_2$ is conceptually still one of the possibilities: if true we have a complete answer for the domain.

What happens is that while the negation of a verifiable statement is not always a verifiable statement, it is still a statement that can be used to characterize the outcome of some experimental test. While we cannot verify non termination of an experimental test, we can still predict it. To be able to find all possibilities, then, we have to create the set of statements that can be used to make predictions which include negations. We call this set the theoretical domain and theoretical statements its elements.

\begin{mathSection}
\begin{defn}
	The \textbf{theoretical domain} $\tdomain$ of an experimental domain $\edomain$ is the set of statements that we can use to state predictions, which is constructed from $\edomain$ by allowing negation. We call \textbf{theoretical statement} a statement that is part of a theoretical domain. More formally, $\tdomain$ is the set of all statements generated from $\edomain$ using negation, finite conjunction and countable disjunction.
\end{defn}
\end{mathSection}

Because of its construction, the theoretical domain will also include all the limits of all the sequences of verifiable statements. Consider the experimental domain for the mass of the photon. It will contain verifiable statements such as
\begin{description}
	\item $\stmt_1$ =\statement{the mass of the photon is smaller than $10^{-1}$ eV}
	\item $\stmt_2$ =\statement{the mass of the photon is smaller than $10^{-2}$ eV}
	\item $\stmt_3$ =\statement{the mass of the photon is smaller than $10^{-3}$ eV}
	\item ...
\end{description}
It will not contain the statement $\stmt=$\statement{the mass of the photon is exactly 0 eV}, though, as we cannot measure a continuous quantity with infinite precision.

Note $\stmt$ can be seen as the limit of the sequence of ever increasing precision, but can also be seen as the conjunction for all those statements $\stmt=\bigAND\limits_{i=1}^{\infty} \stmt_i$. In fact, the mass of the photon is exactly 0 if and only if all the finite precision measurements will contain 0 in the range. It makes sense, then, that it is not part of the experimental domain because only finite conjunctions of verifiable statements are verifiable. But we expect $\stmt$ to be a possibility for the mass of the photon. Why should it be in the theoretical domain?

Because of the De Morgan properties in \ref{boolean_properties}, we can express conjunctions in terms of negation and disjuction. So we have $\stmt=\bigAND\limits_{i=1}^{\infty} \stmt_i=\NOT \bigOR\limits_{i=1}^{\infty} \NOT\stmt_i$. Therefore by allowing negation we are also allowing countable conjunction and therefore we are including all the limits of sequences of verifiable statements.

% Not being used at this point, but keep around to cannibalize later. As we saw before, not all possibilities are verifiable statements. For example, if we are able to only verify \statement{there is extra-terrestrial life}, the opposite possibility will never have experimental confirmation. The possibility \statement{the mass of the photon is exactly 0 eV} is also not verifiable since we can only measure mass with finite precision. The second case, though, is different from the first. Given two different values of mass, we can in principle always find a resolution such that we can tell the two values apart experimentally. Similarly, we can tell the house sparrow (Passer domesticus) apart from the Italian sparrow (Passer italiae) because we have at least two verifiable statements (``it has a dark gray crown", ``it has a chestnut crown") that are incompatible with each other, but each compatible with one bird. In these cases, we say that the domain is experimentally distinguishable.

\begin{mathSection}
	\begin{prop}
		All theoretical domains are closed under countable conjunction.
	\end{prop}
	
	\begin{proof}
		Any countable conjunction $\mathsf{s} = \bigAND\limits_{i=1}^{\infty} \mathsf{s}_i$ is equivalent to the negation of disjunction of the negation: $\mathsf{s} = \NOT\bigOR\limits_{i=1}^{\infty} \NOT\mathsf{s}_i$. As the theoretical domain is closed under negation and countable disjunction, so it is closed under countable conjunction.  
	\end{proof}

	\begin{defn}\label{def_approximately_verifiable}
		A theoretical statement $\stmt \in \tdomain$ is \textbf{approximately verifiable} if it is the limit of some sequence of verifiable statements. Formally, if there exists a sequence $\{\obs_i\}_{i=1}^{\infty} \in \edomain$ such that $\stmt = \bigAND\limits_{i=1}^{\infty} \obs_i$.
	\end{defn}
\end{mathSection}

Note that not all theoretical statements can be approximated with a sequence of verifiable statements. Consider $\stmt=$\statement{the mass of the photon is rational as expressed in eV}. It is the disjunction of all possibilities with rational numbers, which is countable, and therefore is a theoretical statement. Any finite precision version of this statement will always cover all possible values since any finite range will include infinitely many rational (and irrational) numbers. This means we cannot construct a sequence of finite precision verifiable statements that, in the limit, will correspond to $\stmt$. It also means we predict non termination when trying to experimentally verify $\stmt$ or its negation. Therefore we have to be cautious in giving physical significance to all theoretical statements as the prediction for some is that they may not be established experimentally.

Also note that we are closed under countable operations and not arbitrary. Therefore there could be statements that can be constructed from verifiable statements that are not even theoretical statements. Consider a set $U$ of possible mass values for a particle that is uncountable, has an uncountable complement, and where the elements are picked arbitrarily and not according to a simple rule.\footnote{Mathematically, we are looking for a set of real numbers that is not a Borel set.} The statement \statement{the mass of the particle expressed in eV is in the set $U$} can only be tested by checking each value individually. But since the set is uncountable and a procedure can only be made of countable steps, it will be impossible to construct a test for such a statement. It's not that the procedure to test may not terminate, like for a theoretical statement: it's that we can't even write the procedure in the first place.

To sum up, verifiable statements are the only ones that, perhaps under some simplifying assumption, we can think of as tangible scientific objects (e.g. the idea that we can measure mass with finite precision). From these we construct theoretical statements that represent our idealizations (e.g. the infinitely precise value for the mass of a particle or the idea that said value is a rational number expressed in a particular unit). And then there are statements that are not even physically meaningful as they have no well defined experimental consequences.\footnote{It will be a recurrent theme of this work to make a precise distinction between mathematical objects that represent physical entities (e.g. verifiable statements), those that represent idealizations of physical entities (e.g. theoretical statements) and those that do not have scientific standing (e.g. statements that are neither verifiable nor theoretical). The particular status of real numbers will be explored more precisely when discussing arbitrary precision quantities.}

While the theoretical domain contains more statements, it does not contain more information. That is, if we knew which verifiable statements are true and which aren't, we would automatically know which theoretical statements would be true or not. So it is not adding extra cases. It is essentially completing the list of answers by adding a ``no" if only ``yes" can be experimentally verified and vice-versa. To see that this is true, we can show that a basis for an experimental domain $\edomain$ is also a basis for its theoretical domain $\tdomain$. That is, all verifiable and theoretical statements can be expressed as functions of the same basis. The difference is that a theoretical statement can be a function of the negation of the element of a basis.

\begin{mathSection}
\begin{prop}
	The truth values of the statements of a basis $\basis$ for an experimental domain $\edomain$ are enough to determine the truth values for all statements in the associated theoretical domain $\tdomain$. More formally, all statements in the theoretical domain $\tdomain$ can be generated by negation, countable conjunction and countable disjunction from a basis $\basis$ of $\edomain$.
\end{prop}

\begin{proof}
	By definition of basis, any verifiable statement within the experimental domain $\edomain$ can be generated from $\basis$ using only finite conjunction and countable disjunction. The tautology may be generated through negation and disjunction from any verifiable statement therefore $\basis$ generates $\edomain$ which in turn generates $\tdomain$ by definition. This means that $\basis$, through negation, countable conjunction and countable disjunction, generates all of $\tdomain$.
\end{proof}
\end{mathSection}

Having defined what a theoretical domain is, we can finally define what the possibilities of a domain are: those statements that if known to be true determine the truth value of all other statements.

\begin{mathSection}

\begin{defn}
	A \textbf{possibility} for an experimental domain $\edomain$ is a statement $x \in \tdomain$ that, when true, determines the truth value for all statements in the theoretical domain. Formally, $x \nequiv \contradiction$ and for each $\mathsf{s} \in \tdomain$, either $x \narrower \mathsf{s}$ or $x \ncomp \mathsf{s}$. The \textbf{full possibilities}, or simply the \textbf{possibilities}, $X$ for $\edomain$ are the collection of all possibilities.
\end{defn}

\end{mathSection}

A possibility represents a complete answer for a scientific question. Only one of them can be true and one of them must be true since the theoretical domain contains all negations. But how can we construct them? Suppose $\edomain$ is the experimental domain for animal species identification. Suppose $\basis \subset \edomain$ is a basis of statements, like \statement{that animal has feathers}, \statement{that animal has claws}, \statement{that animal has paws} and so on, that allow us to fully identify the animal species. Consider a minterm, a conjunction where each statement appears once either negated or not. For example, \statement{that animal has feathers}$\AND$\statement{that animal has claws}$\AND\NOT$\statement{that animal has paws}$\AND$... . If that statement is true, it will determine the truth value of all the basis, and therefore of all verifiable statements. Then a possibility for the domain is simply a minterm of a basis.

\begin{mathSection}
	
\begin{prop}\label{prop_poss_is_minterm}
	Let $\edomain$ be an experimental domain. A possibility for $\edomain$ is any minterm of a basis that is not a contradiction.
\end{prop}

\begin{proof}
	Let $\basis \subseteq \edomain$ be a basis for $\edomain$. Let $x$ be a minterm of $\basis$. Any theoretical statement $\stmt \in \tdomain$ can be expressed as the disjunction of minterms of $\basis$ by \ref{prop_disjunctive_normal_form}. $x$ is either within the minterms needed to express $\stmt$, or not. If it is, $x \AND \stmt \equiv x$ and therefore $x \narrower \stmt$. If it's not, $x \AND \NOT \stmt \equiv x$ and therefore $x \ncomp \stmt$. Therefore a minterm is either narrower or incompatible with all theoretical statements and, if it is not a contradiction, it is a possibility by definition.
	
	Conversely, suppose $x \in \tdomain$ is a possibility. As it is a theoretical statement, it can be expressed as a disjunction of minterms of a basis $\basis$. Suppose it is the disjunction of more than one minterm. Then each minterm would be narrower than $x$, which cannot be. $x$ must be expressed by a single minterm. Therefore any possibility is a minterm.
\end{proof}

\begin{prop}[No other possibilities]
	All statements that determine and only determine the truth value of all statements in a theoretical domain $\tdomain$ are possibilities of $\edomain$. Formally, there is no statement $\stmt \in \stmtSet$ that has all the properties of a possibility except that $\stmt \notin \tdomain$.
\end{prop}

\begin{proof}
	Let $x \in \mathcal{S}$ be a statement that determines and only determines all truth values of all statements in a theoretical domain $\tdomain$. This is equivalent to determining the truth values and only the truth values of all elements of a basis $\basis \subseteq \edomain$. As we can find a countable basis, the statement $x$ is equivalent to the countable conjunction of statements of $\basis$ or their negation. Therefore $x \in \tdomain$ as it is generated by the statements of the basis by negation and countable conjunction. But a statement in $\tdomain$ that determines all truth values of the statements in $\tdomain$ is a possibility by definition. Therefore $x$ is a possibility.
\end{proof}
\end{mathSection}

There is one possibility that is often forgotten and sometimes needs special handling. Suppose one is trying to identify an illness by going through a series of known markers. It may happen that no match for the disease is found because we are dealing with a new kind of illness. In the same way, we may fail to identify a plant or animal from the standard taxonomy as we may have found a new species. In other words, it may be possible that none of our tests succeed and none of the verifiable statements is verified. We call this possibility the residual because it's what remains after we went through all the cases we already know.

Note, though, that the residual possibility does not exist for all domains. Suppose we have a basket of fruit and we want to count how many whole apples there are. There can only be a finite number of them, and we can successfully identify all finite numbers: there is no ``something else" to be found in this case.

\begin{mathSection}
	\begin{defn}
		The \textbf{residual possibility} $\mathring{x}$ for an experimental domain $\edomain$ is, if it exists, the possibility that predicts that no test will be successful. Formally, let $\basis \subseteq \edomain$ be a basis then  $\mathring{x} = \bigAND\limits_{\stmt[e] \in \basis} \NOT e$ if it is not a contradiction. An experimental domain is \textbf{complete} if it doesn't admit a residual possibility.
	\end{defn}

	\begin{defn}
	The \textbf{established possibilities} $\dot{X}=X\setminus\{\mathring{x}\}$ for an experimental domain is the set of all possibilities excluding the residual possibility.
\end{defn}
\end{mathSection}

As we refine our understanding and techniques for a domain of knowledge, we may find that the residual possibility actually corresponds to multiple cases that weren't previously cataloged. So, intuitively, it is better thought of as a bucket that contains all that is yet to be experimentally discovered within the particular domain of knowledge. Because of its special nature, the residual possibility sometimes behaves differently than the other possibilities. Therefore we will find that some theorems are more elegantly expressed in terms of the established possibilities and some in terms of the full possibilities.

With our definitions in mind, we can answer the following fundamental question: what is the maximum number of possibilities that an experimental domain can have? In other words: what is the maximum number of cases among which we can distinguish experimentally? As we saw before, a possibility is a statement that defines the truth values of a basis. Since a basis is countable, we can uniquely identify a possibility by a countable sequence of $\TRUE$ or $\FALSE$. Note that a real number expressed in a binary basis (e.g. 0.10110001...) will also be uniquely identified by such a sequence: the cardinality of the possibility is at most the one of the continuum.

\begin{mathSection}
	\begin{thrm}
		The possibilities $X$ for an experimental domain $\edomain$ have at most the cardinality of the continuum.
	\end{thrm}
	
	\begin{proof}
		Let $\basis = \{\obs[e]_i\}_{i=1}^{\infty} \subseteq \edomain$ be a countable basis. Let $2^{\mathbb{N}}$ denote the set of infinite binary sequences. We define the function $F:X\to2^{\mathbb{N}}$ such that $F(x) = \{F(x)_i\}_{i=1}^{\infty}$ is given by: 
		$$
		F(x)_i = 
		\begin{cases}
		1 & x \comp \obs[e]_i \\
		0 & x \ncomp \obs[e]_i
		\end{cases}
		$$
		For each $x \in X$ we have $x = \bigAND\limits_{i=1}^{\infty} \NOT^{F(x)_i} \obs[e]_i$. Suppose $x_1 \neq x_2$, then $F(x_1)_i \neq F(x_2)_i$ for some $i$, therefore $F$ is injective. We then have $|X| \leq |2^{\mathbb{N}}|=|\mathbb{R}|$. $X$ has at most the cardinality of the continuum.
	\end{proof}
\end{mathSection}

This means we have an upper bound on how many cases can be distinguished experimentally: only up to the continuum. We are not going to be able to tell apart experimentally more possibilities than those. This result gives us a basic requirement for any mathematical object we want to use in a scientific theory: if the cardinality is greater than the continuum, it cannot have a well defined experimental meaning. For example, while the set of all continuous functions between real numbers has the cardinality of the continuum, the set of all functions (including discontinuous ones) has greater cardinality. We can already conclude that the first set may be useful to represent physical objects and the second may not.

We have now presented the fundamental objects of our general mathematical theory of experimental science. In our framework, a ``scientific theory" or a ``scientific model" \emph{is} an experimental domain: a set of statements, what they mean and how to verify them experimentally.

The starting point is often a basis: a set of verifiable statements which defines all the domain knowledge that we can gather experimentally. The content of the statements determines what combinations can be true at the same time, which defines the possibilities for our domain. Everything in the domain is grounded within the verifiable statements: there is nothing else in it. This also maps well to the practice of most scientific fields, where one defines states and other physical objects based on what can be measured.

As we'll see later, some verifiable statements may be idealizations. For example, we may assume that a quantity can be measured with arbitrary level of precision, which we know not to be strictly true. We may assume a volume of gas to have a well defined temperature, which we know not be true if it is not at equilibrium. This type of simplification makes a domain applicable only within the realm of validity of those idealizations, but does not change the formal structure we have identified here. In fact, the focus of much of this work will be deriving the details of different experimental domains under different physical assumptions.

The main point of our framework is that this conceptual structure is inescapable once we set the principle of scientific objectivity. We will always need a set of statements and a way to test them and, if we are given those, we have all we need. These elements are necessary and sufficient to be able to do science. And by being clear about which statements can be considered physically meaningful, and which are an idealization, we can then be more precise on the physical status of each component of a particular scientific theory.

\section{Topological spaces}

Now that we have defined what experimental domains are, we want to explore the link between them and some fundamental mathematical structures. The main result of this section is that an experimental domain provides a natural topology for its possibilities. Each verifiable statement can be seen as the disjunction of a set of possibilities. Performing finite conjunction and countable disjunction of verifiable statements means performing finite union and countable intersection on those sets of possibilities.

Topological spaces were developed in the first half of the 1900s as a generalization of metric spaces. The idea is to define a notion of closeness without having to define an actual distance.\footnote{In science and engineering, one talks about topology also when discussing the structure of a molecule, an electronic circuit or a computer network. These types of structures (i.e. nodes connected by vertices) are studied by graph theory and should not be confused with point-set topology.} Other branches of math (e.g. metric spaces, differential geometry, Lie algebras) now see their foundation on topological spaces, which therefore play a very important role in mathematics as a whole. In our case, this notion of closeness will map to how hard it is to tell possibilities apart. That is, possibilities that are topologically closer are more difficult to distinguish experimentally.

Let's first review what a topology is. The general idea is that we have a set $X$ of elements, which we call points, and a collection of subsets of $X$ such that it is closed under finite intersection and arbitrary union, contains the empty set and contains the whole set $X$. For example, suppose $X=\{1,2,3\}$ then $\{\{\}, \{1\}, \{2\},\{1,2,3\}\}$ is not a topology while $\{\{\}, \{1\}, \{2\},\{1,2\},\{1,2,3\}\}$ is. The first one is missing the union of $\{1\}$ and $\{2\}$.

\begin{mathSection}
	\begin{defn}
		Let $X$ be a set. A \textbf{topology} on $X$ is a collection $\mathsf{T}_X$ of subsets of $X$ closed under finite intersection and arbitrary union such that it contains $X$ and $\emptyset$. A \textbf{topological space} is a tuple $(X, \mathsf{T}_X)$ of a set and a topology defined on it.
	\end{defn}
\end{mathSection}

Mathematicians designed this abstract mathematical structure because it is a useful and general tool to study the notion of continuity. It also happens that all the mathematical structures used in science are topological spaces. Why is that? What is it that topological spaces capture?

Let's go back to our verifiable statements and possibilities. For example, consider $\stmt_1=$\statement{the mass of the photon is less than $10^{-10}$ eV}. This can be expressed as $\stmt_1=\bigOR\limits_{0\leq x<10^{-10}}$\statement{the mass of the photon is precisely x eV}: the precise value must be in the given range of possibilities. Consider $\stmt_2=$\statement{the mass of the photon is greater than $10^{-20}$ eV}$=\bigOR\limits_{x>10^{-20}}$\statement{the mass of the photon is precisely x eV}. The conjunction is the intersection of the possible values: $\stmt_1\AND\stmt_2=$\statement{the mass of the photon is between $10^{-20}$ and $10^{-10}$ eV}$=\bigOR\limits_{10^{-20}< x<10^{-10}}$\statement{the mass of the photon is precisely x eV}. The disjunction is the union of the possible values: $\stmt_1\OR\stmt_2=$\statement{the mass of the photon can be anything}$=\bigOR\limits_{x\geq0}$\statement{the mass of the photon is precisely x eV}.

This is something that works in general. In Proposition \ref{prop_disjunctive_normal_form} we saw that, if a statement is a function of other statements, it can be expressed as the disjunction of minterms of the arguments. A verifiable statement is a function of basis, so it can be expressed as the disjunction of minterms of a basis. But we have also seen that the minterms of a basis are the possibilities, so each verifiable statement can be expressed as the disjunction of possibilities.


Therefore each statement in the experimental domain defines a set of possibilities, which we call a verifiable set. Since tautology and contradiction are in the domain, the empty set and the full set of possibilities are verifiable sets. Since we can take finite conjunction and countable disjunction of verifiable statements, we can take finite intersection and countable union of verifiable sets. The collection of all verifiable sets forms a topology on the set of possibilities.

\begin{mathSection}
	
\begin{defn}
	Let $\edomain$ be an experimental domain and $X$ its possibilities. We define the map $U : \edomain \rightarrow 2^X$ that for each statement $\obs \in \edomain$ returns the set of possibilities compatible with it. That is: $U(\obs)\equiv\{ x \in X \, | \, x \comp \obs\}$. We call $U(\obs)$ the \textbf{verifiable set} of possibilities associated with $\obs$.
\end{defn}

\begin{prop}
	A statement $\obs \in \edomain$ is the disjunction of the possibilities in its verifiable set $U(\obs)$. That is, $\obs=\bigOR\limits_{x \in U(\obs)} x$.
\end{prop}
\begin{proof}
	First we show each statement is the disjunction of some set of possibilities. Let $\edomain$ be an experimental domain, $\obs \in \edomain$ a verifiable statement and $\basis \subseteq \edomain$ a basis. Since $\obs$ is a function of the basis, it can be expressed as a disjunction of minterms of $\basis$. The minterms of $\basis$ that are contradictions can be ignored since $\obs \OR \contradiction \equiv \obs$. But the minterms of $\basis$ that are not contradictions are possibilities of $\edomain$ so $\obs=\bigOR\limits_{x \in U} x$ for some $U \subseteq X$.
	
	Now we show it is the disjunction of its verifiable set. Let $x \in X$ be a possibility and consider $x \AND \obs$. If $x\in U$ then $x \AND \obs = x \AND \bigOR\limits_{\hat{x} \in U} \hat{x} = \bigOR\limits_{\hat{x} \in U} ( x \AND \hat{x}) \equiv x \nequiv \contradiction$. Therefore $x \comp \obs$. If $x \notin U$ then $x \AND \obs \equiv \contradiction$. Therefore $x \ncomp \obs$. This means $U=U(\obs)$ as it contains and only contains all the possibilities compatible with $\obs$.
\end{proof}

\begin{prop}
	Let $X$ be the set of possibilities for an experimental domain $\edomain$. $X$ has a natural topology given by the collection of all verifiable sets $\mathsf{T}_X=U(\edomain)$.
\end{prop}

\begin{proof}
	The verifiable sets for the tautology and the contradiction correspond to the full set and empty set respectively. Formally, $U(\tautology) = \{ x \in X \, | \, x \comp \tautology\} = X$ while $U(\contradiction) = \{ x \in X \, | \, x \comp \contradiction\} = \emptyset$. Therefore $X, \emptyset \in U(\edomain)$ since $\tautology, \contradiction \in \edomain$.

	The finite intersection of verifiable sets corresponds to the verifiable set of the finite conjunction and therefore it is a verifiable set. Formally, $U(\obs_1\AND\obs_2) = \{ x \in X \, | \, x \comp (\obs_1\AND\obs_2)\} =  \{ x \in X \, | \, x \comp \obs_1 \, and \, x \comp \obs_2\} = \{ x \in X \, | \, x \comp \obs_1\} \cap \{ x \in X \, | \, x \comp \obs_2\} = U(\obs_1) \cap U(\obs_2)$.

	The countable union of verifiable sets corresponds to the verifiable set of the countable disjunction and therefore it is a verifiable set. Formally, $U(\obs_1\OR\obs_2) = \{ x \in X \, | \, x \comp (\obs_1\OR\obs_2)\} =  \{ x \in X \, | \, x \comp \obs_1 \, or \, x \comp \obs_2\} = \{ x \in X \, | \, x \comp \obs_1\} \cup \{ x \in X \, | \, x \comp \obs_2\} = U(\obs_1) \cup U(\obs_2)$. This generalizes to countable disjunctions. Arbitrary disjunctions can be re-expressed as countable disjunctions, since any verifiable statement can always be expressed in terms of a countable basis.

	The collection $\mathsf{T}_X=U(\edomain)$ is therefore a topology by definition since it satisfies all its properties.
\end{proof}
\end{mathSection}

Mainly for historical reasons, the sets in a topology are called open sets. The complements of open sets are called closed sets. In metric spaces, such as the Euclidean space with the standard topology, these will map to the standard notion of open and closed intervals. But, in general, they do not and this may lead to confusion. For example, if we take the integers with their standard topology, any subset is both open and closed.

Given that we are only interested in the natural topologies of possibilities, we are going to refer to the sets in our topology as verifiable sets and we will occasionally call refutable sets their complements. For example, when counting apples a subset of the integers is both verifiable and refutable: we can test whether the apple count is within or outside that set of possible numbers. While this terminology does not follow math convention, we find it more intuitive and meaningful in the context of this work.

We can also re-express the semantic relationships between statements in terms of set operations on the verifiable sets. For example, \statement{that animal is a cat} is narrower than \statement{that animal is a mammal} because the set of possibilities for which the first is true is a subset of the possibilities for which the second is true. Conversely, \statement{that animal is a cat} and \statement{that animal is a dog} are incompatible because the set of possibilities in which both are true is empty.

In the following table we summarize how statement operations and relationships are expressed in terms of operations and relationships between sets of possibilities.

\begin{table}[h]
	\centering
	\begin{tabular}{p{0.075\textwidth} p{0.275\textwidth} p{0.2\textwidth} p{0.3\textwidth}}
		& Statement relationship & & Set relationship  \\ 
		\hline 
		$\stmt_1 \AND \stmt_2$ & (Conjunction) & $U(\stmt_1) \cap U(\stmt_2)$ & (Intersection) \\ 
		$\stmt_1 \OR \stmt_2$ & (Disjunction) & $U(\stmt_1) \cup U(\stmt_2)$ & (Union) \\ 
		$\NOT \stmt$ & (Negation) & $U(\stmt)^C$ & (Complement) \\ 
		$\stmt_1 \equiv \stmt_2$ & (Equivalence) & $U(\stmt_1) = U(\stmt_2)$ & (Equality) \\ 
		$\stmt_1 \narrower \stmt_2$ & (Narrower than) & $U(\stmt_1) \subseteq U(\stmt_2)$ & (Subset) \\ 
		$\stmt_1 \broader \stmt_2$ & (Broader than) & $U(\stmt_1) \supseteq U(\stmt_2)$ & (Superset) \\ 
		$\stmt_1 \comp \stmt_2$ & (Compatibility) & $U(\stmt_1) \cap U(\stmt_2) \neq \emptyset$ & (Intersection not empty)
	\end{tabular} 
	\caption{Correspondence between statement operators and set operators.}
\end{table}

Let's review the definition of basis and sub-basis for a topology: a collection of sets from which we can generate the whole topology through finite intersection and countable union (for a sub-basis) or just through countable union (for a basis). Bases are important since they are often used in proofs and calculations. Moreover, many properties of topologies can be shown to be equivalent to properties of one of their bases. Countability, and in particular second-countability, is one such property which characterizes the number of verifiable sets in the topology.

\begin{mathSection}
\begin{defn}
	A collection $\mathcal{B} \subseteq \mathsf{T}_X$ of verifiable sets of $X$ is a \textbf{sub-basis} if every verifiable set in $X$ is the union of finite intersections of $\mathcal{B}$. It is a \textbf{basis} if every verifiable set in $X$ is the union of elements of $\mathcal{B}$.
\end{defn}
\begin{defn}
	A topology for $X$ is \textbf{second-countable} if it admits a countable basis.
\end{defn}
\end{mathSection}

There is a link between the basis of an experimental domain and a sub-basis of a topology. If every statement in the experimental domain can be constructed from a basis through finite conjunction and countable disjunction, then each corresponding verifiable set can be generated through intersection and union of the verifiable set corresponding to the basis. Therefore the verifiable set corresponding to the basis of the experimental domain forms a sub-basis in the topology. Since experimental domains must have a countable basis to make sure we can test any verifiable statement given enough time, the topologies we'll be interested in must be second-countable.

\begin{mathSection}
	\begin{prop}
		Let $X$ be the set of possibilities of an experimental domain $\edomain$. Let $\basis \subseteq \edomain$ be a basis for the domain, then the collection of verifiable sets $U(\basis)\cup\{X\}$ forms a sub-basis for the natural topology of $X$.
	\end{prop}
	\begin{proof}
		Since every verifiable statement of a domain can be generated by finite conjunction and countable disjucntion from a basis $\basis \subseteq \edomain$, its corresponding verifiable set can be generated by finite intersection and countable union from the verifiable sets $U(\basis)$ corresponding to the basis. Note that the tautology, though, is not necessarily the union of $U(\basis)$: if the domain is not complete, the residual possibility is not contained in any verifiable sets. Therefore $U(\basis)\cup\{X\}$ can generate all verifiable sets, including the one for the tautology, and is a sub-basis.
	\end{proof}
	\begin{prop}
		The natural topology for the possibilities of an experimental domain is second-countable.
	\end{prop}
	\begin{proof}
		Since each experimental domain admits a countable basis, its verifiable sets form a countable sub-basis for the natural topology. We can close the sub-basis over finite intersection, forming a countable basis for the topology. The natural topology is therefore second-countable as it admits a countable basis.
\end{proof}
\end{mathSection}

Another important property to classify topological spaces is the degree of separation of their elements: how well one can use verifiable sets to tell points and sets apart. A Kolmogorov space is one in which for every pair of points there is always a verifiable set that contains one but not the other. This property is significant because it allows all points to be distinguished through verifiable sets. A Hausdorff space is one in which for every pair of points there are always two disjoint verifiable sets each containing one. It is significant because it implies the uniqueness of limits of sequences of points.

\begin{mathSection}
	\begin{defn}
		A topology for $X$ is \textbf{Kolmogorov} (or $\mathsf{T}_0$) if for every two elements $x_1, x_2 \in X$ there exists a verifiable set $U \in \mathsf{T}_X$ containing one element but not the other. That is: either $x_1 \in U$ while $x_2 \notin U$ or $x_1 \notin U$ while $x_2 \in U$.
	\end{defn}
	\begin{defn}
	A topology for $X$ is \textbf{Hausdorff} (or $\mathsf{T}_2$) if for every two elements $x_1, x_2 \in X$ there exist two disjoint verifiable sets $U_1, U_2 \in \mathsf{T}_X$ each containing one element. That is: $U_1 \cap U_2 = \emptyset$, $x_1 
	\in U_1$ and $x_2 \in U_2$.
\end{defn}

\end{mathSection}

How do these properties relate to experimental domains? Consider two possibilities for a domain, for example \statement{that is a cat} and \statement{that is a swan}. We can always find a verifiable statement, such as \statement{that animal has feathers}, that we can use to distinguish one possibility from the other. This means that, given two different possibilities, we can always find a verifiable set that contains one and not the other: the natural topology for any set of possibilities is always Kolmogorov.

Now suppose two possibilities are approximately verifiable as we defined in Definition \ref{def_approximately_verifiable}. For example, \statement{the mass of the photon is exactly 0 eV} or \statement{the mass of the photon is exactly $10^{-20}$ eV}. We can find two verifiable statements \statement{the mass of the photon is less than $10^{-25}$ eV} and \statement{the mass of the photon is more than $10^{-25}$ eV} that are incompatible with each other, but each compatible with one possibility. This means that, given two approximately verifiable possibilities, we can find two disjoint (i.e. incompatible) verifiable sets each containing one possibility: if all possibilities are approximately verifiable then the natural topology is Hausdorff.

\begin{mathSection}
	\begin{prop}
	The natural topology of a set of possibilities is Kolmogorov (or $\mathsf{T}_0$).
\end{prop}
\begin{proof}
	Let $X$ be the set of possibilities for an experimental domain $\edomain$. Let $x_1, x_2 \in X$ be two distinct possibilities. Each of them can be expressed as a minterm of a basis $\basis \subseteq \edomain$. Since the two possibilities are distinct, there must exist a verifiable statement $\obs[e] \in \basis$ that appears negated in one conjunction but not the other. That is, $\obs[e]$ is compatible with only one possibility. Since the verifiable set associated with a verifiable statement contains only the possibilities compatible with said statement, the verifiable set of $\obs[e]$ either contains $x_1$ or $x_2$ but not both. The topology is therefore Kolmogorov (or $\mathsf{T}_0$).
\end{proof}
	\begin{prop}
	The natural topology of a set of possibilities is Hausdorff (or $\mathsf{T}_2$) if and only if all possibilities are approximately verifiable.
\end{prop}
\begin{proof}
	Suppose all possibilities in $X$ for an experimental domain $\edomain_X$ are approximately verifiable. Let $x_1, x_2 \in X$ be two possibilities, then we can find two sequences of verifiable statements $\{\obs_i^1\}_{i=1}^\infty, \{\obs_j^2\}_{j=1}^\infty \in \edomain_X$ such that $x_1=\bigAND\limits_{i=1}^\infty \obs_i^1$ and $x_2=\bigAND\limits_{j=1}^\infty \obs_j^2$. We can assume the sequences are monotone with respect to narrowness, that is $\obs_{i+1}^1 \narrower \obs_i^1$, as we can always create a monotone sequence from one that is not by taking the sequence of finite conjunction, that is $\hat{\obs}_k^1=\bigAND\limits_{i=1}^k \obs_i^1$. If $x_1 \neq x_2$, then $x_1 \AND x_2 \equiv \contradiction$ since different possibilities are incompatible. Therefore we must have $\obs_i^1 \AND \obs_j^2 \equiv \contradiction$ from some $i,j \geq 1$ or the limits would not be incompatible. In terms of verifiable sets we have $U(\obs_i^1) \cap U(\obs_j^2) = \emptyset$. For any two distinct possibilities we can find two disjoint verifiable sets each containing one: the natural topology is Hausdorff.

	Conversely, suppose the natural topology $\mathsf{T}_X$ for the possibilities $X$ for an experimental domain $\edomain_X$ is Hausdorff. Let $x \in X$ be a possibility. Consider the collection, not necessarily countable, of all verifiable sets $\{U_i\}_{i \in I} \subset \mathsf{T}_X$ such that they contain $x$. Consider their intersection $U_x = \bigcap\limits_{i \in I} U_i$. It will contain $x$ since all $U_i$ contain $x$. It will not contain anything else: since the topology is Hausdorff, for every other possibility $\hat{x}$ there is always an open set $U_i$ that does not contain it. Therefore $U_x = \{x\}$. Because the natural topology is second countable, we can find a countable basis $\basis$ and rewrite the arbitrary intersection into $\{x\} = \bigcap\limits_{i=1}^\infty V_i$ a countable intersection of elements $V_i \in \basis$ of the basis. Let $\{\obs_i\}_{i=1}^\infty$ be the sequence of verifiable statements such that $U(\obs_i) = V_i$ for every $i$. Then $x=\bigAND\limits_{i=1}^\infty \obs_i$ which means $x$ is approximately verifiable.

\end{proof}
\end{mathSection}

\section{Sigma-algebras}

In the same way that experimental domains find a natural mathematical representation as topological spaces, theoretical domains find a natural mathematical representation in $\sigma$-algebras. The main result of this section is that a theoretical domain provides a natural $\sigma$-algebra on its possibilities.

Like topologies, $\sigma$-algebras are fundamental in mathematics as they allow us to construct measures (i.e. assigning sizes to sets), limits for sequences of sets and probability spaces. It is again fitting that theoretical domains are associated to such a fundamental mathematical structure.

Let's first review what a $\sigma$-algebra is. The general idea is that we have a set $X$ of elements which we call points, and we have a collection of subsets of $X$ such that it is closed under complement and countable union, contains the empty set and contains the whole set $X$. For example, suppose $X = \{1,2,3\}$ then  $\{\{\},\{1\},\{1,2,3\}\}$ is not a $\sigma$-algebra while $\{\{\},\{1\}, \{2,3\},\{1,2,3\}\}$ is. The first one is missing the complement of $\{1\}$.

\begin{mathSection}
	\begin{defn}
		Let $X$ be a set. A \textbf{$\sigma$-algebra} on $X$ is a collection $\Sigma_X$ of subsets of $X$ closed under complement and countable union such that it contains $X$.
	\end{defn}
\end{mathSection}

Note that $\sigma$-algebras are also closed under countable intersections, since these can be expressed in terms of complements and countable unions.

In the previous section we saw how each verifiable statement can be expressed as the conjunction of a set of possibilities, how the operations on statements can be expressed as operations on the verifiable sets and how all the verifiable sets form a topology. The same is true for theoretical statements, with the only difference being that we will end up with a collection of sets that is closed under complement and countable union since the theoretical domain is closed under negation and countable disjunction.

\begin{mathSection}
	
	\begin{defn}
		Let $\tdomain$ be a theoretical domain and $X$ its possibilities. We define the map $A : \tdomain \rightarrow 2^X$ that for each theoretical statement $\stmt \in \tdomain$ returns the set of possibilities compatible with it. That is, $A(\stmt)\equiv\{ x \in X \, | \, x \comp \stmt\}$. We call $A(\stmt)$ the \textbf{theoretical set} of possibilities associated with $\stmt$
	\end{defn}
	
	\begin{prop}
		Let $X$ be the set of possibilities for a theoretical domain $\tdomain$. $X$ has a natural $\sigma$-algebra given by the collection of all theoretical sets $\Sigma_X=A(\tdomain)$.
	\end{prop}
	
	\begin{proof}
	The theoretical sets for the tautology and the contradiction correspond to the full set and empty set respectively. Formally, $A(\tautology) = \{ x \in X \, | \, x \comp \tautology\} = X$ while $A(\contradiction) = \{ x \in X \, | \, x \comp \contradiction\} = \emptyset$. Therefore $X, \emptyset \in A(\tdomain)$ since $\tautology, \contradiction \in \tdomain$.

	The complement of a theoretical set corresponds to the theoretical set of the negation and therefore it is a theoretical set. Formally, $A(\stmt)^C = \{ x \in X \, | \, x \ncomp \stmt\} =  \{ x \in X \, | \, x \comp \NOT\stmt\} = A(\NOT\stmt)$.

	The countable union of verifiable sets corresponds to the verifiable set of the countable disjunction and therefore it is a theoretical set. Formally, $A(\stmt_1\OR\stmt_2) = \{ x \in X \, | \, x \comp \stmt_1\OR\stmt_2\} =  \{ x \in X \, | \, x \comp \stmt_1 \, or \, x \comp \stmt_2\} = \{ x \in X \, | \, x \comp \stmt_1\} \cup \{ x \in X \, | \, x \comp \stmt_2\} = A(\stmt_1) \cup A(\stmt_2)$. This generalizes to countable disjunctions.

	The collection $\Sigma_X=A(\tdomain)$ is therefore a $\sigma$-algebra by definition since it satisfies all its properties.
	\end{proof}
\end{mathSection}

There is also a special link between topologies and $\sigma$-algebras. As one may want to construct measures and probability spaces on topological spaces, there is a standard way to construct a $\sigma$-algebra from a topology. This object, called Borel algebra, is the smallest $\sigma$-algebra that contains all verifiable sets defined by the topology. The $\sigma$-algebra defined by a theoretical domain is none other than the Borel algebra of the topology defined by the corresponding experimental domain.

\begin{mathSection}
	
	\begin{defn}
		Let $(X, \mathsf{T})$ be a topological space. Its \textbf{Borel algebra} is the collection $\Sigma_X$ of subsets of $X$ generated by countable union, countable intersection and complement from the verifiable sets.
	\end{defn}
	
	\begin{prop}
		The natural $\sigma$-algebra for a set of possibilities is the Borel algebra of its natural topology.
	\end{prop}
	
	\begin{proof}
		Since the theoretical domain can be generated by a basis of the experimental domain, the natural $\sigma$-algebra can be generated by a sub-basis of the natural topology. This means that it is also generated by countable union, countable intersection and negation from the verifiable sets of the natural topology.
	\end{proof}
\end{mathSection}

This fundamental link between experimental domains and topology on one side and theoretical domains and $\sigma$-algebra on the other is important for multiple reasons.

From a practical standpoint, it guarantees that these mathematical tools can always be used in science. Since experimental and theoretical domains are general constructs, any branch of scientific investigation can use techniques and results from topology and $\sigma$-algebras for calculations or for characterizing the domain at hand.

From a conceptual standpoint it provides a Rosetta stone, i.e a way to translate, between the mathematical concepts and the scientific ones. It gives a precise scientific meaning to the mathematical tools and everything built on top of them. Every single step in a calculation, every single argument in a proof can be given a clear, and possibly insightful, physical meaning. It grounds the abstract mathematical language in more concrete scientific objects. This in turn helps clarify the science described by common mathematical tools, unearthing possible hidden assumptions or simplifications about the physical systems being studied.

This connection explains why these mathematical tools have found such successful application in the physical sciences.

\section{Summary}

In this first chapter we have laid down the foundations for our general mathematical theory of experimental science. We have seen how it is grounded in the logic of verifiable statements, which is more limited than the logic of pure statements as it has to deal with the practical constraints introduced by the termination of the tests.

We saw that we can group verifiable statements into experimental domains which must have a countable basis to allow us to test any statement within an indefinite amount of time. We saw how to construct theoretical domains to find all the theoretical statements that we can use as predictions. And we saw how the possibilities are those statements that, if true, give a complete prediction for all statements in the domain.

We have seen that, because of the disjunctive normal form, each verifiable and theoretical statement is equivalent to a set of possibilities and how logic operations and relationships become set operations and relationships. As such, the experimental and theoretical domains respectively provide a natural topology and $\sigma$-algebra for the possibilities.

What we have ended up with is a conceptual framework that captures the necessary elements of scientific practice and codifies them into a symbolic representation with a well defined meaning. There is no guesswork as to what the points of our spaces are: they are the possibilities, statements that provide a complete prediction for the domain. We do not have to provide an ``interpretation" as to what the sets of a topology represent: they correspond to verifiable statements. All the objects have a clear definition and meaning from the start, we know which ones are necessary and to what extent they are physical or idealized. This will provide a much more solid foundation to the rest of the work, which will ultimately allow us to understand much better the fundamental physical theories and the connections between them and to other areas of scientific thought.

\newpage

\section{Reference sheet}

\begin{tabular}{p{0.2\textwidth} p{0.3\textwidth} p{0.5\textwidth}}
	& Name & Meaning  \\ 
	\hline 
	$\mathbb{B}$  & Boolean domain & the set of possible truth values \\ 
	&  & i.e. $\mathbb{B} = \{\TRUE, \FALSE\}$ \\ 
	\hline 
	$\stmt \in \stmtSet$ & statement & an assertion with a well defined truth value \\ 
	\hline 
	$\truth : \stmtSet \to \mathbb{B}$ & the truth function & returns whether a statement is true or not  \\ 
	\hline 
	$\possFn: \mathcal{S} \to \{$& the possibilities function & returns which truth values can be assigned to \\ 
	$\{\FALSE,\TRUE\},$ & & each statement \\ 
	$\{\FALSE\}, \{\TRUE\}\}$ & &  \\ 
	\hline 
	$\NOT \stmt$ & negation (logical NOT) & the statement whose truth value is always opposite \\ 
	\hline 
	$\tautology$ & tautology & a statement that can only be true (i.e. it is true in all truth assignements) \\ 
	\hline 
	$\contradiction$ & contradiction & a statement that can never be true (i.e. it is false in all truth assignements) \\ 
	\hline 
	$\stmt_1 \AND \stmt_2$ & conjunction (logical AND) & the statement that is true only if all statements are true \\ 
	\hline 
	$\stmt_1 \OR \stmt_2$ & disjunction (logical OR) & the statement that is true if any of the statements is true \\ 
	\hline 
	$\stmt_1 \equiv \stmt_2$ & equivalence & whether each statement is a logical consequence of the other (i.e. they must have the same value in every truth assignment) \\ 
	\hline 
	$\stmt_1 \narrower \stmt_2$ & narrower than & whether the first statement is more specific than the second (i.e. in every truth assignment, if the first is true than the second must be also true) \\ 
	\hline 
	$\stmt_1 \broader \stmt_2$ & broader than & whether the second statement is narrower than the first \\ 
	\hline 
	$\stmt_1 \comp \stmt_2$ & compatibility & whether both statement can be true at the same time (i.e. there is a truth assignment in which they are both true) \\
	\hline 
	$\stmt_1 \indep \stmt_2$ & independence & whether both statement can be true at the same time (i.e. there is a truth assignment for each combination of their possible truths) \\
	\hline 
	& minterm & a conjunction where each statement appears once, either negated or not \\
	\hline 
	$\obs \in \vstmtSet$ & verifiable statement & a statement that can be validated experimentally\\ 
	\hline 
	$\edomain$ & experimental domain & a set of verifiable statement that can be tested in an indefinite amount of time (i.e. a set of statements closed under finite conjunction and countable disjunction, that precisely contains the tautology, the contradiction and a set of verifiable statements generated by a countable basis) \\ 
	\hline 
	$\basis \in \edomain$ & basis & a set of verifiable statements from which all others can be constructed\\ 
			
\end{tabular} 

\newpage

\begin{tabular}{p{0.2\textwidth} p{0.3\textwidth} p{0.5\textwidth}}
	& Name & Meaning  \\ 
	\hline 
	$\tdomain$ & theoretical domain & the set of all predictions for an experimental domain\\ 
	\hline 
	& approximately verifiable & when a statement is not verifiable but is the limit of a sequence of statements that are\\ 
	\hline 
	$X$ & possibilities of a domain & those predictions that sets the value of all verifiable statements of a domain\\ 
	\hline 
	$\estPoss$ & established possibility & a possibility for which at least a verifiable statements is true (i.e. it can be established experimentally)\\ 
	\hline 
	$\resPoss$ & residual possibility & if it exists, the possibility for which all verifiable statements are false (i.e. the remaining case that cannot be established experimentally)\\ 
	
\end{tabular} 


\chapter{Domain combination and relationships}

We continue our investigation of the fundamental mathematical structures for experimental science by studying what happens when we have more than one experimental domain. We will define \textbf{experimental relationships} between experimental domains, which capture either causal or inference relationships between them. We will see that these correspond to continuous functions in the natural topology.

We will take two or more domains and merge all the experimental information that can be gathered through them into a \textbf{combined domain}. We will study how the set of possibilities of the combined domain depends not only on the original domains, but also on the relationships between them. These will also determine the natural topology that can vary from the product topology all the way to the disjoint union topology.

We will also show that experimental relationships, under suitable conditions, can themselves be verified experimentally by constructing the \textbf{relationship domain} for which its possibilities correspond to the possible relationships. To conclude, we study \textbf{properties} and \textbf{quantities} which we use to label the possibilities of an experimental domain.

\section{Dependence and equivalence between domains}

The first thing we want to be able to characterize, when dealing with more than one domain, is when there exists a relationship between them. For example, consider the domains for the temperature and height of a mercury column or the domains for the temperature and density of water. How do we express, in this framework, the fact that these domains are connected?

We have two ways to define these relationships between domains. The first is in terms of inference: any measurement on the height of a mercury column is an indirect measurement on its temperature; any experimental test on the density of water is an indirect experimental test on its temperature. The second is in terms of causes: the height of the mercury column depends on its temperature; the density of water is a function of its temperature. The main result of this section is to show that these definitions are equivalent and that the dependent domain can be seen as a sub-domain of the other.

Suppose $\edomain_X$ represents the domain for the temperature of a mercury column while $\edomain_Y$ represents the domain for its height. Since we know that an increase in temperature makes the metal expand, we can infer the temperature of the mercury column by looking at its height. For example, if we verify that \statement{the height of the mercury column is between 24 and 25 millimeters} we will be able to infer that \statement{the temperature is between 24 and 25 Celsius}. That is, given a verifiable statement $\obs_Y$ we have another verifiable statement $\obs_X$ that is going to be true if and only if the first one is, that is $\obs_Y\equiv\obs_X$.

Note that the inference is between verifiable statements and not intervals. For example, the verifiable statement \statement{the water density is between 999.8 and 999.9 kg/$m^3$} will correspond to \statement{the water temperature is between 0 and 0.52 Celsius}$\OR$\statement{the water temperature is between 7.6 and 9.12 Celsius} as water is most dense at 4 Celsius. The disjunction of verifiable statements is still a verifiable statement so we are still inferring one verifiable statement from the other. For each verifiable statement in $\edomain_Y$ we can find a verifiable statement in $\edomain_X$ that is verified if and only the first is. That is: an inference relationship is a map from $\edomain_Y$ to $\edomain_X$ that preserves equivalence.

\begin{mathSection}
	\begin{defn}
		An \textbf{inference relationship} between two experimental domains establishes that testing a verifiable statement in one means testing a verifiable statement in the other. More formally, it is a map $\erel: \edomain_Y \to \edomain_X$ between two experimental domains $\edomain_X$ and $\edomain_Y$ such that $\erel(\obs_Y) \equiv \obs_Y$. In other words: it is an equivalence-preserving map between experimental domains.
	\end{defn}
\end{mathSection}

An inference relationship is essentially an injection that preserves equivalence instead of identity. In terms of equality, the two statements \statement{the height of the mercury column is between 24 and 25 millimeters} and \statement{the temperature is between 24 and 25 Celsius} are different, but they are the same in terms of equivalence. In this sense, the dependent domain is already contained within the other domain. This means we can define domain inclusion and equivalence based on inference relationships.

\begin{mathSection}
	\begin{defn}
		An experimental domain $\edomain_Y$ is \textbf{dependent} on another experimental domain $\edomain_X$, noted $\edomain_Y \subseteq \edomain_X$, if there exists an inference relationship $\erel: \edomain_Y \to \edomain_X$.
	\end{defn}
	\begin{coro}\label{prop_domain_subset_is_dependence}
		Let $\edomain_X$ be an experimental domain. Let $\edomain_Y$ be a subset of statements of $\edomain_X$ that form an experimental domain (i.e. contains contradiction, tautology and is closed under finite conjunction and countable disjunction). Then $\edomain_Y \subseteq \edomain_X$.
	\end{coro}
	\begin{proof}
		Let $\iota : \edomain_Y \to \edomain_X$ be the inclusion map. This is an inference relationship since $\iota(\stmt_Y) = \stmt_Y \equiv \stmt_Y$ therefore $\edomain_Y$ depends on $\edomain_X$.
	\end{proof}
	\begin{defn}
		Two experimental domains $\edomain_X$ and $\edomain_Y$ are \textbf{equivalent} $\edomain_X \equiv \edomain_Y$ if $\edomain_X$ depends on $\edomain_Y$ and vice-versa.
	\end{defn}
	\begin{coro}
		Domain equivalence satisfies the following properties:
		\begin{itemize}
			\item reflexivity: $\edomain \equiv \edomain$
			\item symmetry: if $\edomain_X \equiv \edomain_Y$ then $\edomain_Y \equiv \edomain_X$
			\item transitivity: if $\edomain_X \equiv \edomain_Y$ and $\edomain_Y \equiv \edomain_Z$ then $\edomain_X \equiv \edomain_Z$
		\end{itemize}
		and is therefore an \textbf{equivalence relationship}.
	\end{coro}
	\begin{proof}
		For reflexivity, $\edomain$ is a subset of $\edomain$ that is an experimental domain, therefore $\edomain \subseteq \edomain$ by \ref{prop_domain_subset_is_dependence}. Equivalence follows by symmetry.
		
		For symmetry, suppose $\edomain_X \equiv \edomain_Y$, then $\edomain_Y \subseteq \edomain_X$ and $\edomain_X \subseteq \edomain_Y$ and therefore $\edomain_Y \equiv \edomain_X$.
		
		For transitivity, suppose $\edomain_X \equiv \edomain_Y$ and $\edomain_Y \equiv \edomain_Z$. Then we have the following inference relationships: $\erel_{XY} : \edomain_X \to \edomain_Y$, $\erel_{YX} : \edomain_Y \to \edomain_X$, $\erel_{YZ} : \edomain_Y \to \edomain_Z$, $\erel_{ZY} : \edomain_Z \to \edomain_Y$. We can define the function compositions $\erel_{XZ} = \erel_{YZ} \circ \erel_{XY}$ and $\erel_{ZX} = \erel_{YX} \circ \erel_{ZY}$. These are inference relationships since $\stmt_X \equiv \erel_{XY}(\stmt_X) \equiv \erel_{YZ}(\erel_{XY}(\stmt_X))$ and $\stmt_Z \equiv \erel_{ZY}(\stmt_Z) \equiv \erel_{YX}(\erel_{ZY}(\stmt_Z))$. Therefore $\edomain_X \equiv \edomain_Z$.
	\end{proof}
\end{mathSection}


It should be evident that we cannot impose inference relationships between any two domains: it's something that the domains allow or not. The domains for the temperature of two different mercury columns are in general not related: testing the value of one does not tell us anything about the other. The topologies of the two domains, however, are going to be the same because we'll have the same possible values and the same way to experimentally test them. Equivalence between experimental domains is a much stronger relationship than equivalence of the natural topology. It carries enough of the semantic to be able to tell what spaces are truly scientifically equivalent.

Let's continue with our example. We can re-express a relationship between domains in terms of causal relationship between the two domains. If $x$ is the value of temperature of the mercury column (i.e. a possibility for $\edomain_X$) and $y$ is the height of the mercury column (i.e. a possibility for $\edomain_Y$), then we can write $y=f(x)$ since the height is determined by the temperature.

Note that the direction of the causal relationship is the opposite of the inference. $X$ causes $Y$ and from $\edomain_Y$ we can infer $\edomain_X$ . Chains of events are in terms of possibilities and start with the cause and end with the effect. Chains of inferences are in terms of verifiable statements and start with the result and end with the origin.

The other directions do not work in general. Even if we know the final possibility, we may not be able to reconstruct the initial possibility: if the water density is exactly 999.9 kg/$m^3$, the temperature could be either 0.52 or 7.6 Celsius because density peaks at 4 Celsius. For the same reason, a measurement of the cause is not always equivalent to a measurement of the effect: verifying that \statement{the water temperature is between 0 and 0.52 Celsius} will mean that \statement{the water density is between 999.8 and 999.9 kg/$m^3$} but not the other way around. Because of the peak in density, the statement about the temperature tells us more (i.e. it is narrower) than the statement about the density and therefore they are not equivalent. That is: we can learn more about the temperature by measuring it directly than indirectly through the density.

Another important consideration is that, in order to be consistent, the function $y=f(x)$ has to be continuous. The general idea is the following: if we say that we can only measure both the temperature and height of a mercury column with finite precision, we have to make sure that we can use the causal relationship for inference. Therefore a finite precision measurement of height will correspond to a finite precision measurement of temperature. This means a small change in height has to correspond to a small change in temperature: the function is continuous.

More precisely, consider the verifiable statement $\obs_Y=$\statement{the height of the mercury column is between 24 and 25 millimeters}. The height of the mercury column $y$ is within the verifiable set $U(\obs_Y) = (24, 25)$ millimeters. We can then infer that the temperature must be in the reverse image of the possible heights $f^{-1}(U_Y(\obs_Y))=(24,25)$ Celsius. But this means that, indirectly, we have experimentally verified that $x$ is in $f^{-1}(U_Y(\obs_Y))$. And if $\edomain_X$ is really the domain of the verifiable statements for the temperature, then it must contain one that matches \statement{the temperature of the mercury column is between 24 and 25 Celsius}. In other words, $f^{-1}(U_Y(\obs_Y))$ must be a set in the topology of $X$ and the function is continuous.\footnote{In topology, continuity is defined in terms of the sets in the topology and not in terms of small changes as in analysis. When using the standard topology on real numbers, the two coincide but not in general.}

\begin{mathSection}
	\begin{defn}
		Let $(X, \mathsf{T}_X)$ and $(Y, \mathsf{T}_Y)$ be two topological spaces. A \textbf{continuous function} is a map $f: X \to Y$ such that given any verifiable set $U_Y \in \mathsf{T}_Y$ its reverse image $f^{-1}(U_Y) \in \mathsf{T}_X$ is a verifiable set. A \textbf{homeomorphism} is a continuous bijective map such that its inverse is also continuous.
	\end{defn}
	\begin{defn}
		A \textbf{causal relationship} between two experimental domains establishes that determining which possibility is true in the first domain also determines which possibility is true in the second. More formally, it is a continuous function $f : X \to Y$ between the possibilities of two experimental domains $\edomain_X$ and $\edomain_Y$ such that $x \narrower f(x)$.
	\end{defn}
	\begin{justification}
		Formally, we simply define causal relationships to be continuous but we still need a physical justification. An experimental test for the verifiable set $U_Y$ will indirectly test that the true possibility of $Y$ was in the set $f^{-1}(U_Y)$. This means that $f^{-1}(U_Y)$ can be associated with an experimental test and is therefore a verifiable set. If we want to be consistent, then, we need to make sure $f^{-1}(U_Y)$ is in the natural topology for $\edomain_X$.
	\end{justification}
	\begin{thrm}[Experimental Relationship Theorem]
		Inference and causal relationships are equivalent. More formally, let $\edomain_X$ and $\edomain_Y$ be two experimental domains. An inference relationship $\erel: \edomain_Y \to \edomain_X$ exists between them if and only if a causal relationship $f: X \to Y$ also exists.
	\end{thrm}
	\begin{proof}
		First we show that a causal relationship exists between the independent and the dependent domain. Suppose $\edomain_Y$ depends on $\edomain_X$. Given that for each statement in $\edomain_Y$ there exists an equivalent statement in $\edomain_X$, $\edomain_Y$ is effectively a subset of $\edomain_X$. By the same token, the theoretical domain $\tdomain_Y$ is effectively a subset of $\tdomain_X$. This means that a possibility $x \in \tdomain_X$, if true, will determine all the truth values of  all statements in $\tdomain_Y$, including its possibilities. Because one possibility of $Y$ must be true and because all possibilities are incompatible with each other, there must be one and only one possibility $y \in \tdomain_Y$ compatible with $x$. Therefore we can define $f : X \to Y$ the function that given a possibility $x \in X$ returns the only possibility $y=f(x) \broader x$ that is compatible with it.
		
		We still need to show that $f$ is continuous. Consider a verifiable statement $\obs_Y \in \edomain_Y$. Let $U_Y(\obs_Y) \in \mathsf{T}_Y$ be its verifiable set. Since $\edomain_Y$ depends on $\edomain_X$, we can find $\obs_X \in \edomain_X$ such that $\obs_X \equiv \obs_Y$. Let $U_X(\obs_X) \in \mathsf{T}_X$ be its verifiable set. This is also the set of all possibilities in $X$ that are compatible with $\obs_Y$, which means $U_X(\obs_X)$ contains all the possibilities that are compatible with a possibility in $U_Y(\obs_Y)$. Since $f$ returns the only possibility in $Y$ compatible with a possibility in $X$, $f^{-1}(U_Y(\obs_Y))$ will return all the possibilities in $X$ that are compatible with a possibility in $U_Y(\obs_Y)$. That means $f^{-1}(U_Y(\obs_Y)) = U_X(\obs_X)$ and that $f^{-1}$ maps verifiable sets to verifiable sets. Therefore $f$ is continuous.
		
		Now we show that a causal relationship implies dependence between domains. Suppose we have a causal relationship $f: X \to Y$ between $\edomain_X$ and $\edomain_Y$. Let $y \in Y$ be a possibility for $\edomain_Y$. Consider  $f^{-1}(\{y\})$: this is the set of all possibilities in $X$ that are compatible with $y$ which is, by definition, the theoretical set of $y$. Therefore we have $y \equiv \bigOR\limits_{x \in f^{-1}(\{y\})} x$. Now consider a verifiable statement $\obs_Y \in \edomain_Y$. We have $\obs_Y \equiv \bigOR\limits_{y \in U_Y(\obs_Y)} y \equiv \bigOR\limits_{y \in U_Y(\obs_Y)} \bigOR\limits_{x \in f^{-1}(\{y\})} x \equiv \bigOR\limits_{x \in f^{-1}(U_Y(\obs_Y))} x$. Because $f$ is continuous, the reverse image of a verifiable set is a verifiable set. Therefore there is an $\obs_X \in \edomain_X$ such that $U_X(\obs_X) = f^{-1}(U_Y(\obs_Y))$. The two verifiable statements $\obs_X \equiv \bigOR\limits_{x \in U_X(\obs_X)} x \equiv \obs_Y$ are equivalent. For each $\obs_Y \in \edomain_Y$ we can find an equivalent $\obs_X \in \edomain_X$ so $\edomain_Y$ depends on $\edomain_X$.
	\end{proof}
\end{mathSection}

Since for each inference relationship we have a causal relationship and vice-versa, we will simply use the term \textbf{experimental relationship} to describe the link between the two domains.

We have seen that two experimental domains $\edomain_X$ and $\edomain_Y$ are equivalent if they consist of equivalent statements: if they allow a one to one correspondence that preserves the equivalence of their statements. This implies, for example, that the possibilities are also equivalent but there is more to it.

Suppose we define some type of operation on one domain. For example, on the experimental domain for the temperature of a mercury column we define an increase by one Celsius; or on the experimental domain for the amount of gasoline in a tank we define the sum of two possible amounts. These will correspond either to operations on the domain (e.g. $f : \edomain_X \to \edomain_X$) or on its possibilities (e.g. $+ : X \times X \to X$). But by doing so we are also defining them on all equivalent domains as well: in the end, they are made of equivalent statements. Therefore we are also defining an increase of the height of the mercury column and the sum of the monetary value of the gasoline.

This means that if we capture some physical feature using some mathematical structure on one domain, then all equivalent domains will inherit the same structure. Moreover, the causal relationship is a function that preserves that structure. If the possibilities of one domain form a vector space, then the possibilities of an equivalent domain form a vector space and the causal relationship is an invertible linear transformation. If the possibilities of one domain form a group, then the possibilities of an equivalent domain form a group and the causal relationship is an isomorphism.\footnote{Domain equivalence is an isomorphism in whatever category (e.g. topological space, group, vector space, ...) used to model the experimental domain.} As we'll see much later, this is fundamental since deterministic and reversible evolution means equivalence of the domains describing the past, present and future states. Therefore deterministic and reversible motion is not ``just" a one to one map.

\begin{mathSection}
	\begin{thrm}[Domain Equivalence is Isomorphism]\label{thrm_domain_equivalence_is_isomorphism}
		Let $\edomain_Y \equiv \edomain_X$ be two equivalent experimental domains. Suppose $\edomain_X$ is endowed with some mathematical structure. Then $\edomain_Y$ is also endowed with an equivalent structure and the experimental relationship preserves said structure.
	\end{thrm}
\begin{proof}
	Since an experimental domain is really defined not on the statements themselves but on their equivalence classes, the mathematical structure will also be defined on the equivalence classes. But this means that a structure defined on $\edomain_X$ is also defined on $\edomain_Y$ since they contain the same equivalence classes. Therefore $\edomain_Y$ is also endowed with an equivalent structure.
	
	The experimental relationship can either expressed as a map between possibilities $f : X \to Y$ or as a map between verifiable statements $\erel : \edomain_X \to \edomain_Y$. This means that the mathematical structure defined on $\edomain_Y$ can be transported to $\edomain_X$ using the experimental relationship. But since the mathematical structure defined on $\edomain_X$ already contains the mathematical structure defined on $\edomain_Y$, the transported mathematical structure has to be the same. That is, the experimental relationship must preserve the mathematical structure defined on $\edomain_X$.
\end{proof}
\end{mathSection}

Note that the converse is not true: two domains that are endowed with the same mathematical structure are not necessarily equivalent. Consider two similarly constructed thermometers: their respective experimental domains are not equivalent since knowing something about one tells us nothing about the other. Yet, their natural topologies are equivalent because the way we can measure temperature for both is the same. One way to look at it is that the mathematical structures ``forget" the full equivalence between statements and only look at a particular aspect. Topological spaces capture how the possibilities are distinguished in terms of verifiable statements. Therefore, while the domains for temperature of two different thermometers are not equivalent, their natural topologies are equivalent because the way we characterize all possible measurements is the same (i.e. the value is within a finite precision interval). Similarly, the $\sigma$-algebra only cares about what statements are valid predictions. We'll see that, in some cases, Abelian groups will capture how distributions can be composed into other distributions, that non-Abelian groups will capture how transformations can be composed into other transformations, and so on.

\section{Combining domains}

In this section we want to understand what happens when we combine statements from different domains. For example, suppose we have the experimental domain for the pressure of an ideal gas and the experimental domain for its temperature. We can mix and match verifiable statements with conjunction and disjunction as in \statement{the pressure is between 1 and 1.1 KPa}$\AND$\statement{the temperature is between 20 and 21 C} creating a new domain. How can we characterize this combined experimental domain?

The main result of this section is that the possibilities of the combined domain depend on how compatible the verifiable statements of the domains are. In particular, if the verifiable statements are independent across domains (e.g. the horizontal and vertical position of an object), then the possibilities of the combined domain will be the scalar product of those for the individual domains. On the other hand, if the verifiable statements are incompatible across domains (e.g. plant identification and animal identification), then the possibilities for the combined domain will be the disjoint union of the possibilities of the individual domains.

Suppose $\edomain_X$ is the experimental domain generated by the two verifiable statements \statement{the patient is dead} and \statement{the patient is alive} and a second one $\edomain_Y$ generated by the two verifiable statements \statement{the patient is not in a coma} and \statement{the patient is in a coma}. The given verifiable statements also correspond to the possibilities for the respective domains.

We can construct the combined domain $\edomain_X \times \edomain_Y$ by taking all possible disjunctions and conjunctions. What are the possibilities for the new domain? Since by \ref{prop_poss_is_minterm} the possibilities are minterms, we have the following cases to consider:
\begin{itemize}
	\item \statement{the patient is alive} $\AND$ \statement{the patient is in a coma}
	\item \statement{the patient is alive} $\AND$ \statement{the patient is not in a coma}
	\item \statement{the patient is dead} $\AND$ \statement{the patient is in a coma}
	\item \statement{the patient is dead} $\AND$ \statement{the patient is not in a coma}
\end{itemize}
The third one is a contradiction: the patient cannot be dead and in a coma. Therefore the combined domain has only three possibilities. The possibilities of the combined domain are, in general, the subset of all possible combinations (i.e. the scalar product) of the possibilities of the domains we are combining: those that do not lead to contradictions.

\begin{mathSection}
	
	\begin{defn}
		Let $\{\edomain_{X_i}\}_{i=1}^{\infty}$ be a countable set of experimental domains. The \textbf{combined experimental domain} $\edomain_{X} = \bigtimes\limits_{i=1}^{\infty} \edomain_{X_i}$ is the experimental domain generated from all statements in $\{\edomain_{X_i}\}_{i=1}^{\infty}$ by finite conjunction and countable disjunction.
	\end{defn}
	\begin{proof}
		We need to show that the combined experimental domain is indeed an experimental domain. It will contain the tautology and the contradiction since any of the original experimental domains contains them. It is closed under finite conjunction and countable disjunction by construction. To show that it has a countable basis, for each $i=1..\infty$ let $\basis_i \in \edomain_{X_i}$ be a countable basis for the respective domain. Consider $\basis=\bigcup\limits_{i=1}^\infty \basis_i$. From this set we can generate any $\edomain_{X_i}$ and therefore we can also generate all of $\edomain_{X}$. $\basis$ is a basis and it is countable since it is the union of a countable set of countable elements. Note that it is precisely because the basis needs to remain countable that we cannot extend the operation to an uncountable set of domains.
	\end{proof}
	
	\begin{prop}\label{prop_combined_possibility}
		The possibilities for a combined domain are a subset of the scalar product of the possibilities for the individual domains. Formally, let $\{\edomain_{X_i}\}_{i=1}^{\infty}$ be a countable set of experimental domains and $\{X_i\}_{i=1}^{\infty}$ their respective possibilities. Let $X$ be the set of possibilities for the combined domain $\edomain_{X} = \bigtimes\limits_{i=1}^{\infty} \edomain_{X_i}$.  Then $X = \{ x = \bigAND\limits_{i=1}^{\infty} x_i \, | \, \{x_i\}_{i=1}^{\infty} \in \bigtimes\limits_{i=1}^{\infty} X_i, \, x \nequiv \contradiction \}$.
	\end{prop}   
	\begin{proof}
		A possibility $x$ of the combined domain is a minterm of a basis $\basis \subseteq \edomain_{X}$. Since we can choose $\basis=\bigcup\limits_{i=1}^\infty \basis_i$ where $\basis_i \subseteq \edomain_{X_i}$ is a countable basis for each domain, $x$ is the conjunction $x \equiv \bigAND\limits_{i=1}^{\infty}x_i$ of minterms $x_i$ of $\basis_i$. Since $x$ is a possibility, it is not a contradiction and therefore none of the $x_i$ can be a contradiction. Since each $x_i$ is a minterm of the respective basis $\basis_i$ that is not a contradiction, it is a possibility by \ref{prop_poss_is_minterm}. Therefore a possibility $x$ of the combined domain is the conjunction of the possibilities $x_i$ of the original domains that is not a contradiction.
	\end{proof}
\end{mathSection}

\subsection{Independent domains}

A special case is when combining two independent domains. For example, the domain for the pressure and the domain for the volume of an ideal gas are independent because a measurement on one tells us nothing about the other. Similarly, the domain for the shape and the domain for the color of an object are independent. In these cases, we can have any combination of possibilities: any pressure with any volume or any color with any shape.

In terms of topology, the possibilities of the combined domain are the Cartesian product of the possibilities of the original domains and their natural topology is the product topology.\footnote{Note that the topology is quite naturally the product topology and not the box topology. The box topology would require countable conjunction and is therefore discarded. The fact that the correct topology is the one most natural to define confirms again the appropriateness of our framework.}

\begin{mathSection}
	\begin{defn}
		The experimental domains of a countable set $\{\edomain_{X_i}\}_{i=1}^{\infty}$ are \textbf{independent} if taking one verifiable statement $\obs_i \in \edomain_{X_i}$ from each domain always gives an independent set of statements.
	\end{defn}
	\begin{prop}
		Let $\{\edomain_{X_i}\}_{i=1}^{\infty}$ be a countable set of independent experimental domains and $X_i$ their respective possibilities. The set of possibilities $X$ of the combined experimental domain $\bigtimes\limits_{i=1}^{\infty} \edomain_{X_i}$ consists of all the possible conjunctions of the possibilities of each domain. That is: $X = \{ \bigAND\limits_{i=1}^{\infty} x_i \, | \, x_i \in X_i \}$. Notationally, we write $\edomain_X=\edomain_{\bigtimes\limits_{i=1}^{\infty} X_i}$.
	\end{prop}
	\begin{proof}
		A possibility $x \equiv \bigAND\limits_{i=1}^{\infty}x_i$ for the combined domain is the conjunction of possibilities of each individual domain by \ref{prop_combined_possibility}. Since the domains are independent and since possibilities are neither tautologies nor contradictions, we have $\possFn(x) = \possFn(\bigAND\limits_{i=1}^{\infty}x_i) = \bigAND\limits_{i=1}^{\infty}\possFn(x_i)= \bigAND\limits_{i=1}^{\infty} \{\FALSE, \TRUE\} = \{\FALSE, \TRUE\}$. That is, each conjunction $x=\bigAND\limits_{i=1}^{\infty}x_i$ is not a contradiction and therefore is a possibility.
	\end{proof}
	\begin{defn}
		Let $\{(X_i, \mathsf{T}_i)\}_{i=1}^{\infty}$ be a countable set of topological spaces. Let $X=\bigtimes\limits_{i=1}^{\infty} X_i$ be the Cartesian product of the points. Let $\mathcal{B}$ be the collection of sets of the form $\bigtimes\limits_{i=1}^{\infty} U_{i}$, with $U_i \in \mathsf{T}_i$ and $U_i \neq X_i$ only finitely many times. The topology generated by $\mathcal{B}$ is called the \textbf{product topology}.
	\end{defn}
	\begin{prop}
		Let $\{\edomain_{X_i}\}_{i=1}^{\infty}$ be a countable set of independent experimental domains. The natural topology for the possibilities of the combined experimental domain $\edomain_{\bigtimes\limits_{i=1}^{\infty} X_i}$ is the product topology of the natural topology for the possibilities of each domain.
	\end{prop}
	\begin{proof}
		Let $U_i : \edomain_{X_i} \to \mathsf{T}_{X_i}$ be the map from a verifiable statement of a domain to its verifiable set in the respective topology. Let $U : \edomain_{X} \to \mathsf{T}_X$ be the same map for the combined domain. Let $\obs_i \in \edomain_{X_i}$ be a verifiable statement from a particular domain and $U_i(\obs_i)$ its verifiable set in that domain. Since we also have $\obs_i \in \edomain_{X}$, the statement is also associated with the verifiable set $U(\obs_i)$ in the combined domain. Because the domains are independent, every possibility in $U_i(\obs_i)$ is compatible with any possibility $x_j \in X_j$ for all $j \neq i$. This means that $U(\obs_i)=X_1\times ... \times X_{i-1} \times U_i(\obs_i) \times X_{i+1} \times ...$ . Given that a verifiable statement in the combined domain can be generated using finite conjunction and countable disjunction from the verifiable statements of the independent domains, the topology of the combined space can be generated by all sets of the form $\bigtimes\limits_{i=1}^{\infty} U_{i}$, with $U_i \in \mathsf{T}_i$ and $U_i \neq X_i$ only once. Using finite conjunction, this includes those sets where $U_i \neq X_i$ finitely many times. The natural topology of the combined domain is the product topology by definition.
	\end{proof}
\end{mathSection}

\subsection{Dependent domains}

Another special case is combining a domain $\edomain_X$ with another $\edomain_Y \subseteq \edomain_X$ that is dependent on it. For example, combining the domain for the temperature of a mercury column with the domain for its height. Since the height can be determined by the temperature, no new possibilities are added. The combined domain is equivalent to the independent domain $\edomain_X$ since all the verifiable statements in $\edomain_Y$ have equivalents in it.

\begin{mathSection}
	\begin{prop}
		Let $\edomain_X$ and $\edomain_Y$ be two experimental domains such that $\edomain_Y \subseteq \edomain_X$ depends on the first. Then $\edomain_X \times \edomain_Y \equiv \edomain_X$.
	\end{prop}
	\begin{proof}
		Since $\edomain_Y$ is dependent on $\edomain_X$, any statement in $\edomain_Y$ is equivalent to one in $\edomain_X$. Therefore no statement can be generated from them that is not equivalent to one already contained in $\edomain_X$. Therefore $\edomain_X \times \edomain_Y$ is equivalent to $\edomain_X$. 
	\end{proof}
	\begin{coro}
		Let $\edomain_X$ and $\edomain_Y$ be two experimental domains such that $\edomain_Y \subseteq \edomain_X$ depends on the first. The possibilities of $\edomain_X \times \edomain_Y$ are the possibilities of $\edomain_X$.
	\end{coro}
	\begin{proof}
		The possibilities of $\edomain_X \times \edomain_Y$ are the possibilities of $\edomain_X$ since they are equivalent domains. To be consistent with \ref{prop_combined_possibility}, we additionally show that they are also the subset of the scalar product. Let $f : X \to Y$ be the causal relationship between the domains, let $x$ and $y$ be two possibilities of the respective domains. We have $x \AND y \nequiv \contradiction$ if and only if $y = f(x)$, so the possibilities of $\edomain_X \times \edomain_Y$ are $x \AND f(x)$ for all $x \in X$. We also have $x \AND f(x) \equiv x$ since $x \narrower f(x)$.
	\end{proof}
\end{mathSection}


\subsection{Incompatible domains}

The last special case we consider is when the domains are incompatible, that is all verifiable statements of one are incompatible with the verifiable statements of the other. This is one case where the residual possibility behaves differently from all the others.\footnote{In fact, this is what prompted us to introduce the residual possibility.} Suppose $\edomain_X$ is the domain to classify a particular specimen as an animal and $\edomain_Y$ is the domain to classify it as a plant. If we take a verifiable statement from the first, such as \statement{that specimen has fur}, then it will be incompatible with a verifiable statement from the other, such as \statement{that specimen has lobed leaves}. The only way we can combine the possibilities is to take an established possibility of one (e.g. \statement{this specimen is a cat}) and combine it with the residual possibility of the other (e.g. \statement{this specimen is not a plant}). In other words, the combined possibilities are the union of the possibilities of the two domains (e.g. all possible plants and all possible animals).

In terms of the topology, the established possibilities of the combined domain are the disjoint union of the established possibilities of the original domains and their natural topology is the disjoint union topology (or co-product topology). 

\begin{mathSection}
	\begin{defn}
		Two experimental domains $\edomain_X$ and $\edomain_Y$ are \textbf{incompatible} if all verifiable statements in one are incompatible with all verifiable statements of the other. Formally, $\obs_X \ncomp \obs_Y$ for each pair of verifiable statements $\obs_X \in \edomain_X$ and $\obs_Y \in \edomain_Y$.
	\end{defn}
	\begin{coro}
		Let $\edomain_X$ and $\edomain_Y$ be two incompatible experimental domains. Then they must be incomplete and admit a residual possibility.
	\end{coro}
	\begin{proof}
		Let $\basis_X$ and $\basis_Y$ be a countable basis for the respective domain. Since we have $\obs[e]_X \ncomp \obs[e]_Y$ for all choices of $\obs[e]_X \in \basis_X$ and $\obs[e]_Y \in \basis_Y$, we also must have $\bigOR\limits_{\obs[e]_X \in \basis_X} \obs[e]_X \ncomp \bigOR\limits_{\obs[e]_Y \in \basis_Y} \obs[e]_Y$. Therefore $\bigOR\limits_{\obs[e]_X \in \basis_X} \obs[e]_X \nequiv \tautology$. Which means the residual possibility $\mathring{x} = \bigAND\limits_{\obs[e]_X \in \basis_X} \NOT\obs[e]_X = \NOT \bigOR\limits_{\obs[e]_X \in \basis_X} \obs[e]_X \nequiv \contradiction$. Therefore $\edomain_X$ is not complete and, by symmetry, neither is $\edomain_Y$.
	\end{proof}
	\begin{prop}
		Let $\{\edomain_{X_i}\}_{i=1}^{\infty}$ be a countable set of experimental domains pair-wise incompatible and $\dot{X}_i$ their respective established possibilities. The set of established possibilities $\dot{X}$ of the combined experimental domain $\bigtimes\limits_{i=1}^{\infty} \edomain_{X_i}$ consists of the disjoint union of the possibilities of each domain. That is: $\dot{X} = \coprod\limits_{i=1}^{\infty} \dot{X}_i = \bigcup\limits_{i=1}^{\infty} \dot{X}_i$ as $\dot{X}_i \cap \dot{X}_j = \emptyset$ for all $i,j \geq 1$ and $i \neq j$. Notationally, we write $\edomain_X=\edomain_{\coprod\limits_{i=1}^{\infty} X_i}$.
	\end{prop}
	\begin{proof}
		Consider two incompatible domains $\edomain_X$ and $\edomain_Y$. Let $\dot{x} \in X$ and $\dot{y} \in Y$ be two established possibilities. Then they both correspond to a minterm of the respective basis where at least one element is taken without negation. This also means that their conjunction will include the conjunction of one element of each of the basis. Since the elements of one basis are incompatible with the elements of the other, we have $\dot{x} \ncomp \dot{y}$.
		
		Now let $\dot{x} \in X$ be an established possibility, $\mathring{y} \in Y$ the residual and $\dot{Y} = Y \setminus \{\mathring{y}\}$ the established possibilities. We have $\dot{x} \equiv \dot{x} \AND \tautology \equiv \dot{x} \AND \bigOR\limits_{y \in Y} y \equiv \dot{x} \AND (\bigOR\limits_{\dot{y} \in \dot{Y}} \dot{y} \OR \mathring{y}) \equiv \bigOR\limits_{\dot{y} \in \dot{Y}} (\dot{x} \AND \dot{y}) \OR (\dot{x} \AND \mathring{y}) \equiv \contradiction \OR (\dot{x} \AND \mathring{y}) \equiv \dot{x} \AND \mathring{y}$. By symmetry, $\dot{y} \equiv \mathring{x} \AND \dot{y}$.
		
		To conclude, let $\mathring{x} \in X$ and $\mathring{y} \in Y$ be the two residual possibilities. The conjunction $\mathring{x} \AND \mathring{y}$ corresponds to a minterm where all the elements of the basis are negated. Therefore $\mathring{x} \AND \mathring{y}$ is the residual possibility of the combined domain, if it is not a contradiction. 
		
		Generalizing to a countable set of incompatible domains, the conjunction of all the residual possibilities $\mathring{x}= \bigAND_{i=1}^{\infty} \mathring{x}_i$ is the residual possibility of the combined domain, if it is not a contradiction. The only other conjunctions of the form $x= \bigAND_{i=1}^{\infty} x_i$ with $x_i \in X_i$ for all $i \geq 1$ that are not contradictions are those where only one element is not a residual possibility. Those correspond to the established possibilities. But each of those conjunctions will be equivalent to the only element that is not a residual possibility. Therefore each established possibility of the combined domain is equivalent to an established possibility of one of the original domains: $\dot{X} = \bigcup\limits_{i=1}^{\infty} \dot{X}_i$. Given that the established possibilities of two incompatible domains are incompatible and therefore different, we have $\dot{X}_i \cap \dot{X}_j = \emptyset$ for all $i,j \geq 1$ and $i \neq j$. The established possibilities of the combined domains are the disjoint union of the established possibilities of the individual domains.
	\end{proof}
	\begin{defn}
		Let $\{(X_i, \mathsf{T}_i)\}_{i=1}^{\infty}$ be a countable set of topological spaces. Let $X=\coprod\limits_{i=1}^{\infty} X_i$ be the disjoint union of the points. The \textbf{disjoint union topology} $\mathsf{T}$ is the topology for which $U \in \mathsf{T}$ if and only if $U \cap X_i \in \mathsf{T}_i$ for all $i \geq 1$.
	\end{defn}

	\begin{prop}\label{prop_disjoint_union_topology_is_closure}
		The disjoint union topology is generated by closing the topology of the initial spaces under disjoint union.
	\end{prop}
    \begin{proof}
		First we show that all disjoint unions of verifiable sets are part of the disjoint union topology. Let $\{(X_i, \mathsf{T}_i)\}_{i=1}^{\infty}$ be a countable set of topological spaces and $(X, \mathsf{T})$ their disjoint union with the disjoint union topology. Any disjoint union of verifiable sets can be put in the form $U=\coprod\limits_{i=1}^{\infty} U_i$ with $U_i \in \mathsf{T}_i$ for all $i \geq 1$. We have $U \cap X_i = \coprod\limits_{i=j}^{\infty} U_j \cap X_i = U_i$ for all $i \geq 1$. Therefore $U \in \mathsf{T}$ by definition.
		
		Now we show that any set in the disjoint union topology is the disjoint union of verifiable sets of the individual topologies. Let $U \in \mathsf{T}$. Since $U \subseteq X$ and $X$ is the disjoint union for all $X_i$, we can write $U=\coprod\limits_{i=1}^{\infty} U_i$. As before $U \cap X_i = U_i$ for all $i \geq 1$ and, since $U \cap X_i \in \mathsf{T}_i$ for all $i \geq 1$ by definition of the disjoint union topology, $U_i \in \mathsf{T}_i$ for all $i \geq 1$. Therefore any $U \in \mathsf{T}$ is the disjoint union of verifiable sets.
		
		This also shows that the disjoint union topology is a topology since it is closed under arbitrary union by definition, it is closed under finite intersection within each topology and it is closed under finite intersection across topologies since their intersection is always the empty set.
    \end{proof}

	\begin{prop}
		Let $\{\edomain_{X_i}\}_{i=1}^{\infty}$ be a countable set of pair-wise incompatible domains. The natural topology for the established possibilities of the combined experimental domain $\edomain_{\coprod\limits_{i=1}^{\infty} X_i}$ is the disjoint union topology of the natural topology for the established possibilities of each domain.
	\end{prop}
	\begin{proof}
		Given that the domains are incompatible, they are also incomplete. The only statement in each domain $\edomain_{X_i}$ compatible with the respective residual possibility $\mathring{x}_i$ will be the tautology $\tautology$. This means the natural topology restricted to the established possibilities contains all the verifiable sets associated to the contradictions and to all verifiable statements. This will also be true for the combined domain $\edomain_{\coprod\limits_{i=1}^{\infty} X_i}$, if it is incomplete. If it is complete, then the established possibilities are the full possibilities and their natural topology coincides. Note that all verifiable statements in the combined domain can be generated from the verifiable statements of the individual domains. Also note that the conjunction between the different domains is a contradiction and therefore does not yield a new statement. Therefore all the statements whose verifiable sets form the topology on the established possibilities on the combined domain can be generated by the disjunction of all the statements whose verifiable sets form  the topology on the established possibilities on the individual domains. Therefore the topology of the combined space is simply closing the individual topologies under the disjoint union. The topology of the combined space is therefore the disjoint union topology by \ref{prop_disjoint_union_topology_is_closure}
	\end{proof}
\end{mathSection}

For topologies, as well as for other mathematical structures, we can choose between two types of products. If we have two one dimensional euclidean spaces we can decide whether to take their product (i.e. the plane) or their co-product (i.e. the disjoint union of the two lines). For experimental domains we do not choose: it is what it is. There is no way to combine the two experimental domains for temperature and height of the same mercury column and get the Cartesian product of their possibilities. Though combining two independent domains mimics the categorical product and combining two incompatible domains mimics the categorical co-product, it is the semantic (and ultimately physical) relationship between them that decides which product we have. This is another case where the mathematical structures ``forget" the full equivalence. The topology only captures how the temperature and height can be measured, and not whether they are independent, dependent or incompatible. That information lies outside of the topology and therefore needs to be added by choosing the correct combination.

\section{Experimental domain for experimental relationships}

Now that we have seen how to describe relationships between domains, we should ask: are experimental relationships themselves something we can experimentally verify? We may know that there is a relationship between the temperature of a mercury column and its height, but how can we confirm experimentally which one it is?

The main result of this section is to show that, given two related experimental domains, we can always mathematically construct from them another experimental domain for which the possibilities are continuous functions between the possibilities of the original domains. This means that, since we can recursively create relationship domains about relationship domains, the universe of discourse of our mathematical framework is closed. Yet, the availability of the experimental tests (i.e. whether the statements we construct are actually verifiable) is not guaranteed.

Suppose we have a way to verify experimentally statements of the type \statement{if the temperature of the mercury column is between 24 and 25 Celsius then its height is between 24 and 25 millimeters}. That is, we can verify that whenever $\stmt_X=$\statement{the temperature of the mercury column is between 24 and 25 Celsius} is verified, then $\stmt_Y=$\statement{the height of the mercury column is between 24 and 25 millimeters} is verified. In that case, we can explore the connection between the two domains within different ranges at ever increasing precision. This means we can narrow the range of possible functions in the same way that we can narrow the range of possible values for a quantity. In other words, those types of statements form an experimental domain where each possibility corresponds to a possible continuous function between the two initial experimental domains.

\begin{mathSection}
	\begin{axiom}\label{def_implication_of_statement}
	Given two statements, we can always construct another one that is true only if the first statement is narrower than the second. Formally, the set of all statements $\mathcal{S}$ is equipped with a function $\narrower : \mathcal{S} \times \mathcal{S} \to \mathcal{S}$ such that $\truth(\narrower(\stmt_1, \stmt_2))) = \TRUE$ if and only if $\stmt_1 \narrower \stmt_2$.
	\end{axiom}
	\begin{defn}
		Let $\edomain_X$ and $\edomain_Y$ be two experimental domains such that the second is dependent on the first. Let $\basis_X \subseteq \edomain_X$,  $\basis_Y \subseteq \edomain_Y$ be the two countable basis of the respective domains. Suppose the statements of the form
		$\narrower(\obs[e]_x, \obs[e]_y)$, where $\obs[e]_x \in \basis_X$ and $ \obs[e]_y \in \basis_Y$, are verifiable. Then the \textbf{relationship domain} $\edomain_{C(X,Y)}$ is the experimental domain generated by the said verifiable statements.
	\end{defn}
	\begin{proof}
		The only thing that needs to be checked is that the basis that generates $\edomain_{C(X,Y)}$ is countable. Since $\basis_X$ and $\basis_Y$ are countable, the set of statements of the form $\narrower(\obs[e]_x, \obs[e]_y)$ with $\obs[e]_x \in \basis_X$ and $ \obs[e]_y \in \basis_Y$ is also countable.
	\end{proof}
\begin{prop}
	The possibilities for a relationship domain $\edomain_{C(X,Y)}$ coincide with the possible experimental relationships between $X$ and $Y$. That is, for each possibility $z$ of $\edomain_{C(X,Y)}$ there exists a continuous function $f : X \to Y$ such that $z\equiv\bigAND\limits_{x\in X} \narrower(x, f(x))$.
\end{prop}
\begin{proof}
	To show $z\equiv\bigAND\limits_{x\in X} \narrower(x, f(x))$, we first show that the first is narrower than the second. Let $z$ be a possibility of $\edomain_{C(X,Y)}$. Let $x \in X$ and $y \in Y$ be two possibilities of the respective spaces. We have $x \narrower y$ if and only if for all pairs $(e_x, e_y) \in \basis_X \times \basis_Y$  such that $x \narrower e_x$ and $e_x \narrower e_y$ we also have $y \narrower e_y$. Since by \ref{prop_poss_is_minterm} $z$ is a minterm of the basis of $\edomain_{C(X,Y)}$, if true it determines the truth values of all statements of the form $\narrower (e_x, e_y)$ and therefore we will either have $z \AND \narrower (x, y) \equiv z$ or $z \AND \narrower (x,y) \equiv \contradiction$.
	
	Given that $\edomain_Y$ depends on $\edomain_X$, there exists a continuous function $f : X \to Y$ such that $x \narrower f(x)$ for all $x \in X$. This means that, for each possibility $z$ of the relationship domain, there must exist an $f$ such that $z \AND \bigAND\limits_{x\in X} \narrower(x,f(x)) \nequiv \contradiction$ or $z$ would not allow a consistent truth assignment. Combining with the result of the previous paragraph, $z \AND \bigAND\limits_{x\in X} \narrower(x,f(x)) \equiv z$.
	
	Next we show that narrowness also works in the other direction. Consider $e_x \narrower e_y$ for some $e_x \in \basis_X$ and $e_y \in \basis_Y$. Since $x \narrower f(x)$ for some continuous function $f$, $e_x \narrower e_y$ is true if and only if for all $x \in e_x$ we have $f(x) \in e_y$. Therefore either $\bigAND\limits_{x\in X} \narrower(x,f(x)) \AND \narrower(e_x, e_y) \equiv \bigAND\limits_{x\in X} \narrower(x,f(x))$ or $\bigAND\limits_{x\in X} \narrower(x,f(x)) \AND \narrower(e_x, e_y) \equiv \contradiction$. Recall that $z$ is a collection of minterms and that for each $z$ we must have an $f$ such that $\bigAND\limits_{x\in X} \narrower(x,f(x)) \AND z \nequiv \contradiction$. This means that we also have $\bigAND\limits_{x\in X} \narrower(x,f(x)) \AND z \equiv \bigAND\limits_{x\in X} \narrower(x,f(x))$.
	
	Combining all results, we have $z \AND \bigAND\limits_{x\in X} \narrower(x,f(x)) \equiv z \equiv \bigAND\limits_{x\in X} \narrower(x,f(x))$.
\end{proof}
\end{mathSection}

Note that the definition for the relationship domain simply says that one can be constructed provided we have a way to verify such if/then statements. It does not guarantee that this is actually possible. So when can we do it? Or better, what do we need in practice to be able to build the necessary confidence? Let's think how we would test the relationship between temperature and height of a mercury column. We would prepare different mercury samples with different values of temperatures in many different conditions, measure height and temperature with different devices, repeat many times, ask someone else to do it independently, compare results, and so on. At some point we will have explored enough of the possible cases, checked and tried anything that could invalidate the result and we will have the confidence to say that \statement{if the temperature of the mercury column is between 24 and 25 Celsius then its height is between 24 and 25 millimeters}. We should stress that the procedure is not at all to observe a few values and then generalize. It is the ability to prepare and control the system in many different conditions and our inability to violate the relationship that gives us the confidence needed to reach the conclusion.

Suppose, in fact, that we want to experimentally verify the link between inflation and money supply. As long as we cannot create new countries in different economic conditions, the only thing we can do is gather data for as many nations as we can throughout history.\footnote{Computer simulations can sometimes alleviate this problem, though they are only as good as the model one uses.} Since we cannot purposely explore different conditions and we can't even replicate older ones, the best we can do is show that there was a correlation between those specific values. It is the inability to freely and fully explore the problem space that may not enable us to experimentally verify the causal relationship.\footnote{In this sense, experimental sciences allow for more rigorous results than observational sciences precisely because it is more feasible to experimentally test relationships between domains.}

The point is that we cannot give a general purpose algorithm for how to construct experimental tests for the relationships starting from the experimental tests of the individual domain. We cannot formalize in general what it means that we have explored the space ``enough" to consider the relationship verified, no more than we can formalize when the data collected is ``enough" to consider a statement verified or when a statement is specific ``enough" to consider the semantics well defined. This is where the practice of experimental science comes in.

But, while we may not know in general whether we can experimentally verify a relationship between two specific domains, we do know that the relationship domain can always be constructed in principle and therefore our mathematical framework is complete. That is: we can take two experimental domains (e.g. $\edomain_t$ for time and $\edomain_x$ for position), construct a relationship domain between them (e.g. $\edomain_{x(t)}$ for trajectories in space), then take another experimental domain (e.g. $\edomain_{(q,p)}$ for the states) and construct another relationship domain between the two (e.g. $\edomain_{(q,p)\to x(t)}$ for the relationship between states and trajectories). Our general mathematical theory of experimental science is therefore closed, since we can recursively create relationship domains about relationship domains indefinitely while remaining within its bounds. In other words, we cannot create relationships between domains that lie outside of the theory.

\section{Properties and quantities}

Most of the time we characterize a system by qualifying one or more of its properties, some of which are quantifiable. For example, \statement{this animal is of genus Passer} or \statement{the mass of the electron is between $9.108 \times 10^{-31}$ and $9.110 \times 10^{-31}$ kg}. Therefore we need to properly define what we mean by properties and quantities in our framework and how they relate to the mathematical structures defined before.

First we'll introduce the idea of using properties to differentiate a possibility from the others within a domain. A property can be either a physical one (e.g. the beak color of a bird) or one we define by convention (e.g. the taxonomy name for an animal species). Quantities are properties that have a magnitude: we can compare two different values and determine which one is greater or smaller. For example, groups of individuals can be labeled by their count and distances can be labeled in meters. In particular, we will define discrete quantities (those that correspond to integers and are associated to decidable possibilities) and continuous quantities (those that correspond to real numbers and are associated with arbitrary precision statements).

Suppose $\edomain_X$ is a domain for animal identification and $X$, its possibilities, are all animal species. Providing good names and definitions for species is a whole scientific subject by itself (i.e. taxonomy) with its own rules (i.e. the International Code of Zoological Nomenclature). The ICZN assigns each species a name composed of two Latin words. For example, \statement{Passer domesticus} is the official name for the house sparrow while \statement{Passer italiae} is the one for the Italian sparrow. So, if $\mathcal{Q}$ is the set of all the names for all species, we have a function $q: X \to \mathcal{Q}$ from the species to its name. Since each species is given a unique name the function is invertible as well. This is the most discriminating type of property: one that covers the whole range of possibilities and fully identifies each of them. But this is a special case.

The ICZN also assigns a genus (pl. genera) to each species, which corresponds to the first part of the species name. For example, both aforementioned sparrows are of the genus \statement{Passer} while all swans, black or white, are of the genus \statement{Cygnus}. Now suppose that $\mathcal{Q}$ is the set of all names for all genera and $q: X \to \mathcal{Q}$ is the function that gives us the genus name for each species. We can still use this as a label for our possibilities, but it does not fully identify them. On a different note, we could decide to distinguish species by their morphological attributes. For example, if $\mathcal{Q}$ is the set of all colors, we can imagine a partial function $q: X \to \mathcal{Q}$ that gives us the beak color for each species, if they have one. While this is less general, it is still a valid label. In fact, it is with such labels that animal classification began.

Other examples of properties include: postal addresses for buildings, tax ID numbers for people, generation for fundamental particles, position of the center of mass of a body. In all these cases, the general pattern is that we assign a label to a possibility from an established set.

\begin{mathSection}
	\begin{defn}
		A \textbf{property} for an experimental domain $\edomain_X$ is any attribute we can use to distinguish between its possibilities. Formally, it is a tuple $(\mathcal{Q}, q)$ where $\mathcal{Q}$ is a topological space and $q : U \to \mathcal{Q}$ is continuous function where $U \in \mathsf{T}_X$ is a verifiable set of possibilities.
	\end{defn}
	\begin{justification}
		For the property to be physically meaningful, the domain of $q$ must be a verifiable set in the topology as we must be able to tell experimentally when the property is defined or not. For example, we must be able to tell whether an animal has a beak if we want to define the beak color. Therefore there must be a verifiable statement that is true if the property is defined. This corresponds to the verifiable set $U$, the domain of the property.
		
		Similarly, $\mathcal{Q}$ must be a topological space since we must be able to experimentally test the value for the property. For example, we can look at the beak color or we can look up the species name in a bird guide. Furthermore $q$ must be continuous since there must be a causal relationship between the possibility and the value of the property. For example, the species of the animal determines the color of the beak.
		
		We do not define, though, a property itself as an experimental domain. The idea is that the property is defined independently of any particular object. For example, distance in meters is defined independently of whether we later want to measure the earth diameter or its distance to the moon. The latter two would correspond to two experimental domains with their possibilities. This also means that the range of values defined by the property may exceed the ones possible in each particular case. For example, we are able to recognize a lavender beak even though no animal species may have one.
	\end{justification}
	\begin{defn}
		The possibilities of an experimental domain are \textbf{fully identified} by a property if its value is enough to uniquely determine a possibility. Formally, let $(\mathcal{Q}, q)$ be a property for an experimental domain $\edomain_X$. Then the possibilities $X$ are fully identified if $q: X \to \mathcal{Q}$ is injective.
	\end{defn}

	\begin{defn}
		An experimental domain is \textbf{fully characterized} by a property if there is a one to one correspondence between possibilities and property values. Formally, let $(\mathcal{Q}, q)$ be a property for an experimental domain $\edomain_X$. Then it is fully characterized if $q: X \to \mathcal{Q}$ is a homeomorphism.
	\end{defn}

	\begin{justification}
		Formally speaking, the one to one correspondence between possibilities and property values only implies that $q: X \to \mathcal{Q}$ is bijective and continuous. This, though, would not be sufficient to fully characterize the domain. We need that each verifiable statement on the property values corresponds to a verifiable statement on the possibilities. That is, the property tells us not only what possibilities exist, but also which statements can be experimentally verified. Therefore each open set of property values must correspond to an open set in the natural topology of the possibilities.		 
	\end{justification}
\end{mathSection}

The difference between properties that fully identify and fully characterize the domain is subtle. Consider the experimental domain for identifying negatively charged fundamental particles. The mass in eV is enough to determine the particle, therefore it fully identifies the possibilities. But, given that the range of mass is continuous, we can't know a priori which particular values of mass correspond to an actual particle. In this sense, the mass as a continuous quantity expressed in eV is not enough to fully characterize the experimental domain, which is in fact discrete. Somebody would have to tell us what the allowed values are. On the other hand, consider the experimental domain for the position of the center of mass of a particle along a particular direction. The distance from a fixed point is enough to identify the position, therefore it fully identifies the possibilities. But for each value of the distance we also have a possible position of the particle: the property fully characterizes the domain.

Let's now turn our attention to those properties that can be quantified. The number of elements of a group can be quantified by an integer, the distance between two objects can be quantified in meters, the force acting on a body can be quantified by the magnitude of a vector expressed in Newtons. The defining characteristic for a quantity is that a value can be greater, smaller or equal to another. That is: we have an ordering defined on our labels.
	
\begin{mathSection}
	\begin{defn}
		A \textbf{total order} on a set $\mathcal{Q}$ is a relationship $\leq : \mathcal{Q} \times \mathcal{Q} \to \mathbb{B}$ such that:
		\begin{enumerate}
			\item (antisymmetry) if $q_1 \leq q_2$ and $q_2 \leq q_1$ then $q_1 = q_2$
			\item (transitivity) if $q_1 \leq q_2$ and $q_2 \leq q_3$ then $q_1 \leq q_3$
			\item (total) at least $q_1 \leq q_2$ or $q_2 \leq q_1$
		\end{enumerate}
	\end{defn}
\begin{defn}
	Let $\mathcal{Q}$ be a topological space and $\leq : \mathcal{Q} \times \mathcal{Q} \to \mathbb{B}$ a total order. The \textbf{order topology} is the topology generated by the collections of sets of the form:
	$$(a, \infty) = \{x \in \mathcal{Q} \, | \, a < x\} \;,\; (-\infty, b) = \{x \in \mathcal{Q} \, | \, x < b\}.$$
\end{defn}
\begin{defn}
	A \textbf{quantity} for an experimental domain $\edomain_X$ is an ordered property. Formally, it is a tuple $(\mathcal{Q}, \leq, q)$ where $(\mathcal{Q}, q)$ is a property, $\leq : \mathcal{Q} \times \mathcal{Q} \to \mathbb{B}$ is a total order and $\mathcal{Q}$ is a topological space with the order topology with respect to $\leq$.
\end{defn}
\end{mathSection}

\subsection{Decidable domains and discrete quantities}

If the possible values of a quantity are the integers (positive or negative) we say the quantity is discrete. For example, the number of chromosomes for a species, the number of inhabitants of a country or the atomic number for an element are all discrete quantities.

\begin{mathSection}
\begin{defn}
	A \textbf{discrete quantity} for an experimental domain $\edomain_X$ is a quantity $(\mathbb{Z}, \leq, q)$ where $\mathbb{Z}$ is the set of integers.
\end{defn}
\end{mathSection}

There is a special relationship between discrete quantities and decidability, the ability to test experimentally both the truthfulness and falsehood of a statement. Consider the examples above of discrete quantities: in each case we can experimentally test whether we have a particular value or not. For example, we are always able to tell whether an element has three protons or not.\footnote{Recall that this is not the case with continuous quantities. Because of uncertainty of measurement, we are able to exclude that a given particle has exactly zero mass but it is not possible to conclusively show that it has zero mass.} It turns out that whenever we have a domain consisting of only decidable statements, we can always create a discrete quantity that fully characterizes the experimental domain.

\begin{mathSection}
	
	\begin{defn}
		An experimental domain $\edomain_X$ is \textbf{decidable} if all statements in the domain are decidable. Formally, for every $\obs \in \edomain_X$ we have $\NOT\obs \in \edomain_X$.
	\end{defn}

	\begin{prop}
		The set of possibilities $X$ for a decidable domain $\edomain_X$ is also a countable basis.
	\end{prop}
	
	\begin{proof}
		First we show that $X$ is a basis. The decidable domain $\edomain_X$ is already closed under negation, so it coincides with the theoretical domain $\tdomain_X$. The set of possibilities $X$ is therefore a set of verifiable statements. The possibilities can generate all other statements through disjunction, therefore $X$ is a basis.
		
		Now we just need to show that $X$ is countable. Consider a countable basis $\basis \subseteq \edomain_X$. Because the possibilities are verifiable statements, they can be generated from $\basis$ by finite conjunction and countable disjunction. Moreover, since the possibilities are the narrowest statements that are not contradictions, they can be generated from $\basis$ using finite conjunction only. Since $\basis$ is countable and $X$ is generated by $\basis$ through finite conjunction, $X$ can be at most countable. Therefore $X$ is a countable basis.
	\end{proof}
		
	\begin{defn}
		A topology $\mathsf{T}_X$ on a set $X$ is called \textbf{discrete} if it contains every subset of $X$.
	\end{defn}
	
\begin{thrm}[Decidability is discreteness]\label{thrm_decidablity_is_discreteness}
	The natural topology of the possibilities $X$ for a domain $\edomain_X$ is discrete if and only if the domain is decidable.
\end{thrm}
\begin{proof}
	Suppose $\edomain_X$ is decidable. Let $U \subseteq X$ be a subset of possibilities. The statement $\stmt = \bigOR\limits_{x \in U} x$ is generated from $X$ through countable disjunction. Since $\edomain_X$ is decidable, $X$ is a countable basis and $\stmt$ is verifiable. Therefore $U$ is a verifiable set and it is contained in the natural topology. The natural topology of $X$ is discrete by definition.
	
	Now suppose $\edomain_X$ is such that the natural topology for its possibilities $X$ is discrete. Let $\stmt = \bigOR\limits_{x \in U} x$ be a statement. Since the topology is discrete, $U$ is part of the topology and $\stmt$ is verifiable. Consider its negation $\NOT\stmt = \bigOR\limits_{x \in U^C} x$. Since the topology is discrete, $U^C$ is also part of the topology and $\NOT\stmt$ is verifiable. This means $\stmt$ is decidable. Since every statement in $\edomain_X$ is decidable, the domain is decidable.
\end{proof}
	
\begin{prop}
	The order topology for the integers is discrete.
\end{prop}
\begin{proof}
	Each singleton $\{z\} \subseteq \mathbb{Z}$ is in the order topology since $\{z\} = (z-1, \infty) \cap (-\infty, z+1)$. Each arbitrary set of integers is the union of singletons and is therefore in the order topology as well. The order topology on the integers is discrete.
\end{proof}
	
	\begin{prop}
		An experimental domain is decidable if and only if it is fully characterized by a discrete quantity.
	\end{prop}
	
	\begin{proof}
		Let $\edomain_X$ be a decidable domain. Then the set of possibilities $X$ is countable and the natural topology is discrete. Since $X$ is countable, there exists a bijective map $q: X \to \mathbb{Z}$. The map is a homeomorphism since the topology on both $X$ and $\mathbb{Z}$ is discrete. The domain $\edomain_X$ is fully identified by $(\mathbb{Z}, \leq, q)$.
		
		Let $\edomain_X$ be fully characterized by $(\mathbb{Z}, \leq, q)$. This means that $q : X \to \mathbb{Z}$ is a homeomorphism. The natural topology for $X$ is therefore discrete and the domain is decidable by \ref{thrm_decidablity_is_discreteness}.
	\end{proof}	
	
\end{mathSection}

Note that for the link between decidability and discrete quantities to apply, it is crucial the quantity is measurable: that we can actually experimentally ascertain its values. Consider the domain with the possibilities \statement{there is no extra-terrestrial life} and \statement{there is extra-terrestrial life}. We can arbitrarily label 0 the former and 1 the latter. But since we cannot verify the first statement, we cannot really ``measure'' 0. In that case, the domain is fully identified by the discrete quantity, but not fully characterized: we still need to say what values are measurable.

\subsection{Arbitrary precision and continuous quantities}

If the possible values of a quantity are the real numbers we say the quantity is continuous. For example, the average wingspan for a species, the population density of a country or the mass of a proton are all continuous quantities.

\begin{mathSection}
	\begin{defn}
		A \textbf{continuous quantity} for an experimental domain $\edomain_X$ is a quantity $(\mathbb{R}, \leq, q)$ where $\mathbb{R}$ is the set of the real numbers.
	\end{defn}
\end{mathSection}

There is a special relationship between continuous quantities and the ability to measure the value with arbitrary precision. Consider the examples above of continuous quantities: in each we can never experimentally ascertain the precise value, but we can (in principle) measure it to the desired level of precision. It turns out that whenever we can measure a quantity with arbitrary precision, we can always assign a continuous value to each possibility.

\begin{mathSection}
	
	\begin{defn}
		An experimental domain $\edomain_X$ is said to allow \textbf{arbitrary precision} if it describes a quantity measurable with arbitrary precision. Formally, there exists a countable basis $\basis \subseteq \edomain_X$ such that:
		\begin{itemize}
			\item we can define a function $\operatorname{bounds} : \basis \to \mathbb{Q} \times \mathbb{Q}$ such that $\operatorname{bounds}(\stmt) = (a, b)$ is a tuple where $a < b$ for all $\stmt \in \basis$
			\item for every pair of rational numbers $(a, b) \in \mathbb{Q} \times \mathbb{Q}$ there exists an $\obs \in \basis$ such that $\operatorname{bounds}(\stmt) = (a, b)$
			\item if $\stmt = \stmt_1 \AND \stmt_2$, $\operatorname{bounds}(\stmt_1) = (a_1, b_1)$ and $\operatorname{bounds}(\stmt_2) = (a_2, b_2)$, then $\stmt \equiv \contradiction$ if $b_1 \leq a_2$ or $b_2 \leq a_1$ otherwise $\stmt \nequiv \contradiction$ and $\operatorname{bounds}(\stmt) = (\max(a_1, a_2), \min(b_1, b_2))$
		\end{itemize}
	\end{defn}
	
	\begin{defn}
		We call \textbf{standard topology} for the real numbers $\mathbb{R}$ the one generated by the collections of sets $\mathcal{B} = \{ (a,b) \subset \mathbb{R} \; | \; a,b \in \mathbb{Q} \}$ of all open intervals between rational numbers $\mathbb{Q}$.
	\end{defn}
	
	\begin{thrm}[Arbitrary precision is continuity]\label{thrm_arbitrary_precision_is_continuity}
		Given an experimental domain $\edomain_X$, the set of possibilities with their natural topology is homeomorphic to the reals with the standard topology if and only if the domain allows arbitrary precision.
	\end{thrm}
	\begin{proof}
		The first step is to show that each possibility can be assigned a unique real number. Let $\edomain_X$ allow arbitrary precision and let $\basis \subseteq \edomain_X$ be a countable basis on which the rational bounds are defined. A possibility $x$ is a minterm of such statements. Let $\basis_x =\{\obs[e]^x_i\}_{i=1}^{\infty} \subset \basis$ be the statements that are compatible with the possibility $x$. The set is countable since $\basis$ is countable.
		
		Consider the sequence $\{\stmt_j\}_{j=1}^{\infty}$ where $\stmt_j = \bigAND\limits_{i=1}^j\{\obs[e]^x_i\}$ is the conjunction of the first $j$ elements. For each element we have $\operatorname{bounds}(\stmt_j) = (a_j, b_j)$. The sequence formed by $\{a_j\}_{j=1}^{\infty}$ is monotonically increasing as the lower bound cannot decrease during conjunction. The sequence formed by $\{b_j\}_{j=1}^{\infty}$ is monotonically decreasing as the upper bound cannot increase during conjunction. For each $j$ we have $a_j < b_j$, therefore both sequences are bound which means they both converge. Consider the sequence $c_j = b_j - a_j$. It must converge since it's the difference between two converging sequences. It cannot converge to a negative number since $a_j < b_j$ for all $j$. It cannot converge to a positive number: suppose it would, then we would be able to construct a statement strictly narrower than the limit of the sequence $\{\stmt_j\}_{j=1}^{\infty}$, but that is not possible since the limit is the possibility $x$ and only the contradiction is strictly narrower than a possibility. Therefore $c_j$ converges to zero and $a_j$ and $b_j$ are two equivalent Cauchy sequences of rational numbers. We can repeat the construction by reordering the elements of $\basis_x$. We would obtain different Cauchy sequences that are also equivalent to the first two. Each possibility $x$, then, is an equivalence class for the Cauchy sequences of the rational numbers. But this is a standard way to construct the real numbers; therefore each possibility $x$ can be assigned to a real number.
		
		Now we show that the natural topology is the standard topology for the reals. The verifiable set for each element of $\basis$ is the set of real numbers contained between the bounds: it is the open interval $(a,b)$. This means that the natural topology is the one generated by the collections of sets $\mathcal{B} = \{ (a,b) \subset \mathbb{R} \; | \; a,b \in \mathbb{Q} \}$ of all open intervals of rational numbers $\mathbb{Q}$. The natural topology is the standard topology for the real numbers.
		
		Lastly, we prove the opposite direction. Let $\edomain_X$ be an experimental domain such that the set of possibilities is homeomorphic to the real numbers with the standard topology. Since the collection of all open intervals of rational numbers forms a subbasis of the topology, the statements associated with those verifiable sets form a basis for the experimental domain. To each statement in the set we can associate the bounds of the open set satisfying the definition of an arbitrary precision domain.
	\end{proof}
	
	\begin{prop}
		The order topology for the real numbers is the standard topology.
	\end{prop}
	\begin{proof}
		To show that they are equivalent, we show that the subbasis of one generates the subbasis of the other. Let $a,b \in \mathbb{Q}$ be two rationals. The sets $(-\infty, b)$ and $(a, \infty)$ are in the subbasis of the order topology. Their intersection is the set $(a, b)$ of the standard topology. The subbasis of the standard topology can be generated by the order topology.
		
		Conversely, let $a \in \mathbb{R}$ be a real number. Let $\{U_i\}_{i \in I}$ be the collection of all sets $U_i = (a_i, b_i)$ such that $a_i, b_i \in \mathbb{Q}$ and $a < a_i$. These sets are in the subbasis of the standard topology. We have $\bigcup\limits_{i \in I} U_i = (a, \infty)$. In the same way, let $b \in \mathbb{R}$ be a real number. Let $\{V_j\}_{j \in J}$ be the collection of all sets $V_j = (a_j, b_j)$ such that $a_j, b_j \in \mathbb{Q}$ and $b_j < b$. These sets are in the subbasis of the standard topology. We have $\bigcup\limits_{j \in J} V_j = (-\infty, b)$. The subbasis of the order topology can be generated by the standard topology.
	\end{proof}
	
	\begin{prop}
		An experimental domain allows arbitrary precision if and only if it is fully characterized by a continuous quantity.
	\end{prop}

	\begin{proof}
		If an experimental domain allows arbitrary precision then the set of possibilities with the natural topology is homeomorphic to the real numbers with the standard topology, which is also the order topology. Therefore we can construct a continuous quantity that fully characterizes the possibilities. Conversely, if the domain is fully characterized by a continuous quantity, then the set of real numbers with the order topology, which is also the standard topology, is homeomophic to the set of possibilities with the natural topology. Therefore the domain allows arbitrary precision by \ref{thrm_arbitrary_precision_is_continuity}.
	\end{proof}	
\end{mathSection}

The construction we presented here clarifies a couple of important aspects about continuous quantities. First of all, finite precision measurements are the starting point: those are the ones actually possible. Second, the idea that we can always refine the precision of our measurements is clearly an idealization: at some point we are bound to encounter the physical limitation of either our measurement process or of our definitions. For example, measuring the inner diameter of a gas container with a ruler can only get us so far. Moreover at some point, since a gas is made of molecules and a lot of empty space in between, defining very precisely when the gas ends and the container begins becomes problematic (and of limited utility). So, while the coarse precision measurements are physically meaningful, the finer measurements may not be. Third, real numbers (i.e. the possibilities of an arbitrary precision domain) are abstractions based on the idealization of an arbitrary precision measurement. They are not verifiable statements: we cannot measure a continuous quantity with infinite precision. They exist only in so far that our idealization holds. They are indeed useful ways to model the domain but we should be very cautious in assigning them a real tangible status.

This may be contrary to the way many people see the relationship between mathematical and physical objects. Some may feel that the geometric description, with its infinite precision, is the perfect one while the physical one, with the inherent measurement uncertainties, is the less precise one. Actually, it is quite the opposite: the bounds of a measurement better qualify our description and knowledge while the geometrical description provides a simplified, idealized and therefore less precise account. In other words, $3.14 \pm 0.005$ is something that actually exists while $\pi$ is the approximation.

Why, then, are continuous quantities so successful in science? We will look at this question in detail when we introduce the assumption of deterministic and reversible evolution. We'll see that the role of time is crucial. Time is the quantity that we want to assume continuous (i.e. that there is always an instant between two others). Because we want to describe deterministic and reversible systems, we will have an experimental relationship between time and all other quantities during the evolution. Which means that the way we assume time can be measured (i.e. its topology) will need to be consistent with the way those other quantities can be measured as well during deterministic and reversible evolution.

To sum up, we should regard the real numbers for what they are: the limit of an infinite process of subdivision (i.e. the limit of a Cauchy sequence). But this process, in reality, cannot go on forever.

\section{Summary}

In this chapter we have seen the first important consequences of our general mathematical theory of experimental science. We have seen that experimental relationships between domains can be defined in terms of inference between verifiable statements or equivalently in terms of causal relationship between possibilities. The causal relationship always corresponds to a continuous function in the natural topology. Moreover, it always needs to preserve any mathematical structure that captures some physical relationship within the domain.

We have also seen how to combine a set of countably many experimental domains and how the combined possibilities depend on the logical relationships that exist across domains. We can have the scalar product of the possibilities (with the product topology) all the way to the disjoint union of the established possibilities (with the disjoint union topology).

We have shown that it is possible to construct experimental domains for the relationships themselves. This means that within our theory we can describe relationships of arbitrarily higher order (i.e. relationships about relationships) and therefore we never go outside of our framework.

We have also seen how we can identify the possibilities of a domain using properties and quantities and the intimate connection between discrete quantities and decidability on one side and between continuous quantities and arbitrary precision on the other side.

We should stress that we have only explored simple constructions based on the original concepts and yet we have already made far-reaching conclusions. These will have numerous consequences throughout the rest of this work. 

\appendix

\chapter{Exploratory section}

\section{Side tracks}

This chapter lists ideas to be explored further. These are problems left open as they are not critical for the foundation of the work, but are nonetheless interesting. Some of these may very well turn out to be dead ends or not as interesting as they sound.

\subsection{Chapter 1 - can we construct set theory?}

One thing to explore is whether the same ideas can be extended to be used as a foundation for set theory. From what I understand, axiomatic set theory is developed to avoid paradoxes: proposition that if true prove their falsehood. For example: (Russel's paradox) does the set of all sets that do not contain themselves contain itself? Or (Berry's paradox) the set of all natural numbers that can be described in fewer than twenty words of the English language, which leads to ``the least natural number that cannot be described in fewer than twenty words of the English language", which we used less than twenty words to describe.

The way this is framed is that one needs to avoid the ability to construct predicates that allow to construct paradoxes. It uses two basic strategy. The first is to constrain statements to only ones formed with a formal language, which avoids the paradoxes of the semantic kind. The downside is that all ``real objects" are thrown out. The second strategy is to divide elements (things that can be contained) from classes (things that can contain things). Since the machinery we introduced puts at the same level ``logical" relationships (i.e. $\stmt$ and $\NOT\stmt$ can't both be true) with ``semantic" relationships (i.e. \statement{this is a dog} and \statement{this is a cat} can't both be true) maybe it can be used to solve both problems at the same time, without sacrificing the semantic.

One possible point of attack. We start with statements, like is done in this work, that are primary undefined objects. The formal operations do not ``construct" sentences, but simply pick statements from the universal set of statements. And since all statements have a well defined truth value, they can't be paradoxes. The basic axioms, then, enumerate all the rules one has to follow to construct statements from statements (i.e. that do not generate paradoxes). An object could simply be a set of statements (i.e. a particular chair is everything we can say about a chair, the number one is all the statements that we can say about it). A set, in particular, would be the set of statements that say what objects it contains. A predicate would be a function that given an element would give a statement. 

There may be a certain amount of circular reference in the basic definitions, but this does not seem to be a problem for computer languages.

\subsection{Chapter 1 - homogeneity of an experimental domain}

Probably an important property a domain can have is whether all possibilities can be equally verified. That is, the ``extra-terrestrial life" domain is not homogeneous because one possibility can be verified while the other cannot. While when we measure space, each point is equally verifiable from the other. It is not clear how this intuitive notion should be formalized, but it should have consequences. For example, it should give us a complete domain (since the residual possibility is not verifiable) and most likely it will give us approximately verifiable possibilities. In fact, it may coincide with approximately verifiable possibilities.

It could be something like: suppose $\stmt_a \narrower \stmt$ and $\stmt_b \narrower \stmt$. If the domain is homogeneous then for each $\stmt_a \narrower \stmt_1 \narrower \stmt$ we can find a $\stmt_a \narrower \stmt_2 \narrower \stmt$. If there is a verifiable statement in the middle in one case, there is a verifiable statement in the middle in the other case as well.

\subsection{Chapter 2 - predictive relationships}

Another way to characterize experimental relationships should be in terms of predictions. That is, we give a prediction (i.e. a theoretical statement) for the independent domain and this should correspond to the best prediction (i.e. theoretical statement) for the dependent domain. The idea is to find the correct mathematical representation for this.

A possible approach. Let $\edomain_X$ and $\edomain_y$ be two experimental domains and $\tdomain_X$ and $\tdomain_Y$ their respective theoretical domains. Let them be experimentally consistent, such that if a theoretical statement is in both domains, then it is verifiable for both or for neither. Suppose that a prediction for $\edomain_X$ gives us a prediction for $\edomain_Y$. That is, we are given a function $\pi: \tdomain_X \to \tdomain_Y$ such that $\pi(\tdomain_X) = \tdomain_Y$ and given $\stmt_X \in \tdomain_x$ and $\stmt_Y \in \tdomain_Y$ such that $\stmt_X \narrower \stmt_Y$ we always have $\stmt_X \narrower \pi(\stmt_X) \narrower \stmt_Y$. Under these assumption, can we prove that $\pi$ is a projection and that $\edomain_Y \subseteq \edomain_X$?

\subsection{Chapter 2 - structure preserving maps and experimental relationships}

Theorem \ref{thrm_domain_equivalence_is_isomorphism} shows the connection between domain equivalence and isomorphism. Is there a way to have a similar conclusion for domain dependence and homomorphism?

\subsection{Chapter 2 - defining structures on experimental domain instead of possibilities}

Some mathematical structures are defined on the points (i.e. vector spaces, ordering) and others on $\sigma$-algebra. In our context, verifiable statements are the only elements that are actually physical, therefore it would be nice to always define the structures on the experimental domain and show that it induces a unique structure on the theoretical statements and possibilities (and vice-versa).

For example, we could define a partial ordering on the finite precision statements, and show that, under suitable conditions, it gives us an ordering on the possibilities.

\subsection{Chapter 2 - space of possible combined domains}

It should be possible to better characterize the space of all possible combined domains. As we show that the space of the possible experimental relationships is the space of continuous functions, there should be an analogue for the space of all possible combined domains. For example, one should be able to show that the combined domain is an immersion within the product topology. Is that the only constraint? How can that be characterized? Can we create an experimental domain to distinguish them?

\subsection{Chapter 2 - continuous quantities}

It should be possible to define the requirement for arbitrary precision more abstractly, and therefore more generally. The general idea should be that if we have arbitrary precision it would mean that for each verifiable statement one can always find a set of narrower statements whose disjunction is the original statement. With the correct starting point one should then be able to arbitrarily assign pairs rational numbers to the bounds.

It may be necessary to require an ordering. This could be defined on the verifiable statements themselves. The idea would be to keep the basis of contiguous intervals. And then assign a partial ordering to those elements that are incompatible, which means they do not overlap. That is: if we have two contiguous intervals that do not overlap we can tell which is before the other.

\subsection{Chapter 2 - limited precision}

What type of space we have once we recognize that precision can't be arbitrary? How is it different from the continuous case? There are a few issues that are already identified.

The limited precision case can't simply lead to a discrete topology. The standard topology of the real is not the limit of the integer topology since it is not discrete. Most likely, the limited precision case will need to have uncountable possibilities so that the limit to arbitrary precision can work well.

The main cause of confusion is that, in the continuous case, overlapping of the precision and compatibility of the statements is the same. So ``position is between 0 and 1 meters" and ``position is between 2 and 3 meters" are both incompatible and not overlapping. This cannot be the case for limited precision. The possibilities themselves must be incompatible with each other but some of them must overlap. That is, suppose that 1 unit is the precision limit, the statements ``the position is between 0 and 1" and ``the position is between 0.5 and 1.5" are incompatible because if we measure one we cannot measure the other. If we could measure them both, we would measure at a smaller precision. So, overlapping cannot be defined in terms of incompatibility.

We can define overlapping in terms of precision: suppose we have following arbitrary precision statements.
\begin{description}
	\item $\stmt_1=$\statement{the position is between 0 and 1 meter}
	\item $\stmt_2=$\statement{the position is between 0.5 and 1.5 meter}
	\item $\stmt_3=$\statement{the position is between 2 and 3 meter}
\end{description}

The precision associated to all statements will be one meter. The precision for $\stmt_1\OR\stmt_2$ will be one meter and a half while the precision for $\stmt_1\OR\stmt_3$ will be two meters. That is: the precision for non overlapping statements sums. In the limited precision case, we can still recognize if two statement are not overlapping by checking the precision of the disjunction. It it simply sums, they do not overlap.

This has far reaching consequences. The measure associated to the real numbers is really the precision. Since we are saying that two incompatible statements are not necessarily non overlapping, we are saying that the ``measure" we define for limited precision does not sum if the open sets are disjoint. That is: it is not a measure mathematically. This means that many concepts built on top of the measure (e.g. probability, integration) may need to be revisited as well.

\section{Main track}

This chapter includes partially developed ideas toward the main goal of the work. Some of these may very well turn out to be dead ends.

\subsection{Sequences/probability}

One thing we'll need to recover/justify is probability theory. We already have sigma algebras, so we are not that far. One possible ideas is to link convergence of a sequence of truth values with the value of probability.

Here's a possible approach. A source is a sequence of truth values $s=\{t_i\}$. Two sources $s=\{t_i\}$ and $s=\{u_i\}$ are similar $s_1 \sim s_2$ if given $\epsilon > 0$ we can find an $N \in \mathbb{N}$ such that for all $a,b>N$ we have $\left| \frac{1}{a} \sum\limits_{i=1}^a t_i - \frac{1}{b} \sum\limits_{i=1}^b u_i \right| < \epsilon$. That is, at some point the number of truths from one is close to the number of truths of the other. A source is stable if it self-similar $s \sim s$. The average of a stable source converges as it satisfies the Cauchy condition. That average we call the probability.

This means that if we have a sequence of experimental domains, all constructed the same, we can create a sequence for each verifiable statement and assign a probability to all. Then we can prove that the probability is a measure and it sums to 1.

\subsection{Thermodynamics}

At some point we'll have to recover/justify thermodynamics. The idea is to study non-deterministic evolution, as opposed to deterministic/reversible evolution which gives Hamiltonian mechanics. We still have a reducible system, so the state is a distribution over the state of the parts. Deterministic and reversible processes conserve information entropy. Non-deterministic processes increase information entropy. Non-reversible processes decrease information entropy. Deterministic and reversible processes lead to Hamiltonian mechanics. Non-deterministic processes lead to max entropy.

Suppose you have a non-deterministic process. Either because it is influenced by an external system or because of unknown internal degrees of freedom. Since the evolution is non-deterministic, information entropy increases.

Suppose you have a constraint, i.e. conservation of energy. The constraints limits what states can be explored by the system. The non-deterministic evolution will push the state to the ones that have higher information entropy. If the constraint bounds the maximum information entropy to a finite value, the system will tend to those states.

Suppose the constraint is such that there is a unique state that corresponds to the maximum entropy. Then the non-deterministic process will push the system into that state state, no matter what the process is. That is: the constrain is the enough to determine the final state. We call this state equilibrium.

Suppose the only constraint on the system is the total energy (how do we justify this?). Suppose for each value of energy there is an equilibrium state. Then the entropy $I=I(E)$ is a function of $E$.

Suppose two systems come into contact. The entropy of each one constraint by its total energy. $I_1=I_1(E_1)$ and $I_2=I_2(E_2)$. The entropy sums $I=I_1+I_2$ if the systems are independent degrees of freedom. The energy sums $E=E_1+E_2$ (why? under what conditions the Hamiltonian of the whole is the sum of the Hamiltonian of the parts?). Suppose the system undergoes non-deterministic evolution and they can exchange energy. $I$ is maximized under the constraint of the total energy. The equilibrium is reached when $\frac{\partial I}{\partial E_1} = 0$ and $\frac{\partial I}{\partial E_2} = 0$ on the constraint. That is: $\frac{\partial I}{\partial E_1} = \frac{\partial I_1}{\partial E_1} +\frac{\partial I_2}{\partial E_2} \frac{\partial E_2}{\partial E_1} = \frac{\partial I_1}{\partial E_1} -\frac{\partial I_2}{\partial E_2}=0$. We have $\frac{\partial I_1}{\partial E_1} = \frac{\partial I_2}{\partial E_2}$.

Define temperature $\frac{1}{T_1} = \frac{\partial I_1}{\partial E_1}$: at equilibrium the two systems have the same temperature. Note that temperature cannot be zero since the information entropy at equilibrium is a function of the energy, and not the other way around.

\subsection{Closed two form for Hamiltonian mechanics}

We have to better understand why the two form $\omega$ has to be closed. One idea: consider $\frac{\omega^n}{n!}$. This gives us the volume in phase space. It's a $2n$-form in a $2n$-dimensional space. It's exterior derivative $\frac{\partial\omega^n}{n!}=0$ because its rank exceeds the dimensionality of the space. We have $\frac{\partial\omega^n}{n!}=\frac{\omega^{n-1}}{(n-1)!}\wedge\partial\omega=0$. Since $\omega$ cannot be degenerate, $\partial \omega$ must be zero. Does that work?

\subsection{Better notation for differential calculus}

To really understand/derive the correct physical relationships we'll need to use differential geometry. The standard vector calculus does not generalize and does not lead to the correct way of thinking. The notation used in differential geometry (for vectors and covectors) and their definitions (i.e. space of derivations, space of real functions of derivations) makes no physical sense. We need to define better concepts and notation that fit the physics better.

In terms of concepts, the main idea is to start from the integral operators and see the differential operators as the limit of recursive subdivisions. This is the opposite of what is typically done, but is what is closer to the physics. That is: mass over a finite region is what we measure and the density is the limit for which we make the region shrink. Same thing for a vector: a finite curve is what we have and the idea that we can divide it into infinitesimal parts, each described by a vector, is a limit. Since we start from a different point, some theorems get reversed.

For example, given an $n$-dimensional space, we will have a function $F$ from an $m$-dimensional sub-space to a real number. These functions are going to be linear, in the sense that if the function applied to the union of disjoint region is equal to the sum of the function of the individual regions: $F(\bigcup X_i) = \sum F(X_i)$ if $X_i \cap X_j = \emptyset$. So, for example, $F(\emptyset) = F(\emptyset \cup \emptyset) = F(\emptyset) + F(\emptyset) = 0$ always. We want to be able to show that $F=\int f(dx^m)$ where $f$ is an $m$-form. Stokes theorem should be reversed. That is, we start by saying that if we have a function on $m$-dimensional subspace we can always create one that is $m+1$ dimensional by applying the $m$ dimensional to the boundary. That is $F_{(m+1)}(U) = F_{(m)}(\partial U)$. We then show/define the corresponding $f_{(m+1)} $ as the exterior derivative of $f_{m}$. Already we have $F_{(m+2)}(U) = F_{(m+1)}(\partial U) = F_{(m)}(\partial \partial U) = F_{(m+2)}(\emptyset) = 0$ since a boundary has no boundary. So double exterior derivative is the zero form. This is the generalization of $curl(grad)=0$ and $div(curl)=0$. 

Here is a first stab at the notation.

Exterior product: $\theta_1 \wedge \theta_2$. Anti-symmetric: rotating 180 degrees is the same as reflection.

Base vector along $i-th$ component: $e_i$. Generic form for vector: $v = v^i e_i$.

Base one-form for $i-th$ component: $e^i$. Base one-form returns one if the base vector is along the same component. Zero otherwise. $e^i(e_j) = \delta^i_j$.  Generic form for one-form: $\theta = \theta_i e^i$. Generic one form applied to generic vector: $\theta(v) = \theta_i e^i(v) = \theta_i v^j e^i(e_j) = \theta_i v^j \delta^i_j = \theta_i v^i$.

Generic form for n-form: $\theta = \theta_{i_1...i_n}e^{i_1}\wedge ... \wedge e^{i_n}$.

Exterior derivative: $\partial \theta = \partial_{i_1} \theta_{i_2...i_{n+1}}e^{i_1}\wedge ... \wedge e^{i_{n+1}}$. $\partial \partial \theta = \partial_{i_1} \partial_{i_2} \theta_{i_3...i_{n+1}}e^{i_1}\wedge^{i_2}\wedge^{i_3}\wedge ... \wedge e^{i_{n+1}} = - \partial_{i_1} \partial_{i_2} \theta_{i_3...i_{n+1}}e^{i_2}\wedge^{i_1}\wedge^{i_3}\wedge ... \wedge e^{i_{n+1}} = - \partial_{i_2} \partial_{i_1} \theta_{i_3...i_{n+1}}e^{i_2}\wedge^{i_1}\wedge^{i_3}\wedge ... \wedge e^{i_{n+1}} = 0$.

In three dimensions. Exterior derivative of zero form $f$: $\partial f = \partial_x f e^x + \partial_y f e^y + \partial_z f e^z$. Exterior derivative of one-form $\theta$: $\partial \theta = \partial_x \theta_x e^x \wedge e^x + \partial_y \theta_x e^y \wedge e^x + \partial_z \theta_x e^z \wedge e^x + \partial_x \theta_y e^x \wedge e^y + \partial_y \theta_y e^y \wedge e^y + \partial_z \theta_y e^z \wedge e^y + \partial_z \theta_x e^x \wedge e^z + \partial_y \theta_z e^y \wedge e^z + \partial_z \theta_z e^z \wedge e^z = (\partial_x \theta_y - \partial_y \theta_x) e^x \wedge e^y + (\partial_y \theta_z - \partial_z \theta_y) e^y \wedge e^z + (\partial_z \theta_x - \partial_x \theta_z) e^z \wedge e^x$. Exterior derivative of two-form $\omega$: $\partial \theta = \partial_x \theta_{yz} e^x \wedge e^y \wedge e^z + \partial_y \theta_{zx} e^y \wedge e^z \wedge e^x + \partial_z \theta_{xy} e^z \wedge e^x \wedge e^y = (\partial_x \theta_{yz} + \partial_y \theta_{zx} + \partial_z \theta_{xy}) e^x \wedge e^y \wedge e^z$.

Connection between axial vector and two-form: $B^x = \omega_{yz}, B^y = \omega_{zx}, B^z = \omega_{xy}$.

Another reason why we should not use $df$ for exterior derivative. $f$ can be consider a point in a function space or a function from the $X$ to $\mathbb{R}$. We can take $df$ to be the differential (i.e. infinitesimal change) of the function in the function space while $\partial f$ the exterior derivative. Using $df$ as the exterior derivative would be misleading.

\subsection{Angular momentum and spin}

To derive the Dirac equation, we need to have a good way to motivate spin. The idea is to say that spin is the degree of freedom that captures a direction in space. Many things work, but there are a number of open issues which makes it unclear (for example) how to make it relativistic.

First, what works. Suppose you have one d.o.f. for spatial direction. Degrees of freedom must be two dimensional. This means that we can only use two variables to specify a direction. This means the space is three dimensional.

Next, we need to find conjugate variable. Consider the solid angle $d\Omega=\sin \varphi_z d\varphi_z d\theta_{xy}$ where $\varphi_z$ is the azimuthal angle. This is a quantity that is dimensionless and that is proportional to the number of possible directions. Therefore we can use it as a measure for the number of degrees of freedom. We can the two form for our space as $\omega(d\theta_{xy}, d\varphi_z) = \hbar d\Omega = \hbar\sin \varphi_z d\varphi_z d\theta_{xy} = d(- \hbar \cos d\varphi_z ) \wedge d\theta_{xy} = d\theta_{xy} \wedge d(\hbar \cos \varphi_z )$. Set $S_z= \hbar \cos \varphi_z$ the component of the normalized vector multiplied by $\hbar$. We have that $\omega(d\theta_{xy}, dS_z) = d\theta_{xy} \wedge dS_z$ therefore $\theta_{xy}$ and $S_z$ are conjugate variables.

The question is: how do those two quantities change under coordinate transformations?

A simple answer should be: they should change like angular momentum. So we study that change and we should be fine. Except that in phase space angular momentum does not really change like a vector or a covector.

Suppose we have $(q^x, q^y, q^z)$ and $(p_x, p_y, p_z)$. Note that we are assuming Cartesian, so we already have limited the applicability. Change to spherical coordinates $(r,\theta,\varphi) = (\sqrt{(q^x)^2 + (q^y)^2 + (q^z)^2 }, \arccos \frac{z}{r}, \arctan \frac{y}{z})$. Conjugate momentum becomes:
\begin{align*}
	q^x &= r \sin \varphi \cos \theta \\
	q^y &= r \sin \varphi \sin \theta \\
	q^z &= r \cos \varphi \\
	p_r&= \frac{\partial q^x}{\partial r} p_x + \frac{\partial q^y}{\partial r} p_y + \frac{\partial q^z}{\partial r} p_z \\
	&= \frac{1}{\sqrt{(q^x)^2 + (q^y)^2 + (q^z)^2 }} (q^x p_x + q^y p_y + q^z p_z) \\
	p_\theta&= \frac{\partial q^x}{\partial \theta} p_x + \frac{\partial q^y}{\partial \theta} p_y + \frac{\partial q^z}{\partial \theta} p_z \\
	&= - r \sin \varphi \sin \theta p_x + r \sin \varphi \cos \theta p_y + 0 p_z \\
	&= - q^y p_x + q^x p_y \\
	p_\varphi&= \frac{\partial q^x}{\partial \varphi} p_x + \frac{\partial q^y}{\partial \varphi} p_y + \frac{\partial q^z}{\partial \varphi} p_z \\
	&= r \cos \varphi \cos \theta p_x + r \cos \varphi \sin \theta p_y - r \sin \varphi p_z \\
	&= q^z \frac{q^x}{\sqrt{(q^x)^2 + (q^y)^2}} p_x + q^z \frac{q^y}{\sqrt{(q^x)^2 + (q^y)^2}} p_y - \sqrt{(q^x)^2 + (q^y)^2} p_z \\
\end{align*}

The conjugate of $\theta$ is angular momentum. The first problem is that here angular momentum is simply a component within a vector. The other components of the vector are not angular momentum. The second problem is that $q^x p_y - q^y p_x$ is neither invariant, covariant or contravariant. This is radically different from $x v^y - y v^x$ where we use velocity instead of momentum. This has better transformation rules but velocity and momentum are not the same. This is not going to help us understand how spin should transform. The last problem is that we could create an "angular-momentum of angular momentum". That is, we can make the spherical coordinate of the spherical coordinates and we'd have $r p_\theta - \theta p_r$. Is that an angular momentum?

The issue seems to be that angular momentum is only vaguely related to actual momentum. The best way to look at it should be: I have a group of generators for rotations along different directions. How do they combine? So, I have a rotation along the $x$ axis and a rotation along the $y$ axis: how do they compose? But again, seems somewhat ill defined. These are going to be global rotations on the whole space. What group of rotation is possible depends on the topology of the space. For example, on a sphere a rotation along the pole is the same as a translation along the equator. How can this all be constructed in a way that does not lead into contradictions?




\backmatter

\chapter[Credits]{\centering Credits}

\begin{table}[h]
\centering
\begin{tabular}{R{0.45\textwidth} L{0.5\textwidth}}
Created by: & Gabriele Carcassi \\
Written by: & Gabriele Carcassi and Christine Aidala \\
& \\
& \\
Subject-matter advisors (Math): & Mark Greenfield (Ch. 1) \\
Additional subject-matter advisors (Phi): & Josh Hunt (Ch. 1) \\

% Possible role definitions
%\multicolumn{2}{c}{{\LARGE \textbf{Additional consultants}}} \\
%\multicolumn{2}{c}{\emph{Occasional role in providing significant feedback that reshapes some ideas}} \\

%\multicolumn{2}{c}{{\LARGE \textbf{Consultants}}} \\
%\multicolumn{2}{c}{\emph{Continued role in providing significant feedback that reshapes some ideas}} \\

%\multicolumn{2}{c}{{\LARGE \textbf{Testing/Proof-reading}}} \\
%\multicolumn{2}{c}{\emph{Someone who reads drafts on a regular basis and provided useful feedback (i.e. typos or cause minor corrections)}} \\

%\multicolumn{2}{c}{{\LARGE \textbf{Additional testing}}} \\
%\multicolumn{2}{c}{\emph{Someone who occasional reads drafts on a regular basis and provided useful feedback (i.e. typos or cause minor corrections)}} \\
\end{tabular} 
\end{table}


	
\end{document}