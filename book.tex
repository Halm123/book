% Possible use http://www.latextemplates.com/template/the-legrand-orange-book as template? See https://www.overleaf.com/9174958nyjxxdxbchks#/33024595/

\documentclass[11pt,letterpaper,fleqn]{memoir} % Default font size and left-justified equations

\input{formatting} % Loads the book formatting

\begin{document}
	
% Set theory (expected) \in, \subset, injective/surjective, cartesian product

% Closure of a set under an operation

% Need examples of topology and sigma algebra

% Note that sigma algebra are also closed under intersections

\chapter*{Assumptions of physics}

\textbf{This book is a work in progress}. This draft is a development copy built on \today. You can get the latest version for http://assumptionsofphysics.org. It is provided as-is for the purpose of early review and feedback. 

\chapter{Experimental observations and distinguishability}

In this chapter we introduce a general theory of science, a formalism that is broad enough to be applied to any area of scientific investigation. It is based on the idea of \textbf{experimental observations}, which consist of a \textbf{statement}, an assertion that is either true or false, and an \textbf{experimental test}, which provides a way to experimentally verify it. Whether it is physics or chemistry, economics or psychology, medicine or biology, it is always a matter of finding some truth about the natural world and a way to show that experimental data supports that claim.


We group experimental observations into \textbf{experimental domains} which represent the list of all possible testable answers to a particular scientific question. From those, we define \textbf{theoretical domains} which adds those statements that, though not directly testable, would have consequences on the experimental tests. These will include, for example, limits of an experimental procedure. Within each theoretical domains, we find those particular statements that, if true, determine the truthfulness or falsehood of all other statements: they give us the full solution. We call those \textbf{possibilities}. To answer a scientific question, then, is to find which possibility is the correct one.

The striking result is that the above organization is always possible on any given set of statements that can be experimentally verified. That is, it is a fundamental structure for all sciences. The other striking result is that these concept map exactly to two mathematical structures that are at the core of mathematics: experimental domains map to topologies while theoretical domains map to a $\sigma$-algebras. These two mathematical structures provide foundation to differential geometry, Lie algebras, measure theory, probability theory and other mathematical branches that are heavily used in physics and other sciences.

As a consequence of this connection, we can fully understand why these mathematical tools are pervasive in science and clarify their physical significance.

\section{Statements}

Science is the systematic study of the physical world through observation and experimentation. Therefore we start our discussion introducing the following principle that formally captures that idea.

\begin{mathSection}
	\textbf{Principle of scientific objectivity}.
		Science is universal, non-contradictory and evidence based.
\end{mathSection}

The main goal in stating this principle is to make clear what the domain of scientific investigation is and acknowledge its limits. For example, assertions like \statement{jazz is marvelous} or \statement{green and red go well together} cannot be the subject of scientific inquiry as they are not objective. That is, there is no agreed upon definition or procedure for what constitutes marvelous music or good color combination. This does not mean that marvelous music or good color combinations do not exist or are not worth studying. They just can't be the subject of scientific inquiry.\footnote{In fact, one can argue that most of the things that make life worth living (e.g. love, friendship, arts, purpose and so on) defy objective characterization and, therefore, that science gives us certain truth about trifling matters.} If we choose to do science, then, we are limiting ourselves to those assertions that are either true or false (i.e. non-contradictory) for everybody (i.e. universal): assertions that have a single truth value.

\begin{mathSection}
\begin{defn}
	The \textbf{Boolean domain} is the set $\mathbb{B} = \{\FALSE, \TRUE\}$ of all possible truth values.
\end{defn}


\begin{axiom}\label{def_statement}
	A \textbf{statement} $\stmt$ is a declarative sentence that is either true or false. Formally, a statement is an element of the set $\mathcal{S}$ of all statements upon which is defined a function $\truth: \mathcal{S} \to \mathbb{B}$ that returns the truth value for each element.
\end{axiom}

\end{mathSection}

Statements are the first building block of our general theory of science and we are borrowing them from the established philosophical tradition of classical logic. Any language can be used to form them, formal or natural, as indeed any language is used in practice. Scientific investigation in the broad sense of learning from experimentation predates math and formal languages: information about agriculture, astronomy, metallurgy, botany and the like were collected and used even before the written word. Moreover, cognitive scientists have shown that children start using deliberate experimentation at a very young age to understand the world around them, even before their speech is fully developed. Ultimately, that knowledge is encoded in the language of electrical and biochemical signals. Formal languages are indeed extremely helpful in that they allow to be more precise and to better keep track of possible inconsistencies, but ultimately one always needs natural language to give meaning and context to the mathematical symbols. 

Since any language is allowed, the particular syntax of the language used to write the statements is not of interested. That is, we are not going to care what particular symbols and particular grammar rules are used. In fact, even a grammatically incorrect statement is fine as long as the intent is clear. On the other hand, we are going to care about the semantics of the statements (i.e. their content and meaning). Without a clear semantic it would be impossible to gather experimental evidence in favor or against a statement. Therefore we need to slightly extend its definition to allow a minimal set of operations to compare and contrast the content.

As a first step, we want to avoid assigning truths that are inconsistent with the content of a statement.  We want to avoid saying that contradictory statements such as \statement{that cat is a bird} are true or that obvious statements such as \statement{that cat is an animal} are false. The content of the statement, then, is such that it defines what possible truth values the statement is allowed to take.

\begin{mathSection}
	
	\begin{axiom}\label{def_possibilities}
		The \textbf{possibilities} of a statement $\stmt$ are the possible truth values allowed by the content of the statement. Formally, on the set $\mathcal{S}$ of all statements is also defined a function $\poss: \mathcal{S} \to \{\{\FALSE, \TRUE\},\{\FALSE\},\{\TRUE\}\}$ such that $\truth(\stmt) \in \poss(\stmt)$ for all $\stmt \in \mathcal{S}$.
	\end{axiom}
	
	\begin{defn}
		A \textbf{tautology} $\tautology$ is a statement that must be true simply because of its content. That is, $\poss(\stmt) = \{\TRUE\}$.
	\end{defn}
	
	\begin{defn}
		A \textbf{contradiction} $\contradiction$ is a statement that must be false simply because of its content. That is, $\poss(\stmt) = \{\FALSE\}$.
	\end{defn}
	
\end{mathSection}

Therefore we say \statement{that cat is a bird} is a contradiction while \statement{that cat is an animal} is a tautology.

Next we want to keep track when the truth of a statement is a function of the truth of other statements. For example, \statement{that animal is a cat} and \statement{that animal is not a cat} can't both be true. As there are no limits in the way we can logically combine assertions, we will assume we can create any arbitrary function of any set of statements.

\begin{mathSection}
	\begin{axiom}\label{def_functions_of_statement}
		We can always construct a statement whose truth value arbitrarily depends on an arbitrary set of statements. Formally: given an arbitrary truth function $f : \mathbb{B}^n \to \mathbb{B}$ and a set of statements $\{\stmt_1, ..., \stmt_n\} \subseteq \mathcal{S}$  whose cardinality matches the arity (i.e. number of arguments) of the function, there exists a unique statement in $\mathcal{S}$, noted as $f(\stmt_1, ..., \stmt_n)$, such that:
		\begin{itemize}
			\item its truth value is the result of the truth function: \newline $\truth(f(\stmt_1, ..., \stmt_n)) = f(\truth(\stmt_1), ..., \truth(\stmt_n))$
			\item its possibilities are consistent with the truth function: \newline $\poss(f(\stmt_1, ..., \stmt_n)) \subseteq f(\poss(\stmt_1) \times ... \times \poss(\stmt_n))$
			\item all possibilities for all arguments are allowed:
			\newline let $1 \leq i \leq n$, for every $t_i \in \poss(\stmt_i)$ there exists a combination of possibilities $(t_1, ..., t_n) \in \poss(\stmt_1) \times ... \times \poss(\stmt_n)$ such that the value for $i$-th argument is $t_i$ and  $f(t_1, ..., t_n) \in \poss(f(\stmt_1, ..., \stmt_n))$.
		\end{itemize}
	This is also holds in the case of infinite, possibly uncountable, arguments.
	\end{axiom}
	\begin{justification}
		Since this is an axiom, there is technically nothing to prove. However, we need to make sure the starting points of our framework are well justified.
		
		The idea that we can use statements to construct other statements is something well established in logic. The first property simply states that the truth of the final statement is calculable from the truth of the arguments.
		
		On the other hand, it is not possible in general to calculate the possibilities of the result given only the truth value and possibilities of the arguments. A few examples will illustrate the problem.
		
		Let $\stmt_1$ be a statement such that $\truth(\stmt_1) = \TRUE$ and $\poss(\stmt_1) = \{\FALSE, \TRUE\}$. Let $\stmt_2$ be a statement such that $\truth(\stmt_2) = \FALSE$ and $\poss(\stmt_2) = \{\FALSE, \TRUE\}$. Let $f : \mathbb{B} \times \mathbb{B} \to \mathbb{B}$ be the truth function that returns $\TRUE$ only if the arguments are $\TRUE$ (i.e. the logical conjunction as we'll see later). Consider $f(\stmt_1, \stmt_2)$. We would expect $\truth(f(\stmt_1, \stmt_2)) = \FALSE$ since one of the statement is not $\TRUE$. This is guaranteed by the first property.
		
		The possibilities, though, cannot be known without further information. Suppose $\stmt_1$ is \statement{Felix is a cat} and that $\stmt_2$ is \statement{Felix is black}. If these are the actual statements, then we would expect $\poss(f(\stmt_1, \stmt_2)) = \{\FALSE, \TRUE\}$ since Felix could be a black cat or not a black cat. However, suppose $\stmt_1$ is \statement{Felix is a cat} and that $\stmt_2$ is \statement{Felix is a dog}. If these are the actual statements, then we would expect $\poss(f(\stmt_1, \stmt_2)) = \{\FALSE\}$ since Felix cannot be both a cat and a dog. Depending on the extra information we reach different results.
		
		While we are not always able to calculate the possibilities, we can put some bounds. Suppose $f$ is as defined before, and both $\stmt_1$ and $\stmt_2$ are tautologies. In this case we would expect $\FALSE \notin \poss(f(\stmt_1, \stmt_2))$ since both statement cannot be false and $f$ only returns false when one of the inputs is false. This justifies the second property: the result can only be possibly true or false if the possibilities of the arguments applied to the truth functions allows for it.
		
		Now suppose $f$ is as before, $\stmt_1$ is a tautology and $\poss(\stmt_2) = \{\FALSE, \TRUE\}$. We would expect that  $\poss(f(\stmt_1, \stmt_2)) = \{\FALSE, \TRUE\}$. Suppose, in fact, that $f(\stmt_1, \stmt_2)$ could only be true. Then we would expect that the arguments can never be false, since $f$ only returns true when both inputs are true. But this can't be since $\stmt_2$ is not a tautology. On the other hand, suppose that $f(\stmt_1, \stmt_2)$ could only be false. This would mean that $\stmt_2$ can only be false, since $f$ only returns false when one of the inputs is false and $\stmt_1$ can only be true. But this, again, can't be. This justifies the third property: the possibilities of the result can never limit the possibilities of the arguments in a way that is contradictory.	
	\end{justification}
\end{mathSection}

To better characterize truth functions, we borrow ideas and definitions from Boolean algebra which is the branch of algebra that operates on truth values. Boolean algebra is fundamental in logic and computer science, since every digital circuit ultimately is implemented on two-state systems (e.g. high/low voltage, up/down magnetization).  One of its main results is that all truth functions can be expressed by combining the following three simple operations.

\begin{mathSection}
	\begin{defn}
		The \textbf{negation or logical NOT} is the function $\NOT : \mathbb{B} \to \mathbb{B}$ that takes a truth value and returns its opposite. That is: $\NOT \TRUE = \FALSE$ and $\NOT \FALSE = \TRUE$.
	\end{defn}
	
	\begin{defn}
		The \textbf{conjunction or logical AND} is the function $\AND : \mathbb{B} \times \mathbb{B} \to \mathbb{B}$ that returns $\TRUE$ only if all the arguments are $\TRUE$. That is: $\TRUE \AND \TRUE = \TRUE$ and $\TRUE \AND \FALSE =\FALSE \AND \TRUE =\FALSE \AND \FALSE = \FALSE$.
	\end{defn}
	
	\begin{defn}
		The \textbf{disjunction or logical OR} is the function $\OR : \mathbb{B} \times \mathbb{B} \to \mathbb{B}$ that returns $\FALSE$ only if all the arguments are $\FALSE$. That is: $\FALSE \AND \FALSE = \FALSE$ and $\TRUE \AND \FALSE =\FALSE \AND \TRUE =\TRUE \AND \TRUE = \TRUE$.
	\end{defn}
\end{mathSection}

Each of these operations defined on the truth value will have a corresponding operation on statements. As an example, here is a table that show how these logical operations work.
\begin{table}[h]
	\centering
	\begin{tabular}{p{0.2\textwidth} p{0.1\textwidth} p{0.1\textwidth} p{0.5\textwidth}}
		Operator & Gate & Symbol & Example \\ 
		\hline 
		Negation & NOT & $\NOT \stmt_1$ &  \emph{``the sauce is not sweet"} \\ 
		Conjunction & AND & $\stmt_1 \AND \stmt_2$ & \emph{``the sauce is sweet and sour"} \\ 
		Disjunction & OR & $\stmt_1 \OR \stmt_2$ & \emph{``the sauce is at least sweet or sour"}\\
		\multicolumn{4}{c}{  where $\stmt_1$ = \emph{``the sauce is sweet"} and $\stmt_2$ = \emph{``the sauce is sour"}}
	\end{tabular} 
	\caption{Boolean operations on statements}
\end{table}

Most languages typically already provide similar operations, as the examples show. Technically, though, we should consider the ones defined here as meta-operations that are defined outside the language of the statements. For example, \statement{x is the position of a ball}$\AND$\statement{$\,\frac{d^2 x}{dt^2} = - g$} stitches together an English statement with a calculus statement into a new statement that is neither. This kind of mix should be allowed as it does happen in practice.

Negation, conjunction and disjunction as we have defined them form the two-values Boolean algebra. Any function that takes truth values and return truth values can be expressed with only these three operations. Or, as we'll say, it can be \emph{generated} via negation, conjunction and disjunction. The idea is to create one term for each combination of arguments that returns $\TRUE$ and using the disjunction to combine them together. For example, the statement \statement{the sauce is sweet and sour or neither} can be expressed as $(\stmt_1 \AND \stmt_2) \OR (\NOT \stmt_1 \AND \NOT \stmt_2)$ and the statement \statement{the sauce is not sweet and sour} can be expressed as $(\stmt_1 \AND \NOT \stmt_2) \OR (\NOT \stmt_1 \AND \stmt_2) \OR (\NOT \stmt_1 \AND \NOT \stmt_2)$.

\begin{mathSection}
	\begin{defn}\label{def_minterm}
		Let $\{t_1, ..., t_n\} \subseteq \mathbb{B}^n$ be a set of truth values. A \textbf{minterm} of $\{t_1, ..., t_n\}$ is a conjunction where each element appears only once, either negated or not. That is, it can be written as $m = \bigAND \limits_{i=1}^n (\NOT)^{a_{i}} \, t_i$ where $a_{i} \in \mathbb{B}$, $\NOT ^ \TRUE \, t_i = t_i$ and $\NOT ^ \FALSE \, t_i = \NOT t_i$. In this notation, $m = \TRUE$ if and only if $t_i = a_i$ for all $i=1...n$. This extends to arbitrary sets of truth values
	\end{defn}
	
	\begin{prop}\label{prop_disjunctive_normal_form}
		Any function $f : \mathbb{B}^n \to \mathbb{B}$ that takes $n$ truth values and returns a truth values, which we call a \textbf{truth function}, can be expressed in its \textbf{disjunctive normal form} as a disjuction of minterms of the arguments. Formally, $f(t_1, ..., t_n) =\bigOR \limits_{i=1}^m \left( \bigAND \limits_{j=1}^n (\NOT)^{a_{ij}} \, t_j \right)$ where $m \in \mathbb{N}$ and  $a_{ij} \in \mathbb{B}$. This extends to functions of arbitrary arguments.
	\end{prop}
	\begin{proof}
		We first show that this can be done for a function that returns $\TRUE$ for a unique combination of values. Let $a_1, ..., a_n \in \mathbb{B}$ be $n$ truth values. Let $f_1: \mathbb{B}^n \to \mathbb{B}$ be a function such that $f_1(t_1, ..., t_n) = \TRUE$ if and only if $t_j = a_j$ for all $j=1...n$. Consider the minterm $\bigAND \limits_{j=1}^n (\NOT)^{a_{j}} \, t_j$. It will be $\TRUE$ if and only if $t_j \equal a_j$ for all $j=1...n$. Then we have $f_1(t_1, ..., t_n) = \bigAND \limits_{j=1}^n (\NOT)^{a_{j}} \, t_j$ since they return the same values for the same arguments.
		
		Now we generalize the result for arbitrary functions. Let $f : \mathbb{B}^n \to \mathbb{B}$ be a truth function. Let $m \in \mathbb{N}$ be the number of value combinations for which $f(t_1, ..., t_n) = \TRUE$. For each value combination $i=1..m$ let $a_{ij} \in \mathbb{B}$ be the sequence of values. Then $f_i = \bigAND \limits_{j=1}^n (\NOT)^{a_{ij}} \, t_j$ is the minterm for each value combination. Consider $\bigOR \limits_{i=1}^m f_i$. This function returns $\TRUE$ if and only if the arguments match one of the value combinations for which $f$ returns $\TRUE$. Then we have $f(t_1, ..., t_n) =\bigOR \limits_{i=1}^m \left( \bigAND \limits_{j=1}^n (\NOT)^{a_{ij}} \, t_j \right)$ since they return the same values for the same arguments.
		
		This procedure can be generalized to the case where the number of arguments of $f$ and the number of minterms is infinite.
	\end{proof}
\end{mathSection}

Since the disjunctive normal form allows us to write all functions in terms of just negation, conjunction and disjunction, it is sufficient to study those operations to understand the properties of all functions. Given the previous definitions, we can deduce the following.

\begin{mathSection}
	\begin{prop}
		The set of all statements $\mathcal{S}$ is closed under negation, arbitrary conjunction and arbitrary disjunction.
	\end{prop}
	\begin{proof}
		Negation, arbitrary intersection and arbitrary union are particular truth functions. The statement associated with them always exists by definition  \eqref{def_functions_of_statement}.
	\end{proof}
	\begin{prop}\label{boolean_properties}
		The set of all statements $\mathcal{S}$ satisfies the following properties:
		\begin{itemize}
			\item associativity: $a \OR (b \OR c) = (a \OR b) \OR c$, $a \AND (b \AND c) = (a \AND b) \AND c$
			\item commutativity: $a \OR b = b \OR a$, $a \AND b = b \AND a$
			\item absorption: $a \OR (a \AND b) = a$, $a \AND (a \OR b) = a$
			\item identity: $a \OR \contradiction = a
			$, $a \AND \tautology = a$
			\item distributivity: $a \OR (b \AND c) = (a \OR b) \AND (a \OR c)$, $a \AND (b \OR c) = (a \AND b) \OR (a \AND c)$
			\item complements: $a \OR \NOT a = \tautology$, $a \AND \NOT a = \contradiction$
		\end{itemize}
		This, by definition, means $\mathcal{S}$ is a \textbf{Boolean algebra}.
	\end{prop}
	\begin{proof}
		The left and right expression for each equality correspond to the same truth function applied to the same statements. Therefore, by definition  \eqref{def_functions_of_statement}, they correspond to the same statement.
	\end{proof}
\end{mathSection}

These operations and properties define the \textbf{algebra of statements}. Note that statements naturally inherit all the logical identities of classical logic from the properties of truth functions. This is exactly what we needed if we are to avoid assigning inconsistent truth values to statements that are related. 

The last step is to keep track when two statements are different but have the same content. For example \statement{that animal is a cat}, \statement{that creature is a cat} and \statement{quell'animale \`{e} un gatto} all mean the same thing. It would be inconsistent to assign them different truth values.

\begin{mathSection}

\begin{defn}
	Two statements $\stmt_1$ and $\stmt_2$ are \textbf{equivalent} $\stmt_1 \equiv \stmt_2$ if they must be equally true or false simply because of their content. That is, $(\stmt_1 \AND \stmt_2) \OR (\NOT\stmt_1 \AND \NOT\stmt_2)$ is a tautology.
\end{defn}

\begin{prop}
	Statement equivalence satifies the following properties:
	\begin{itemize}
		\item reflexivity: $s \equiv s$
		\item symmetry: $s_1 \equiv s_2$ if and only if $s_2 \equiv s_1$
		\item transitivity: if $s_1 \equiv s_2$ and $s_2 \equiv s_3$ then $s_1 \equiv s_3$
	\end{itemize}
	and is therefore an equivalence relation.
\end{prop}
\begin{proof}
	For reflexivity, we have $(\stmt \AND \stmt) \OR (\NOT\stmt \AND \NOT\stmt) = (\stmt) \OR (\NOT\stmt) = \tautology$. Therefore $s \equiv s$.
	
	For symmetry, we have $s_1 \equiv s_2$ implies $\tautology = (\stmt_1 \AND \stmt_2) \OR (\NOT\stmt_1 \AND \NOT\stmt_2) = (\stmt_2 \AND \stmt_1) \OR (\NOT\stmt_2 \AND \NOT\stmt_1)$. Therefore $s_2 \equiv s_1$.
	
	For transitivity, we have TODO.
\end{proof}

\end{mathSection}

Again, we want to stress that this notion of equivalence is not based on the truth value (i.e. whether the statements happen to be both true or false) or on properties \ref{boolean_properties} (i.e. whether they are the same statement): it is based on the possibilities (i.e. whether the two statement can possibly have a different truth). Also note that the semantics defines the possibilities but not the truth value, unless the statement is a tautology or a contradiction. For example, even if the meaning of \statement{the next race is going to be won by Secretariat} is clear, we may be none the wiser about its truthfulness. Intuitively, the equivalence we defined here answers the question: do these two statement carry the same information? If they do, they are essentially the same to us. So much so, that from now on we will implicitly assume two different statements to be inequivalent. Technically, when we'll say that $\stmt$ is a statement we actually mean $\stmt$ is an equivalence class of statement.

Equivalence is not the only semantic relationship that we want to capture. Consider the contents of the following:
\begin{enumerate}
	\item \statement{that animal is a cat}
	\item \statement{that animal is a mammal}
	\item \statement{that animal is a dog}
	\item \statement{that animal is a black}
\end{enumerate}
The second will be true whenever the first is true. The third will be false whenever the first is true. The fourth will be true or false regardless of whether the first is true. Assigning truth values at odds with these relationships would be, again, inconsistent. So we want to give a name to these kind of relationships and track them.

\begin{mathSection}

\begin{defn}
	Given two statement $\stmt_1$ and $\stmt_2$, we say that:
	\begin{itemize}
		\item $\stmt_1$ \textbf{is narrower than} $\stmt_2$ (noted $\stmt_1 \narrower \stmt_2$) if $\stmt_2$ is true whenever $\stmt_1$ is true simply because of their content. That is, $\stmt_1 \AND \NOT \stmt_2 \equiv \contradiction$.
		\item $\stmt_1$ \textbf{is broader than} $\stmt_2$ (noted $\stmt_1 \broader \stmt_2$) if $\stmt_2 \narrower \stmt_1$.
		\item $\stmt_1$ \textbf{is compatible to} $\stmt_2$ (noted $\stmt_1 \comp \stmt_2$) if their content allows them to be true at the same time. That is, $\stmt_1 \AND \stmt_2 \nequiv \contradiction$.

	\end{itemize}
	The negation of these properties will be noted by $\nnarrower$, $\nbroader$ , $\ncomp$ respectively.
\end{defn}
\begin{defn}
	The elements of a set of statements $S \subseteq \mathcal{S}$ are said \textbf{independent} (noted $\stmt_1 \indep \stmt_2$ for a set of two) if their content is such that any combination of their possibilities are allowed. That is, $\poss(f(S)) = f(\bigtimes_{x \in S} \poss(s))$ for any truth function $f : \mathbb{B}^{|S|} \to \mathbb{B}$. The negation of independence, will be noted by $\nindep$.
\end{defn}

\end{mathSection}

In the example before: the first statement is narrower than the second (1 $\narrower$ 2), is incompatible with the third (1 $\ncomp$ 3) and is independent from the fourth (1 $\indep$ 4).

Depending on context, a statement could be narrower than another even if it is describing different qualities. For example, \statement{this harp seal is white} is narrower than \statement{this harp seal is less than one year old}. Since harp seals have a white fur only for their first month, the first one can never be true while the second is not.

Note that independence is not transitive and pair-wise independence is not sufficient. Consider the following statements for an ideal gas:
\begin{enumerate}
	\item \statement{the pressure is $101\pm1$ kPa}
	\item \statement{the volume is $1\pm0.1$ $m^3$}
	\item \statement{the temperature is $293\pm1$ Kelvin}
\end{enumerate}
Since the three quantities are linked by the equation of state $PV=nRT$, any two statements are independent but the three together aren't.

We can also prove the following properties that will be useful later.


\begin{mathSection}
	
	\begin{prop}
		Two statements constructed using the same truth function and two sets of equivalent statements are equivalent. That is: given $f : \mathbb{B}^n \to \mathbb{B}$ then $f(\stmt_1, ..., \stmt_n) \equiv f(\bar{\stmt}_1, ..., \bar{\stmt}_n)$ if $\stmt_i \equiv \bar{\stmt}_i$ for all $1 \leq i \leq n$. This extends to functions of arbitrary arguments.
	\end{prop}
	\begin{proof}
		We first show the proposition holds when $f$ is the negation. Let $\stmt, \bar{\stmt} \in \mathcal{S}$ be two equivalent statements. Since $\stmt \equiv \bar{\stmt}$ we have $\{\TRUE\} = \poss((\stmt \AND \bar{\stmt}) \OR (\NOT \stmt \AND \NOT \bar{\stmt})) = \poss((\NOT \NOT \stmt \AND \NOT \NOT \bar{\stmt}) \OR (\NOT \stmt \AND \NOT \bar{\stmt})) = \poss((\NOT \stmt \AND \NOT \bar{\stmt}) \OR (\NOT (\NOT \stmt) \AND \NOT (\NOT \bar{\stmt})))$. Which means  $\NOT \stmt \equiv \NOT \bar{\stmt}$.
		
		We first show the proposition holds when $f$ is the conjunction. Let $\stmt_1, \stmt_2, \bar{\stmt}_1, \bar{\stmt}_2 \in \mathcal{S}$ be four statements such that $\stmt_1 \equiv \bar{\stmt}_1$ and $\stmt_2 \equiv \bar{\stmt}_2$. Consider
		\begin{align*}
\stmt[a] &= ((\stmt_1 \AND \bar{\stmt}_1) \OR (\NOT \stmt_1 \AND \NOT \bar{\stmt}_1)) \AND ((\stmt_2 \AND \bar{\stmt}_2) \OR (\NOT \stmt_2 \AND \NOT \bar{\stmt}_2)) \\
&=(\stmt_1 \AND \bar{\stmt}_1 \AND \stmt_2 \AND \bar{\stmt}_2) \OR (\stmt_1 \AND \bar{\stmt}_1 \AND \NOT \stmt_2 \AND \NOT \bar{\stmt}_2) \OR (\NOT \stmt_1 \AND \NOT \bar{\stmt}_1 \AND \stmt_2 \AND \bar{\stmt}_2) \OR (\NOT \stmt_1 \AND \NOT \bar{\stmt}_1 \AND \NOT \stmt_2 \AND \NOT \bar{\stmt}_2).
		\end{align*}
		Since $\stmt_1 \equiv \bar{\stmt}_1$ and $\stmt_2 \equiv \bar{\stmt}_2$, $\stmt[a]$ is the conjunction of two tautologies so it is a tautology as well. Consider
		\begin{align*}
		\stmt[b] &= ((\stmt_1 \AND \stmt_2) \AND (\bar{\stmt}_1 \AND \bar{\stmt}_2)) \OR  (\NOT (\stmt_1 \AND \stmt_2) \AND \NOT (\bar{\stmt}_1 \AND \bar{\stmt}_2)) \\
		&= 	
		(\stmt_1 \AND \stmt_2 \AND \bar{\stmt}_1 \AND \bar{\stmt}_2) \OR ((\NOT \stmt_1 \OR \NOT \stmt_2) \AND (\NOT \bar{\stmt}_1 \OR \NOT \bar{\stmt}_2)) \\
		&= (\stmt_1 \AND \stmt_2 \AND \bar{\stmt}_1 \AND \bar{\stmt}_2) \OR (\NOT \stmt_1 \AND \NOT \bar{\stmt}_1) \OR (\NOT \stmt_1 \AND \NOT \bar{\stmt}_2) \OR (\NOT \stmt_2 \AND \NOT \bar{\stmt}_1) \OR (\NOT \stmt_2 \AND \NOT \bar{\stmt}_2).
		\end{align*}
		Note that the conjunction of $\stmt[b]$ with any minterm of $\stmt[a]$ is the same minterm. Therefore we have  $\stmt[a] \AND \stmt[b] = \stmt[a]$. But if $\stmt[a]$ is a tautology, then $\stmt[a] \AND \stmt[b]$ is a tautology because it is equal to $\stmt[a]$, and $\stmt[b]$ is tautology as well or we would violate the third property of \ref{def_functions_of_statement}. Since $\stmt[b]$ is a tautology, $\stmt_1 \AND \stmt_2 \equiv \bar{\stmt}_1 \AND \bar{\stmt}_2$.
		
		Given that all functions can be generated from negation, conjunction and disjunction, and given that disjunction can be generated from negation and conjunction, the result proven generalizes to all functions.
	\end{proof}
	
	\begin{prop}
		$\stmt_1 \narrower \stmt_2$ if and only if $\stmt_1 \AND \stmt_2 \equiv \stmt_1$.
	\end{prop}
	
	\begin{proof}
		Consider $\stmt_1 \AND \stmt_2 = \stmt_1 \AND \stmt_2 \OR \contradiction$. Since $\stmt_1 \narrower \stmt_2$, $\stmt_1 \AND \NOT \stmt_2 \equiv \contradiction$. We have $\stmt_1 \AND \stmt_2 \OR \contradiction \equiv ( \stmt_1 \AND \stmt_2 ) \OR (\stmt_1 \AND \NOT \stmt_2) = \stmt_1 \AND (\stmt_2 \OR \NOT \stmt_2) = \stmt_1 \AND \tautology = \stmt_1$. Therefore $\stmt_1 \AND \stmt_2 \equiv \stmt_1$. The same logic can be applied in reverse.
	\end{proof}	
	
	\begin{prop}
		$\stmt_1 \ncomp \stmt_2$ if and only if $\stmt_1 \AND \NOT \stmt_2 \equiv \stmt_1$.
	\end{prop}
	
	\begin{proof}
		Consider $\stmt_1 \AND \NOT \stmt_2 = \stmt_1 \AND \stmt_2 \OR \contradiction$. Since $\stmt_1 \ncomp \stmt_2$, $\stmt_1 \AND \NOT \stmt_2 \equiv \contradiction$. We have $\stmt_1 \AND \NOT \stmt_2 \OR \contradiction \equiv ( \stmt_1 \AND \NOT \stmt_2 ) \OR (\stmt_1 \AND \stmt_2) = \stmt_1 \AND (\NOT \stmt_2 \OR \stmt_2) = \stmt_1 \AND \tautology = \stmt_1$. Therefore $\stmt_1 \AND \NOT \stmt_2 \equiv \stmt_1$. The same logic can be applied in reverse.
	\end{proof}	
	
	\begin{prop}
		$\stmt_1 \narrower \stmt_2$ and $\stmt_1 \broader \stmt_2$ if and only if $\stmt_1 \equiv \stmt_2$.
	\end{prop}
	
	\begin{proof}
		Suppose $\stmt_1 \narrower \stmt_2$ and $\stmt_1 \broader \stmt_2$. Then $\stmt_1 \AND \stmt_2 \equiv \stmt_1$ since $\stmt_1 \narrower \stmt_2$ and $\stmt_1 \AND \stmt_2 \equiv \stmt_2$ since $\stmt_2 \narrower \stmt_1$. Therefore $\stmt_1 \equiv \stmt_2$. Conversely, suppose $\stmt_1 \equiv \stmt_2$. Then $\stmt_1 \AND \stmt_2 \equiv \stmt_1 \equiv \stmt_2$. Therefore $\stmt_1 \narrower \stmt_2$ and $\stmt_1 \broader \stmt_2$.
	\end{proof}	
\end{mathSection}

With these tools in place we are in a position to formulate models that are universal and non-contradictory. These models will be a collection of statements with a well defined content, whose truth value will be discovered experimentally.

\section{Experimental tests}

The previous section took care of universality and non-contradiction, but the principle of scientific objectivity requires science to be evidence based. For example, \statement{the square of the hypotenuse is equal to the sum of the squares of the other two sides} or \statement{God is eternal} are not scientific statements as they deal with abstract concepts that cannot be defined experimentally. Moreover, they depend on what basic axioms or definitions we take as a starting point. For example, the first statement is not true in non-Euclidean geometry and the concept of God has evolved significantly throughout the millennia. Again, this does not mean these concepts are of less significance, just that they cannot be the subject of scientific inquiry.\footnote{In fact, one may be more interested in them precisely because of their abstract, and therefore less transient, nature.}

Limiting the scope of our discussion to objects and properties that are well defined physically is also not enough. For example, \emph{``the electron is green"} or \emph{``1 meter is equal to 5 Kelvin"} are still not suitable scientific statements as the relationships established are not physically meaningful. Even when the relationship is meaningful, we may still not be able to validate it experimentally. For example, \emph{``there is no extra-terrestrial life"} or \emph{``the mass of the electron is exactly $9.109 \times 10^{-31}$ kg"} are not statements that can be verified in practice. In the first case, we would need to check every corner of the universe and find none, with the closest galaxy like ours, Andromeda, being 2.5 millions light-years away; in the second case, we will always have an uncertainty associated with the measurement, however small.

So we have to narrow the scope to those and only those statements that can be verified experimentally. That is, we have to provide a repeatable (i.e. non-contradictory) experimental procedure (i.e. evidence based) that anyone (i.e. universal) can in principle execute. This is both the power and the limit of scientific inquiry: it gives us a way to construct a coherent description of the physical world but it is limited to those aspects that can be reliably studied experimentally.

\begin{mathSection}
\begin{axiom}\label{def_experimental_tests}
	An \textbf{experimental test} $\expt$ is a repeatable procedure (i.e. it can be restarted and stopped at any time) that anybody can execute and will always either terminate successfully, terminate unsuccessfully or never terminate. Formally, an experimental test is an element of the set $\mathcal{E}$ of all experimental tests upon which is defined a function $\result: \mathcal{E} \to \{\SUCCESS, \FAILURE, \UNDEF\}$ that returns the result for each element.
\end{axiom}
\end{mathSection}

As an example, the following procedure defines an experimental test:
\begin{enumerate}
	\item find a swan
	\item if it's black terminate successfully
	\item go to step 1
\end{enumerate}
If a black swan exists, at some point we'll find it and the test will be successful. If a black swan does not exist, then the procedure will never terminate and the result is undefined.

Experimental tests are the second and last building block of our general theory of science. As with statements, any language can in principle be used to describe the procedure, which can be arbitrarily complicated. It may require building detectors, gathering large amount of data and performing complicated computations. We are not going to care how these procedure are described, just that it is done in a way that allows us to execute the test.

Similarly to statements, we want to define experimental tests whose success is a function of the success of other experimental tests. This is not as straight forward as with statements: this time we need to make sure we actually can create a suitable experimental procedure in practice and this is not always possible. What we do, then, is to study how experimental tests combine under the three basic Boolean operations.

The first important result is that the negation of an experimental test, an experimental test that is successful when the first is not successful, does not necessarily exist. Going back to the swan example, its negation would be a procedure that terminates successfully if black swans do not exist. But the given procedure never finishes in that case, so it is not just a matter of switching success with failure. Because of non-termination, not-successful does not necessarily mean failure.\footnote{In this case, the old adage ``absence of evidence is not evidence of absence" applies.} Note that in many cases one may construct the negation of an experimental test, but there is nothing that guarantees us that it must exist a priori as we can't construct it in general. Moreover, it is a result of computability theory that some problems are undecidable: they do not allow the construction of an algorithm that always terminates with a correct yes-or-no answer. So we know that in some cases this is not actually possible.

In the same vein we are able confirm experimentally that \statement{the mass of this particle is not zero} but not that \statement{the mass of this particle is exactly zero} since we always have uncertainty in our measurements of mass. Even if we could continue shrinking the uncertainty arbitrarily, we would ideally need infinite time to shrink it to zero. What this means is that not all answers to the same question can be equally verified. Is the mass of the photon exactly zero? We can either give a precise ``no" or an imprecise ``it's within this range." Is there extra-terrestrial life? We can either give a precise ``yes" or an imprecise ``we haven't found it so far."\footnote{Note that we are on purpose avoiding induction. It cannot have any role in a fundamental theory of scientific investigation since the decision of when and how to apply it violates the principle of scientific objectivity. Induction is an extremely useful mental shortcut that can be used to point us in the right direction, but giving it a central role in science just creates confusion. We should think of induction like scaffolding when constructing a building: its removal is necessary to claim that the work is done.}


\begin{mathSection}
	\emph{Remark}. The \textbf{negation or logical NOT} of an experimental test does not necessarily exist.
\end{mathSection}

Combining experimental tests with conjunction (i.e. the logical AND) is more straightforward. If we are able to verify that \emph{``the sauce is sweet"} and that \emph{``the sauce is sour"}, we can verify that \emph{``the sauce is sweet and sour"} by executing both. If both are successful, then the conjunction is successful. That is, if we have two or more experimental tests, we can aways test the logical AND for success by checking one at a time if all tests are successful. Yet, the number of tests needs to be finite or we would never terminate.

\begin{mathSection}
	\begin{axiom}\label{def_experimental_test_AND}
	The \textbf{conjunction or logical AND} of a finite collection of experimental tests $\{\expt_i\}_{i=1}^{n}$ is the experimental test $\bigAND\limits_{i=1}^{n} \expt_i$ (or simply $\expt_1 \AND \expt_2$ for two statements) that is successful only when all experimental tests are successful. Formally, for any finite collection $\{\expt_i\}_{i=1}^{n} \subseteq \mathcal{E}$ there exists $ \bigAND\limits_{i=1}^{n} \expt_i \in \mathcal{E}$ such that $\result(\bigAND\limits_{i=1}^{n} \expt_i) = \SUCCESS$ if and only if $\result(\expt_i) = \SUCCESS$ for all $i=1..n$.
	\end{axiom}
	\begin{justification}
		Mathematically, we are simply assuming that the finite conjunction exists, so there it nothing to prove. However, we want to convince ourselves that in practice we can construct the test to show that the assumption is well justified. Let $\bigAND\limits_{i=1}^{n} \expt_i$ be the experimental procedure defined as follows:
		\begin{enumerate}
			\item for each $i=1..n$ run the test $\mathsf{e}_i$
			\item if all tests terminated successfully terminate successfully.
		\end{enumerate}
		The experimental procedure so defined terminates successfully if and only if all $\mathsf{e}_i$ terminate successfully as per the definition.
	\end{justification}
\end{mathSection}	

Combining experimental tests with disjunction, i.e. the logical OR, is also straightforward. To verify that \emph{``the sauce is at least sweet or sour"} we can first test that \emph{``the sauce is sweet"}. If that is verified that's enough: the sauce is at least sour. If not, we test that \emph{``the sauce is sour"}. That is, if we have two or more experimental tests we can always test the logical OR for success just by stopping at the first test that is successful. Because we stop at the first success, the number of tests we combine in a logical OR can be countably infinite. As long as one test succeeds, which will always be the case when the overall test succeeds, it does not matter how many elements we are not going to verify later. But it cannot be more than countably infinite since the only way we have to find if one experimental test in the set is successful is testing them all one by one.

\begin{mathSection}
	\begin{axiom}\label{def_experimental_test_OR}
	The \textbf{disjunction or logical OR} of a (finite or infinite) countable collection of experimental tests $\{\expt_i\}_{i=1}^{\infty}$ is the experimental test $\bigOR\limits_{i=1}^{\infty} \expt_i$ (or simply $\expt_1 \OR \expt_2$ for two statements) that is successful if and only if at least one experimental test in $E$ is successful. Formally, for any countable collection $\{\expt_i\}_{i=1}^{\infty} \in \mathcal{E}$ there exists $ \bigOR\limits_{i=1}^{\infty} \expt_i \in \mathcal{E}$ such that $\result(\bigOR\limits_{i=1}^{\infty} \expt_i) = \SUCCESS$ if and only if $\result(\expt_i) = \SUCCESS$ for some $1 \leq i \leq n$.
	\end{axiom}
	\begin{justification}
		Mathematically, we are simply assuming that the countable disjunction exists, so there it nothing to prove. As before, we want to convince ourselves that in practice we can construct the test to show that the assumption is well justified. This time we have to be more careful to handle tests that may not terminate.
		Let $\bigOR\limits_{i=1}^{\infty} \expt_i$ be the experimental procedure defined as follows:
		\begin{enumerate}
			\item initialize $n$ to 1
			\item for each $i=1..n$
			\begin{enumerate}
				\item run the test $\mathsf{e}_i$ for $n$ seconds
				\item if $\mathsf{e}_i$ terminated successfully, terminate successfully
			\end{enumerate}
			\item increment $n$ and go to step 2
		\end{enumerate}
		The procedure will eventually run all tests for an arbitrary long amount of time. Suppose there exists an $1 \leq i \leq n$ such that $\mathsf{e}_i$ will terminate successfully. Then the above procedure will eventually run that test for a time long enough and terminate successfully.
	\end{justification}
\end{mathSection}

Taken as whole, these logical operations define the \textbf{algebra of experimental tests}. It is much more limited than the algebra of statements and it tells us that, in practice, we are not going to be able in general to write a test whose success if an arbitrary function of the success of other tests.

Before we continue, it is interesting and useful to understand the interplay between scientific and mathematical constructs. Technically, definitions \ref{def_statement}, \ref{def_possibilities}, \ref{def_functions_of_statement}, \ref{def_experimental_tests}, \ref{def_experimental_test_AND} and \ref{def_experimental_test_OR} are the axioms of our mathematical formalism for statements and experimental tests. Note that the actual content of the statements and the procedure for the tests are not formally defined: the math treats them simply as label that we use for identification. The only assumptions are that statements exist (each with a set of possible truth values and an actual truth value), that experimental tests exists (each with a well defined result) and that they both admit the associated algebra. The mathematical formalism does not know what these objects actually are: they may as well be pieces of cardboard painted black or white. Therefore the math does not know whether the properties we assigned make actual sense: it can only guarantee their non-contradiction. In other words, the way that we are making the framework precise is not by making everything precise: is by omitting the details that are not amenable to a precise specification.

We should stress this for a couple of reasons. First, the part that is not formalized is \emph{the most important part}. Discovering new science is exactly finding new things to study (i.e. new statements) or devising new measurement techniques (i.e. new experimental tests). The content of the statements and the procedure of the experimental test \emph{is} the actual science. Everything that follows is, in a sense, the trivial bit and that is why it can be done generally. Which leads to the second reason: understanding whether statements and experimental tests \emph{actually} follow the algebras we defined is crucial. The math just takes it at face value, it does not prove it. The justifications for our definitions, then, are the most critical part of this work and they are not mathematical proofs. If we botch them, we'll have a nice, consistent, rich but meaningless mathematical framework. Lastly, it has to be clear that something gets lost in the formalization. The mathematical framework cannot carry all the physics content: we removed the most important part! Different systems may have the same mathematical description, so the scientific content can never be entirely reconstructed from the math. That is why we always have to carefully bring it along.

\section{Experimental observations and experimental domains}

Now that statement and experimental tests are well defined, we can match them to create a verifiable statement.

\begin{mathSection}
\begin{defn}
	An \textbf{experimental observation} is a tuple $\obs = \obsdef{\stmt}{\expt}$ composed by a statement $\stmt$ and an experimental test $\expt$ such that the statement is true if and only if the  experimental test is always successful. That is, $\truth(\stmt)=\textsc{true}$ if and only if $\result(\expt)=\textsc{success}$. The experimental observation is \textbf{verified} if the statement is true.
\end{defn}
\end{mathSection}

Note that, in principle, science can also study statements that can be refuted experimentally. But the negation of those is a statement that can be verified experimentally. Therefore we lose nothing by only focusing on verification.\footnote{Mathematically, the space of verifiable statements and refutable statements are dual to each other.}

As pairing a statement with an experimental test does not affect its truth or meaning, we can extend on experimental observations all the operations that compare the content of the statements. Therefore we'll be able to say that observations and statements are equivalent, incompatible and so on.

\begin{mathSection}
\begin{defn}
	The operations $\equiv$, $\nequiv$, $\subseteq$, $\nsubseteq$, $\supseteq$, $\nsupseteq$, $\comp$, $\ncomp$, $\indep$, $\nindep$ are extended to experimental observations (and between statements and observations) by simply comparing the associated statements.
\end{defn}
\end{mathSection}

The logical operations, though, are affected. To take the conjunction or the disjunction of experimental observations we must make sure that the experimental tests still exist. And since the experimental tests are more restrictive, it is their rules that will determine what logical operations are available.
\begin{mathSection}
	\begin{defn}
	The \textbf{conjunction or logical AND} of a finite collection  of experimental observations $\{\mathsf{o}_i\}_{i=1}^{n}=\{\llparenthesis \stmt_i, \expt_i\rrparenthesis\}_{i=1}^{n}$ is the experimental observation $\bigAND\limits_{i=1}^{n} \mathsf{o}_i = \llparenthesis \bigAND\limits_{i=1}^{n} \stmt_i, \bigAND\limits_{i=1}^{n} \expt_i\rrparenthesis$.
\end{defn}
\begin{proof}
	To check that the definition is valid, we need to make sure that the statement is true if and only if the experimental test is successful. We have $\truth(\bigAND\limits_{i=1}^{n} \stmt_i) = \TRUE$ if and only if $\truth(\stmt_i) = \TRUE$ for all $\stmt_i \in \{\stmt_i\}_{i=1}^{n}$. This is the case if and only $\result(\expt_i) = \SUCCESS$ for all $\expt_i \in \{\expt_i\}_{i=1}^{n}$. This can only happen if and only if   $\result(\bigAND\limits_{i=1}^{n} \expt_i) = \SUCCESS$. Therefore $\bigAND\limits_{i=1}^{n} \mathsf{o}_i$ is a valid experimental observation.
\end{proof}
	\begin{defn}
	The \textbf{disjunction or logical OR} of a (finite or infinite) countable  collection of experimental observations $\{\mathsf{o}_i\}_{i=1}^{\infty}=\{\llparenthesis \stmt_i, \expt_i\rrparenthesis\}_{i=1}^{\infty}$ is the experimental observation $\bigOR\limits_{i=1}^{\infty} \mathsf{o}_i = \llparenthesis \bigOR\limits_{i=1}^{\infty} \stmt_i, \bigOR\limits_{i=1}^{\infty} \expt_i\rrparenthesis$.
\end{defn}
\begin{proof}
	As before, we need to make sure that the statement is true if and only if the experimental test is successful. We have $\truth(\bigOR\limits_{i=1}^{n} \stmt_i) = \TRUE$ if and only if $\truth(\stmt_i) = \TRUE$ for at least one $\stmt_i \in \{\stmt_i\}_{i=1}^{n}$. This is the case if and only $\result(\expt_i) = \SUCCESS$ for the corresponding test $\expt_i \in \{\expt_i\}_{i=1}^{n}$. This can only happen if and only if   $\result(\bigOR\limits_{i=1}^{n} \expt_i) = \SUCCESS$. Therefore $\bigOR\limits_{i=1}^{n} \mathsf{o}_i$ is a valid experimental observation.
\end{proof}
\end{mathSection}

Now that we know how we can verify each experimental observation or their combination, we want to understand how can we verify a group of them. The idea is that we may not need to individually verify all the observations. For example, once we test \statement{the sauce is sweet} and \statement{the sauce is sour}, for example, there will be no need to verify their conjunction \statement{the sauce is sweet and sour}. The test of the latter amounts to running the tests for the former two, which we already did.

\begin{mathSection}
	\begin{defn}
		Given a set $\edomain$ of experimental observations, $E \subseteq \edomain$ is an \textbf{essential subset} if verifying its elements is equivalent to verifying the whole set. Formally, all elements of $\edomain$ that are not contradictions or tautologies can be generated from $E$ using finite conjunction and countable disjunction.
	\end{defn}
\end{mathSection}

The idea is that once we gathered experimentally the truth values of the essential observations, we can deduce the truth values of all other observations by computing the appropriate truth function.

\begin{mathSection}
\begin{defn}
	An \textbf{experimental domain} $\edomain$ represents all the experimental evidence that can be acquired about a scientific subject in an indefinite amount of time. That is, it is a set of experimental observations that includes the tautology and the contradiction, is closed under finite conjunction and countable disjunction, and allows a countable essential subset.
\end{defn}
\begin{justification}
	As usual, let's make sure the formal definition is consistent with the informal one. The set consists only of experimental observations which can be verified experimentally. The set contains the tautology and contradiction since those don't even need to be verified experimentally. Functions of experimental observations represent experimental evidence about the same subject, therefore it is appropriate the experimental domain is closed under finite conjunction and countable disjunction. Given that each test terminates successfully in a finite amount of time, we can only verify a countable set in an indefinite amount of time. Therefore, if the experimental domain didn't allow for a countable essential subset, we would always have experimental observations we would never be able to test.
\end{justification}
\end{mathSection}

An experimental domain represents the enumeration of all possible verifiable answers to a scientific question. For example, the domain related to the question ``what is that animal?" would include \emph{``it is a mammal"}, \emph{``it is a dog"}, \emph{``it is an animal with feathers"} and so on. If two statements are possible answers to that question, then their conjunction and disjunction will also be possible answers. For example: \emph{``it is a dog or a cat"} or \emph{``it is a mammal and it lays eggs"}.

While each observation only needs finite time to be verified, we allow indefinite time for the domain because we want to capture those questions that can be answered only approximately. The idea is that, given more time, we can always get a better answer so, in principle, we have an infinite sequence of tests to perform and continue indefinitely.

The essential subset not only serves as a way to constrain the size of the experimental domain, most of the time will also serve to define the experimental domain itself. We will typically start by characterizing a set of observations (e.g. the set of animals and how to identify them) and then consider the domain of all the observations that can be constructed from them (e.g. the set of all groups of animals we can identify).

\section{Theoretical domains and possibilities}


While the negation of an experimental observation is not always an observation, the negation of its statement is still a statement. It may not be one we can readily verify, but it still is one that can be used to characterize the outcome of some experimental test. For example, if \statement{black swans do not exist} then a procedure that looks for one will never terminate. So, while in practice the negation my not be verifiable, in theory it does yield consequences. To each set of experimental observations, then, we associate a set of theoretical statements by allowing negation: these are the statements that can be used to construct predictions.

\begin{mathSection}
\begin{defn}
	The \textbf{theoretical domain} $\tdomain$ of an experimental domain $\edomain$ is the set of statement that could be tested if all negations were verifiable. More formally, let $\mathsf{S}$ be the set of all statements associated with an experimental observation in $\edomain$. $\tdomain$ is the set of all statements generated from $\mathsf{S}$ using negation, finite conjunction and countable disjunction.
\end{defn}
\end{mathSection}

While the theoretical statement contains more statements, it does not contain more information. That is, if we knew what experimental observations are verified and which aren't, we would automatically know which theoretical statements would be true or not. So it is not adding extra cases. It is essentially completing the list of answers by adding a ``no" if only ``yes" can be experimentally verified and vice-versa. For example, if our experimental domain contained the experimental observation \emph{``the mass of the photon is not zero"}, its theoretical domain would contain the theoretical statement \emph{``the mass of the photon is exactly zero"} which cannot be experimentally verified.

\begin{mathSection}
\begin{prop}
	The truth value of the statements of an essential set $E$ for an experimental domain $\edomain$ are enough to determine the truth value for all statements in the associated theoretical domain $\tdomain$. More formally, all statements in the theoretical domain $\tdomain$ can be generated by negation, countable conjunction and countable disjunction from the statements associated to $E$.
\end{prop}

\begin{proof}
	By definition of essential set, any observation within the experimental domain $\edomain$ can be generated from $E$ using only finite conjunction and countable disjunction. This relationships will hold between the respective statements. Since the statements associated to $E$ generate, through finite conjunction and countable disjunction, all statements in $\edomain$ which in turn generate all statements in $\tdomain$, then $E$, through negation, countable conjunction and countable disjunction, generates all of $\tdomain$.
\end{proof}
\end{mathSection}

A direct consequence of our definitions is that the countable conjunction of theoretical statements is a theoretical statement.

\begin{mathSection}
	\begin{prop}
		All theoretical domains are closed under countable conjunction.
	\end{prop}

\begin{proof}
	Any countable conjunction $\mathsf{s} = \bigAND\limits_{i=1}^{\infty} \mathsf{s}_i$ is equivalent to the negation of disjunction of the negation: $\mathsf{s} = \NOT\bigOR\limits_{i=1}^{\infty} \NOT\mathsf{s}_i$. As the theoretical domain is closed under negation and countable disjunction, so it is closed under countable conjunction.  
\end{proof}

\end{mathSection}

Both the experimental and the theoretical domains contain answers at different level of precision. For example, \emph{``that animal is a feline"} tells us more than \emph{``that animal is a mammal"}. What we want to find are those theoretical statements that are narrowest: those that, if known to be true, would tell us whether each theoretical statement is true or false. For example, if we knew \emph{``that animal is a cat"} we would know that \emph{``that animal is a mammal"} is true and that \emph{``that animal is a dog"} is false.

\begin{mathSection}

\begin{defn}
	A \textbf{possibility} for $\edomain$ is a statement $x \in \tdomain$ that, when true, determines the truth value for all statements in the theoretical domain. That is, $x \nequiv \contradiction$ and for each $\mathsf{s} \in \tdomain$, either $x \subseteq \mathsf{s}$ or $x \ncomp \mathsf{s}$. The \textbf{full possibilities}, or simply the \textbf{possibilities}, $X$ for $\edomain$ is the collection of all possibilities.
\end{defn}

\end{mathSection}

A possibility represents a complete prediction for a scientific question. Only one of them can be true and one of them must be true since the theoretical domain contains all negations. In fact, we can think it as the conjunction of all observations or their negations. That is, the possibility \statement{cat} is the conjunction \statement{that animal is a cat}$\AND \NOT$\statement{that animal is a dog}$\AND$... of all the elements of an essential set of observations.

\begin{mathSection}
	
\begin{prop}\label{prop_poss_is_minterm}
	Let $\edomain$ be an experimental domain. A possibility for $\edomain$ is a minterm of an essential set that is not a contradiction.
\end{prop}

\begin{proof}
	Let $E \subseteq \edomain$ be an essential set. Let $x$ be a minterm of $E$. Any theoretical statement $\stmt \in \tdomain$ can be expressed as the disjunction of minterms of $E$. $x$ is either within the minterms needed to express $\stmt$, or not. If it is, $x \AND \stmt \equiv x$ and therefore $x \narrower \stmt$. If it's not, $x \AND \NOT \stmt \equiv x$ and therefore $x \ncomp \obs[e]_i$. Therefore a minterm is either narrower or incompatible with all theoretical statement and, if it is not a contradiction, it is a possibility by definition.
	
	Conversely, suppose $x \in \tdomain$ is a possibility. As it is a theoretical statement, it can be expressed as a disjunction of minterms of an essential set $E$. Suppose it is the disjunction of more then one minterm. Then each minterm would be narrower than $x$, which cannot be. $x$ must be expressed by a single minterm. Therefore any possibility is a minterm.
\end{proof}

\begin{prop}[No other possibilities]
	All statements that determine and only determine the truth value of all statements in a theoretical domain $\tdomain$ are possibilities of $\edomain$.
\end{prop}

\begin{proof}
	Let $x \in \mathcal{S}$ be a statement that determines and only determines all truth values of all statements in a theoretical domain $\tdomain$. This is equivalent to determine the truth values and only the truth values of all elements of an essential subset $E \subseteq \edomain$. As we can find a countable basis, the statement $x$ is equivalent to the countable conjunction of statements or negation of statements associated to $E$. Therefore $x \in \tdomain$ as it is generated by the statements of the essential subset by negation and countable conjunction. But a statement in $\tdomain$ that determines all truth values of the statements in $\tdomain$ is a possibility by definition. Therefore $x$ is a possibility.
\end{proof}
\end{mathSection}

There is one possibility that is often forgotten and sometimes needs special handling. Suppose one is trying to identify an illness by going through a series of known markers. It may happen that no match for the disease is found: we are dealing with a new kind of illness. In the same way, we may fail to identify a plant or animal from the standard taxonomy: we may have found a new species. In other words, it may be possible that none of our tests succeed and none of the observations of a domain are verified.

\begin{mathSection}
	\begin{prop}
		The \textbf{alternative possibility} $\mathring{x}$ for an experimental domain $\edomain$ is, if it exists, the possibility that predicts the failure of all experimental tests. That is, let $E \subseteq \edomain$ be an essential set then  $\mathring{x} = \bigAND\limits_{\stmt[e] \in E} \NOT e$ if it is not a contradiction. An experimental domain is \textbf{complete} if it doesn't admit an alternative possibility.
	\end{prop}

	\begin{prop}
	The \textbf{established possibilities} $X$ for an experimental domain is the set of all possibilities excluding the alternative possibility.
\end{prop}
\end{mathSection}

We call this special case the alternative possibility because it is outside of what our set of experimental tests can verify and because it sometimes requires special handling. It should also be noted that, as we refine our understanding and techniques for a domain of knowledge, we may find that the alternative possibility actually corresponds to multiple cases that weren't previously cataloged. So, intuitively, is better thought as a bucket that contains all that is yet to be experimentally discovered within the particular domain of knowledge. Because of its special nature, the alternative possibility sometimes behaves differently than the other possibilities. Therefore we will find that some theorems are more elegantly expressed in terms of the established possibilities and some in terms of the full possibilities.\footnote{Since this distinction will mainly be technical, we will use the same symbol for both the established possibilities and the full possibilities as the intuition remains the same.}

Note, though, that an alternative possibility does not exist for all domains. Suppose we have a basket of fruit and we want to count how many apples are there. There can only be a finite number of them, and we can successfully identify all finite numbers: there is no something else to be found in this case.

Given the definitions, we can ask a fundamental questions: what is the maximum number of possibilities? That is, what is the maximum number of cases between which we can distinguish experimentally?

\begin{mathSection}
	\begin{prop}
		The possibilities $X$ for an experimental domain $\edomain$ has at most cardinality of continuum.
	\end{prop}
	
	\begin{proof}
		The idea is that each possibility can be identified by knowing which observations of an essential set are verified. Since the essential set of an experimental domain can be assumed countable, the possible combinations of their truth values have at most cardinality of continuum.
		
		More formally, let $E = \{\obs[e]_i\}_{i=1}^{\infty} \subseteq \edomain$ be a countable essential set. Let $2^{\mathbb{N}}$ denotes the set of infinite binary sequences. We define the function $F:X\to2^{\mathbb{N}}$ such that $F(x) = (F(x)_i)_{i=1}^{\infty}$ is given by: 
		$$
		F(x)_i = 
		\begin{cases}
		1 & x \comp \obs[e]_i \\
		0 & x \ncomp \obs[e]_i
		\end{cases}
		$$
		For each $x \in X$ we have $x = \bigAND\limits_{i=1}^{\infty} \NOT^{F(x)_i} \obs[e]_i$. Suppose $x_1 \neq x_2$, then $F(x_1)_i \neq F(x_2)_i$ for some $i$, therefore $F$ is injective. We then have $|X| \leq |2^{\mathbb{N}}|=|\mathbb{R}|$. $X$ has at most cardinality of continuum.
	\end{proof}
\end{mathSection}

This means we have an upper bound on how many cases can be distinguished experimentally: only up to the continuum. More than that we are not going to be able to tell them apart. This result gives us a basic requirement for any mathematical object we want to use in a scientific theory: if the cardinality is greater than it is cannot have a well defined experimental meaning. For example, while the set of all continuous functions between real numbers has cardinality of continuum, the set of all functions (including all discontinuous) has greater cardinality. We can already conclude that the first set may be useful to represent a physical objects and the second may not.

There is still something that can go wrong, though: we need to make sure we have enough experimental observations to tell different possibilities apart. For example, if we are able to only verify \emph{``there is extra-terrestrial life"}, the opposite possibility will never have experimental confirmation. Since in most cases we want (and are able) to, we want to formally capture this notion.

\begin{mathSection}
\begin{defn}
	The set of possibilities $X$ of a domain $\edomain$ is \textbf{experimentally distinguishable} if given two distinct possibilities $x_1, x_2 \in X$ we can always find two experimental observations $\textsf{o}_1, \textsf{o}_2 \in \edomain$ such that $\textsf{o}_1 \broader x_1$, $\textsf{o}_2 \broader x_2$ and $\textsf{o}_1 \ncomp \textsf{o}_2$.
\end{defn}
\end{mathSection}

For example, to tell the house sparrow (Passer domesticus) apart from the Italian sparrow (Passer italiae) we have at least two observations (``it has a dark gray crown", ``it has a chestnut crown") that are incompatible with each other, but each compatible with one bird.

This concludes the introduction to our fundamental scientific objects. Experimental domains, with their respective theoretical domains and possibilities, are the essence of our theory of scientific investigation. In our context, a ``scientific theory" or a ``scientific model" \emph{are} an experimental domain.


The starting point is often an essential set of experimentally verifiable statements, which defines all the domain knowledge that we can gathered experimentally. The content of the statements determines what combinations can be true at the same time, which define the possibilities for our domain. Everything in the domain is grounded into the experimental observations: there is nothing else in it.

As we'll see later, the experimental observations may be idealizations. For example, we may assume that a quantity can be measured with arbitrary level of precision, which we know not to be true. Or the experimental observations may be valid only under some assumption. For example, we assume a volume of gas is at equilibrium and therefore has a well specified temperature. This type of simplifications changes the details of the domain, but not the formal structure we have identified here. In fact, the main body of this work is deriving the details of different experimental domains under different physical assumptions.

The point is that this conceptual structure is inescapable once we set the principle of scientific objectivity. It is necessary and sufficient to be able to do science and it is, consciously or unconsciously, always there.

\section{Topological spaces}

Now that we have defined what scientific domains are, we want to explore the link between them and some fundamental mathematical structures. The first such connection is between experimental domains and topology: each set of possibilities has a natural topological structure given by the associated experimental domain. So first we need at least to define what a topology is.

\begin{mathSection}
	\begin{defn}
		Let $X$ be a set. A \textbf{topology} on $X$ is a collection $\mathsf{T}_X$ of subsets of $X$ closed under finite intersection and arbitrary union such that it contains $X$ and $\emptyset$. A \textbf{topological space} is a tuple $(X, \mathsf{T}_X)$ of a set and a topology defined on it.
	\end{defn}
\end{mathSection}

Topologies are used to define a notion of closeness without having to define an actual distance. Other branches of math (e.g. metric spaces, differential geometry, Lie algebras) have their foundation on topological spaces, which therefore play a very important role in mathematics as a whole.

In our case, this notion of closeness will map to how hard is to tell possibilities apart. That is: possibilities that are topologically closer are more difficult to distinguish experimentally. Each set in the topology corresponds to an experimental observation.

\begin{mathSection}
	
\begin{defn}
	Let $\edomain$ be an experimental domain and $X$ its possibilities. We define the map $U : \edomain \rightarrow 2^X$ that for each experimental observation $\mathsf{o} \in \edomain$ returns the set of possibilities compatible with it. That is: $U(\mathsf{o})\equiv\{ x \in X \, | \, x \comp \mathsf{o}\}$. We call $U(\mathsf{o})$ the \textbf{verifiable set} of possibilities associated with $\mathsf{o}$
\end{defn}

\begin{prop}
	Let $X$ be the set of possibilities for an experimental domain $\edomain$. $X$ has a natural topology given by the collection of all verifiable sets $\mathsf{T}_X=U(\edomain)$.
\end{prop}

\begin{proof}
	The verifiable sets for the tautology and the contradiction correspond to the full set and empty set respectively. Formally, $U(\tautology) = \{ x \in X \, | \, x \comp \tautology\} = X$ while $U(\contradiction) = \{ x \in X \, | \, x \comp \contradiction\} = \emptyset$. Therefore $X, \emptyset \in U(\edomain)$ since $\tautology, \contradiction \in \edomain$.

	The finite intersection of verifiable sets corresponds to the verifiable set of the finite conjunction and therefore it is a verifiable set. Formally, $U(\obs_1\AND\obs_2) = \{ x \in X \, | \, x \comp \obs_1\AND\obs_2\} =  \{ x \in X \, | \, x \comp \obs_1 \, and \, x \comp \obs_2\} = \{ x \in X \, | \, x \comp \obs_1\} \cap \{ x \in X \, | \, x \comp \obs_2\} = U(\obs_1) \cap U(\obs_2)$.

	The union of verifiable sets corresponds to the verifiable set of the disjunction and therefore it is a verifiable set. Formally, $U(\obs_1\OR\obs_2) = \{ x \in X \, | \, x \comp \obs_1\OR\obs_2\} =  \{ x \in X \, | \, x \comp \obs_1 \, or \, x \comp \obs_2\} = \{ x \in X \, | \, x \comp \obs_1\} \cup \{ x \in X \, | \, x \comp \obs_2\} = U(\obs_1) \cup U(\obs_2)$. This generalizes to countable disjunctions. Arbitrary disjunctions can be re-expressed as countable disjunctions, since any observation can always be expressed in term of a countable set of essential elements.

	The collection $\mathsf{T}_X=U(\edomain)$ is therefore a topology by definition since it satisfies all its properties.
\end{proof}
\end{mathSection}

Mainly for historical reason, the sets in a topology are called \textbf{open sets}. The complements of open sets are called \textbf{closed sets}. In metric spaces, such as the Euclidean space with the standard topology, these will map to the more standard definition. But, in general, they do not and this may lead to confusion. For example, if we take the integers with their standard topology, any subset is both open and closed.

Given that we are only interested in the natural topologies of possibilities, we are going to refer to the sets in our topology as \textbf{verifiable sets} and we will call \textbf{refutable sets} their complements. As such, a subset of integer is both verifiable and refutable: the number could be in the set or not in the set and we have a test for both cases.  While this terminology does not follow math convention, we find it more intuitive and meaningful in the context of this work.

We now define basis and sub-basis on a topology along with an important property.
\begin{mathSection}
\begin{defn}
	A collection $\mathcal{B} \subseteq \mathsf{T}_X$ of verifiable sets of $X$ is a \textbf{sub-basis} if every verifiable set in $X$ is the union of finite intersections of $\mathcal{B}$. It is a \textbf{basis} if every verifiable set in $X$ is the union of elements of $\mathcal{B}$.
\end{defn}
\begin{defn}
	A topology for $X$ is \textbf{second-countable} if it admits a countable basis.
\end{defn}
\end{mathSection}

Basis are important since they are often used in proofs and calculations. Moreover, many properties of topologies can be shown to be equivalent to properties of one of their basis. Countability, and in particular second-countability, is one such property which characterizes the number of verifiable sets in the topology.

Conceptually, there is a link between sub-basis and essential subsets.

\begin{mathSection}
	\begin{prop}
		Let $X$ be the set of possibilities of an experimental domain $\edomain$. Let $E \subseteq \edomain$ be an essential subset, then the collection of verifiable sets $U(E)$ forms a sub-basis for the natural topology of $X$.
	\end{prop}
	\begin{proof}
		Since every experimental observation of a domain can be expressed as the disjunction of finite conjunctions of the essential observations, its corresponding verifiable set can be expressed as the union of finite intersections of the verifiable sets corresponding to the essential observations.
	\end{proof}
	\begin{prop}
		The natural topology of a set of possibility is second-countable.
	\end{prop}
	\begin{proof}
		Since each experimental domain admits a countable essential subset, its verifiable sets form a countable sub-basis for the natural topology. We can close the sub-basis through finite intersection, forming a countable basis for the topology. The natural topology is therefore second-countable as it admits a countable basis.
\end{proof}
\end{mathSection}

Another important property to classify topological space is their degree of separation: how well one can use open sets to tell points and sets apart. A Kolmogorov space is on in which for every pair of points there is always a verifiable set that contains one but not the other. This property is significant because it allows to distinguish all points through the verifiable sets. A Hausdorff space is one in which for every pair of points there always are two disjoint verifiable set each containing one. It is significant because it implies the uniqueness of limits of sequences of points.

\begin{mathSection}
	\begin{defn}
		A topology for $X$ is \textbf{Kolmogorov} (or $\mathsf{T}_0$) if for every two elements $x_1, x_2 \in X$ there exists a verifiable set $U \in \mathsf{T}_X$ containing one element but not the other. That is: either $x_1 \in U$ while $x_2 \notin U$ or $x_1 \notin U$ while $x_2 \in U$.
	\end{defn}
	\begin{defn}
	A topology for $X$ is \textbf{Hausdorff} (or $\mathsf{T}_2$) if for every two elements $x_1, x_2 \in X$ there exist two disjoint verifiable sets $U_1, U_2 \in \mathsf{T}_X$ each containing one element. That is: $U_1 \cap U_2 = \emptyset$, $x_1 
	\in U_1$ and $x_2 \in U_2$.
\end{defn}

\end{mathSection}

What we have is that the natural topology for any set of possibilities is Kolmogorov because two different possibilities must give a different outcome for at least one experimental test. If the possibilities are physically distinguishable, then the topology is Hausdorff because we can always find two incompatible observations each verifying one.

\begin{mathSection}
	\begin{prop}
	The natural topology of a set of possibilities is Kolmogorov (or $\mathsf{T}_0$).
\end{prop}
\begin{proof}
	Let $X$ be the set of possibilities for an experimental domain $\edomain$. Let $\tdomain$ be the corresponding theoretical domain. Let $x_1, x_2 \in X$ be two distinct possibilities. Each of them can expressed as the conjunction of the elements of an essential set $E \subseteq \edomain$ or their negation. Since the two possibilities are distinct, there must exist an experimental observation $\obs[e]_i \in E$ that appears negated in one conjunction but not the other. That is, $\obs[e]_i$ is compatible with only one possibility. Since the verifiable set of an experimental observation contains only the possibilities compatible with the observation, the verifiable set of $\obs[e]_i$ either contains $x_1$ or $x_2$ but not both. The topology is therefore Kolmogorov (or $\mathsf{T}_0$).
\end{proof}
	\begin{prop}
	The natural topology of a set of experimentally distinguishable possibilities is Hausdorff (or $\mathsf{T}_2$).
\end{prop}
\begin{proof}
	Since the possibilities are distinguishable, given two distinct possibilities $x_1, x_2 \in X$ we can find two observations such that $\obs_1 \broader x_1$, $\obs_2 \broader x_2$ and $\obs_1 \ncomp \obs_2$. This means $x_1 \in U(\obs_1)$, $x_2 \in U(\obs_2)$ and $U(\obs_1) \cap U(\obs_2) = \emptyset$. The topology is therefore Hausdorff (or $\mathsf{T}_2$).
\end{proof}
\end{mathSection}

\section{Sigma-algebras}

In the same way that experimental domains find a natural mathematical representation as topological spaces, theoretical domains find a natural mathematical representation in $\sigma$-algebras. Let's first define what that is.

\begin{mathSection}
	\begin{defn}
		Let $X$ be a set. A \textbf{$\sigma$-algebra} on $X$ is a collection $\Sigma$ of subsets of $X$ closed under complement and countable union such that it contains $X$.
	\end{defn}
\end{mathSection}

Note that $\sigma$-algebras are also closed under countable intersections, since they can be expressed in terms of negation and countable unions.

Like topologies, $\sigma$-algebras are fundamental in mathematics as they allow to construct measures (i.e. assigning sizes to sets), limits for sequences of sets and probabilities spaces. It is again fitting that we can associate such fundamental mathematical structure to theoretical domains.

\begin{mathSection}
	
	\begin{defn}
		Let $\tdomain$ be a theoretical domain and $X$ its possibilities. We define the map $A : \tdomain \rightarrow 2^X$ that for each theoretical statement $\stmt \in \tdomain$ returns the set of possibilities compatible with it. That is: $A(\stmt)\equiv\{ x \in X \, | \, x \comp \stmt\}$. We call $A(\stmt)$ the \textbf{theoretical set} of possibilities associated with $\stmt$
	\end{defn}
	
	\begin{prop}
		Let $X$ be the set of possibilities for a theoretical domain $\tdomain$. $X$ has a natural $\sigma$-algebra given by the collection of all theoretical sets $\Sigma_X=A(\tdomain)$.
	\end{prop}
	
	\begin{proof}
	The theoretical sets for the tautology and the contradiction correspond to the full set and empty set respectively. Formally, $U(\tautology) = \{ x \in X \, | \, x \comp \tautology\} = X$ while $U(\contradiction) = \{ x \in X \, | \, x \comp \contradiction\} = \emptyset$. Therefore $X, \emptyset \in A(\tdomain)$ since $\tautology, \contradiction \in \tdomain$.

	The complement of a theoretical set corresponds to the theoretical set of the negation and therefore it is a theoretical set. Formally, $A(\stmt)^C = \{ x \in X \, | \, x \ncomp \stmt\} =  \{ x \in X \, | \, x \comp \NOT\stmt\} = A(\NOT\stmt)$.

	The countable union of verifiable sets corresponds to the verifiable set of the countable disjunction and therefore it is a theoretical set. Formally, $A(\stmt_1\OR\stmt_2) = \{ x \in X \, | \, x \comp \stmt_1\OR\stmt_2\} =  \{ x \in X \, | \, x \comp \stmt_1 \, or \, x \comp \stmt_2\} = \{ x \in X \, | \, x \comp \stmt_1\} \cup \{ x \in X \, | \, x \comp \stmt_2\} = A(\stmt_1) \cup A(\stmt_2)$. This generalizes to countable disjunctions.

	The collection $\Sigma_X=A(\tdomain)$ is therefore a $\sigma$-algebra by definition since it satisfies all its properties.
	\end{proof}
\end{mathSection}

There is also a special link between topologies and $\sigma$-algebra. As one may want to construct measures and probabilities space on topological space, there is a standard way to construct a $\sigma$-algebra from a topology. This object, called Borel algebra, is the smallest $\sigma$-algebra that contains all verifiable sets defined by the topology. The $\sigma$-algebra defined by a theoretical domain is none other than the Borel algebra of the topology defined by the corresponding experimental domain.

\begin{mathSection}
	
	\begin{defn}
		Let $(X, \mathsf{T})$ be a topological space. Its \textbf{Borel algebra} is the collection $\Sigma_X$ of subsets of $X$ generated by countable union, countable intersection and complement from the verifiable sets.
	\end{defn}
	
	\begin{prop}
		The natural $\sigma$-algebra for a set of possibilities is the Borel algebra of its natural topology.
	\end{prop}
	
	\begin{proof}
		Since the theoretical domain can be generated by an essential set of the experimental domain, the natural $\sigma$-algebra can be generated by a sub-basis of the natural topology. This means that it is also generated by the countable union, countable intersection and negation from the verifiable sets of the natural topology.
	\end{proof}
\end{mathSection}

This fundamental link between experimental domains and topology on one side and theoretical domains and $\sigma$-algebra on the other is important for a couple of reasons.

From a practical standpoint, it guarantees that these mathematical tools can always be used. Since the experimental and theoretical domains are of truly general applicability, this means that any branch of scientific investigation can use techniques and results from topology and $\sigma$-algebras for calculations or for characterizing the domain at hand.

From a conceptual standpoint, it gives a precise scientific meaning to the mathematical tools and everything built on top of them. Every single step in a calculation, every single argument in a proof can be given a clear, and possibly insightful, physical meaning. It grounds the abstract mathematical language in more concrete scientific objects. This in turn helps clarify the science described by common mathematical tools, unearthing possible hidden assumptions and simplifications about the physical systems being studied.

\section{Dependence and equivalence between domains}

Having characterized experimental and theoretical domains together with their connection to topologies and $\sigma$-algebras, we want to study the case where an experimental domains is physically related to another. For example, consider the domains for the temperature and height of a mercury column or the domains for the temperature and density of water. How do we express, in this framework, the fact that these domains are connected?

We have two ways to define these type of relationships between domains. The first is in terms of inference: any experimental observation on the height of a mercury column is an indirect experimental observation on its temperature; any experimental observation on the density of water is an indirect experimental observation on its temperature. The second is in terms of causes: the height of the mercury column is a function of its temperature; the density of water is a function of its temperature. The main result of this section is to show that these perspectives are equivalent.

Suppose $\edomain_X$ represents the domain for the temperature of a mercury column while $\edomain_Y$ represents the domain for its height. Since we know that an increase in temperature makes the metal expand, we can infer the temperature of the mercury column by looking at its height. For example, if we verify that \statement{the height of the mercury column is between 24 and 25 millimeters} we may be able to infer that \statement{the temperature is 24 and 25 degrees Celsius}. That is, given an observation $\obs_Y$ we have an observation $\obs_X$ that is going to be verified if and only if the first one is.

Note that the inferences is between observations in general and not a single interval. For example, the observation \statement{the water density is between 999.8 and 999.9 kg/$m^3$} will correspond to \statement{the water temperature is between 0 and 0.52 Celsius}$\OR$\statement{the water temperature is between 7.6 and 9.12 degrees Celsius} as water is most dense at 4 degrees Celsius. But the disjuction of an observation is still an observation so we are still inferring one observation from the other. For each observation in $\edomain_Y$ we can find an observation in $\edomain_X$ that is verified if and only the first is. That is: an inference relationship is a map from $\edomain_Y$ to $\edomain_X$ that preserves equivalence.

\begin{mathSection}
	\begin{defn}
		An \textbf{inference relationship} between two experimental domains establishes that verifying an observation in one means verifying an observation in the other. More formally, it is a map $\erel: \edomain_Y \to \edomain_X$ between two experimental domains $\edomain_X$ and $\edomain_Y$ such that $f(\obs_Y) \equiv \obs_Y$. In other words: it is an equivalence preserving map between experimental domains.
	\end{defn}
	\begin{defn}
		An experimental domain $\edomain_Y$ is \textbf{dependent} on another experimental domain $\edomain_X$ if there exists and experimental relationship $\erel: \edomain_Y \to \edomain_X$.
	\end{defn}
	\begin{defn}
		Two experimental domains $\edomain_X$ and $\edomain_Y$ are \textbf{equivalent} $\edomain_X \equiv \edomain_Y$ if $\edomain_X$ depends on $\edomain_Y$ and vice-versa.
	\end{defn}
\end{mathSection}

It should be evident that we cannot impose inference relationships between any domain: it's something that the domains allow. The domains for the temperature of two different mercury columns are in general not related: testing the value of one does not tell us anything about the other. The topologies of the two domains, however, are going to be the same because we'll have the same possible values and the same way to experimentally test them. This shows that the equivalence of experimental domains is much stronger one typically has for standard mathematical structure. And confirms why the one we have setup is most appropriate for scientific investigation: it carries enough of the semantic to be able to tell what elements are truly scientifically equivalent.

Let's continue with our example. We can re-express the inference relationship in terms of causal relationship between the two domains. If $x$ is the value of temperature of the mercury column, that is a possibility for $\edomain_X$, and $y$ is the height of the mercury column, that is a possibility for $\edomain_Y$, then we can write $y=f(x)$ since the height if determined by the temperature.

Note that the direction of the causal relationship is the opposite of the inference. $X$ causes $Y$ and we can infer $Y$ from $X$. Chains of events are in terms of possibilities and start with the cause and end with the effect. Chains of inferences are in terms of observations and start with the result and end with the origin.

The reverse does not work in general. Even if we know the final possibility, we may not be able to reconstruct the initial possibility: if water density of water is exactly 999.9 kg/$m^3$, the temperature could be either 0.52 or 7.6 Celsius because density peaks at 4 Celsius. Conversly, an observervation on the cause is not necessarily an observation of the effect: measuring we have produced an electron is not enough to measure its mass to arbitrary precision (that is a separate measurement).

Another important consideration is that, in order to be consistent, the function $y=f(x)$ has to be continuous. An observation $\obs_Y$ on the height of the mercury column, in fact, will establish that the height is within the set of possibilities compatible to $\obs_Y$, say between 24 and 25 millimeters. That is $y$ is in $U_Y(\obs_Y)$, a verifiable set in the topology for $Y$. We can then infer that the temperature must be in the reverse image of the possible heights, say between 24 and 25 Celsius. That is $x$ is in $f^{-1}(U_Y(\obs_Y))$. But this means that, indirectly, we have experimentally verified that $x$ is in $f^{-1}(U_Y(\obs_Y))$. And if $\edomain_X$ is really the domain of the observations for the temperature, then it must contain one that matches that set of possible temperature, one for which the temperature is between 24 and 25 Celsius. In other words, $f^{-1}(U_Y(\obs_Y))$ must be a set in the topology of $X$.

Another way to look at this: if we say that we can only measure both the temperature and height of a mercury column with finite precision, we have to make sure that when we use the causal relationship for inference, a finite precision measurement of height will correspond to a finite precision measurement of temperature. This can only be true if the function is continuous.

\begin{mathSection}
	\begin{defn}
		Let $(X, \mathsf{T}_X)$ and $(Y, \mathsf{T}_Y)$ be two topological spaces. A \textbf{continuous function} is a map $f: X \to Y$ such that given any open set $U_Y \in \mathsf{T}_Y$ its reverse image $f^{-1}(U_Y) \in \mathsf{T}_X$ is an open set. Moreover, $f$ is continuous in the natural topologies.
	\end{defn}
	\begin{defn}
		Let $\edomain_X$ and $\edomain_Y$ be two experimental domains. A \textbf{causal relationship} from $\edomain_X$ to $\edomain_Y$ is a continuous function $f : X \to Y$ between the possibilities of the domains such that $x \narrower f(x)$.
	\end{defn}
	\begin{justification}
		Formally, we simply define causal relationships to be continuous. The details of the physical justifications are in the theorem that follows, but the idea is that if the function is not continuous, one can experimentally test statements that are not part of the experimental domain of $\edomain_X$, which would be contradictory.
	\end{justification}
	\begin{thrm}[Experimental Relationship Theorem]
		Inference and causal relationships are equivalent. More formally, let $\edomain_X$ and $\edomain_Y$ be two experimental domains. An inference relationship $\erel: \edomain_Y \to \edomain_X$ exists between them if and only if a causal relationship $f: \edomain_X \to \edomain_Y$ also exists.
	\end{thrm}
	\begin{proof}
		First we show that a causal relationship exists between independent and dependent domain. Suppose $\edomain_Y$ depends on $\edomain_X$. Given that for each observation in $\edomain_Y$ there exists an equivalent observation in $\edomain_X$, $\edomain_Y$ is effectively a subset of $\edomain_X$. By the same token, the theoretical domain $\tdomain_Y$ is effectively a subset of $\tdomain_X$. This means that a possibility $x \in \tdomain_X$, if true, will determine all the truth values of  all statements in $\tdomain_Y$, including its possibilities. But only one possibility $y \in \tdomain_Y$ can be compatible with $x$ since the possibilities of a domain are all incompatible with each other. Therefore we can define $f : X \to Y$ the function that given a possibility $x \in X$ returns the only possibility $y=f(x) \broader x$ that is compatible with it.
		
		We still need to show that $f$ is continuous. Consider an observation $\obs_Y \in \edomain_Y$. Let $U_Y(\obs_Y) \in \mathsf{T}_Y$ be its verifiable set. Since $\edomain_Y$ depends on $\edomain_X$, we can find $\obs_X \in \edomain_X$ such that $\obs_X \equiv \obs_Y$. Let $U_X(\obs_X) \in \mathsf{T}_X$ be its verifiable set. This is the set of all possibilities in $X$ that is compatible with $\obs_Y$, which means $U_X(\obs_X)$ contains all the possibilities that are compatible with one possibility in $U_Y(\obs_Y)$. Since $f$ returns the only possibility in $Y$ compatible with a possibility in $X$, $f^{-1}(U_Y(\obs_Y))$ will return all the possibilities in $X$ that are compatible with one possibility in $U_Y(\obs_Y)$. That means $f^{-1}(U_Y(\obs_Y)) = U_X(\obs_X)$ maps verifiable sets to verifiable sets. Therefore $f$ is continuous.
		
		Now we show that a causal relationship implies dependence between domain. Suppose we have a causal relationship $f: X \to Y$ between $\edomain_X$ and $\edomain_Y$. Let $y \in Y$ be a possibility for $\edomain_Y$. Consider   $f^{-1}(\{y\})$: this is the set of all possibilities in $X$ that are compatible with $y$. Since $\truth(y)=\TRUE$ if and only if $\truth(x)=\TRUE$ for some $x \in f^{-1}(\{y\})$, we must have $y \equiv \bigOR\limits_{x \in f^{-1}(\{y\})} x$. Now consider an observation $\obs_Y \in \edomain_Y$ and its associated theoretical statement $\stmt_Y \in \tdomain_Y$. Let $U_Y(\obs_Y)$ be the verifiable set associated with $\obs_Y$. We can write $\stmt_Y = \bigOR\limits_{y \in U_Y(\obs_Y)} y$ since the observation will be verified if and only if one of the possibilities compatible with it is true. We can expand each possibility in $Y$ as a conjunction of possibilities in $X$ using the previous relationship. We have $\stmt_Y = \bigOR\limits_{y \in U_Y(\obs_Y)} \bigOR\limits_{x \in f^{-1}(\{y\})} x = \bigOR\limits_{x \in f^{-1}(U_Y(\obs_Y))} x$. Because $f$ is continuous, the reverse image of a verifiable set is a verifiable set. Therefore there is a $\obs_X \in \edomain_X$ such that $U_X(\obs_X) = f^{-1}(U_Y(\obs_Y))$. Consider $\stmt_X \equiv \bigOR\limits_{x \in U_X(\obs_X)} x \equiv \stmt_Y$. This is the statement associated with $\obs_X$ so $\obs_X \equiv \obs_Y$. Therefore for each $\obs_Y \in \edomain_Y$ we can find an equivalent observation $\obs_X \in \edomain_X$. The experimental domain $\edomain_Y$ depends on $\edomain_X$.
	\end{proof}
\end{mathSection}

Given the equivalence, we will use \textbf{experimental relationship} to describe the link between the two domains. We still need to show that experimental relationships are themselves statements that can be tested experimentally. For example, \statement{there is a linear relationship between the temperature of a mercury column between 15 and 40 Celcius and it height between 15 and 40 millimeters} is also something tht we need to be able to verify experimentally. Intuitively, this something simple enough to do: one prepares different values of temperatures and measures different values of height. This means we'll have to extend our framework to define mathematically what we mean by preparing different values of temperature.

\section{Combining domains}

In this section we want to understand what happens when we combine statements from different domains. For example, suppose we have the experimental domain for the pressure of an ideal gas and the experimental domain for its temperature. We can mix observations with conjunction and disjunction as in \statement{the pressure is between 1 and 1.1 KPa}$\AND$\statement{the temperature is between 20 and 21 C} creating a new domain.

In this section we want to define how to combine different domains and study how the possibilities of the combined domain compared to the individual ones. The main result is that the possibilities of the combined domain domain depend on how compatible are the observations of the domains. We will explore three particular cases: combing independent domains will give use the scalar product of the possibilities, combining a dependent domain will leave the possibilities unchanged while combing incompatible domains will give the disjoint union of the established possibilities.

Suppose we have an experimental domain $\edomain_X$ generated by the two observations \statement{the patient is dead} and the \statement{the patient is alive} and a second one $\edomain_Y$ generated by the two observations \statement{the patient is not in a coma} and \statement{the patient is in a coma}. Both domains are decidable and the given observations also correspond to the possibilities for the respective domain.

We can construct the combined domain $\edomain_X \times \edomain_Y$ by taking all possible disjunctions and conjunctions. What are the possibilities for the new domain? Since by \ref{prop_poss_is_minterm} the possibilities are minterms, we have the following cases to consider:
\begin{itemize}
	\item \statement{the patient is alive} $\AND$ \statement{the patient is in a coma}
	\item \statement{the patient is alive} $\AND$ \statement{the patient is not in a coma}
	\item \statement{the patient is dead} $\AND$ \statement{the patient is in a coma}
	\item \statement{the patient is dead} $\AND$ \statement{the patient is not in a coma}
\end{itemize}
The last one is a contradiction: the patient cannot be dead and in a coma. Therefore the combined domain has only three possibilities. The possibilities of the combined domain is, in general, a subset of all possible combination (i.e. the scalar product) of the possibilites of the domains we are combining.

\begin{mathSection}
	
	\begin{defn}
		Let $\{\edomain_{X_i}\}_{i=1}^{\infty}$ be a countable set of experimental domains. The \textbf{combined experimental domain} $\edomain_{X} = \bigtimes\limits_{i=1}^{\infty} \edomain_{X_i}$ is the experimental domain generated from all statements in $\{\edomain_{X_i}\}_{i=1}^{\infty}$ by finite conjunction and countable disjunction.
	\end{defn}
	\begin{proof}
		We need to show that the combined experimental domain is indeed an experimental domain. It will contain the tautology and the contradiction since any of the original experimental domain contains them. It is closed under finite conjunction and countable disjunction by construction. To show that it has a countable essential subset, for each $i=1..\infty$ let $E_i \in \edomain_{X_i}$ be a countable essential subset. Consider $E=\bigcup\limits_{i=1}^\infty E_i$. From this set we can generate any $\edomain_{X_i}$ and therefore we can also generate all of $\edomain_{X}$. $E$ is an essential subset and it is countable since it is the union of a countable set of countable elements.
	\end{proof}

\begin{prop}\label{prop_combined_possibility}
	The possibilities $X$ for a combined domain $\edomain_{X} = \bigtimes\limits_{i=1}^{\infty} \edomain_{X_i}$ is set of all possible conjunctions of possibilities $x_i$ of the original domain that are not contradictions. That is $X = \{ x = \bigAND\limits_{i=1}^{\infty} x_i \, | \, x_i \in X_i, \, x \nequiv \contradiction \}$.
\end{prop}   
\begin{proof}
	A possibility $x$ of the combined domain is a minterm of an essential set $E \subseteq \edomain_{X}$. Since we can choose $E=\bigcup\limits_{i=1}^\infty E_i$ where $E_i \subseteq \edomain_{X_i}$ is the essential set for each domain, $x$ is the conjunction $x=\bigAND\limits_{i=1}^{\infty}x_i$ of minterms $x_i$ of $E_i$. Since $x$ is a possibility, it is not a contradiction and therefore neither of the $x_i$ can be a contradiction. Since each $x_i$ is a minterm of the respective essential set $E_i$ that is not a contradiction, it is a possibility by \ref{prop_poss_is_minterm}. Therefore a possibility $x$ of the combined domain is the conjunction of the possibilities $x_i$ of the original domains that does not lead to a contradiction.
\end{proof}
\end{mathSection}

\subsection{Independent domains}

A special case is when combining two independent domains. For example, the domain for the pressure and the domain for the volume of an ideal gas are indepent because a measurement on one tells us nothing about the other. Similarly, the domain for the shape and the domain for the color of an object are independent. In these cases, we can have any combination of the possibilties: any pressure with any volume or any color with any shape.

In terms of topology, the possibilities of the combined domain is the cartesian product of the possibilities of the original domains and its natural topology is the product topology.\footnote{Note that the topology is quite naturally the product topology and not the box topology. The box topology would require countable conjunction and is therefore discarded. The fact that the correct topology is the one most natural to define confirms again the appropriatedness how our framework.}

\begin{mathSection}
	\begin{defn}
		The experimental domains in a countable set $\{\edomain_{X_i}\}_{i=1}^{\infty}$ are \textbf{independent} if taking one observation $\obs_i \in \edomain_{X_i}$ from each domain always gives an independent set of statements.
	\end{defn}
	\begin{prop}
		Let $\{\edomain_{X_i}\}_{i=1}^{\infty}$ be a countable set of independent experimental domains and $X_i$ their respective possibilities. The set of possibilities of the combined experimental domain $\bigtimes\limits_{i=1}^{\infty} \edomain_{X_i}$ consists of all the possible conjunctions of the possibilities of each domain. That is: $X = \{ \bigAND\limits_{i=1}^{\infty} x_i \, | \, x_i \in X_i \}$. Notationally, we write $\edomain_{\bigtimes\limits_{i=1}^{\infty} X_i}$.
	\end{prop}
	\begin{proof}
		A possibility $x=\bigAND\limits_{i=1}^{\infty}x_i$ for the combined domain is the conjunction of possibilities of each individual domain by \ref{prop_combined_possibility}. Since the domains are independent and since possibilities are neither tautologies or contradictions, we have $\poss(x) = \poss(\bigAND\limits_{i=1}^{\infty}x_i) = \bigAND\limits_{i=1}^{\infty}\poss(x_i)= \bigAND\limits_{i=1}^{\infty} \{\FALSE, \TRUE\} = \{\FALSE, \TRUE\}$. That is, each conjunction $x=\bigAND\limits_{i=1}^{\infty}x_i$ is not a contradiction and therefore is a possibility.
	\end{proof}
	\begin{defn}
	Let $\{(X_i, \mathsf{T}_i)\}_{i=1}^{\infty}$ be a countable set of topological spaces. Let $X=\bigtimes\limits_{i=1}^{\infty} X_i$ be the Cartesian product of the points. Let $\mathcal{B}$ the collection of sets of the form $\bigtimes\limits_{i=1}^{\infty} U_{i}$, with $U_i \in \mathsf{T}_i$ and $U_i \neq X_i$ only finitely many times. The topology generated by $\mathcal{B}$ is called the \textbf{product topology}.
\end{defn}
	\begin{prop}
	Let $\{\edomain_{X_i}\}_{i=1}^{\infty}$ be a countable set of independent experimental domains. The natural topology for the possibilities of the combined experimental domain $\edomain_{\bigtimes\limits_{i=1}^{\infty} X_i}$ is the product topology of the natural topology for the possibilities of each domain.
\end{prop}
\begin{proof}
	Let $U_i : \edomain_{X_i} \to \mathsf{T}_{X_i}$ be the map from an observation of a domain to its verifiable set in the respective topology. Let $U : \edomain_{X} \to \mathsf{T}_X$ the same map for the combined domain. Let $\obs_i \in \edomain_{X_i}$ an observation from a particular domain and $U_i(\obs_i)$ its verifiable set in that domain. Since we also have $\obs_i \in \edomain_{X}$, it is also associate with the verifiable set $U(\obs_i)$ in the combined domain. Because the domains are independent, every possibility in $U_i(\obs_i)$ is compatible with any possibility $x_j \in X_j$ for all $j \neq i$. This means that $U(\obs_i)=X_1\times ... \times X_{i-1} \times U_i(\obs_i) \times X_{i+1} \times ...$ . Given that all observations in the combined domain can be generated using finite conjunction and countable disjunction from the observations of the independent domains, the topology of the combined space can be generated by all sets of the form $\bigtimes\limits_{i=1}^{\infty} U_{i}$, with $U_i \in \mathsf{T}_i$ and $U_i \neq X_i$ only once. Using finite intersection, this includes those sets where $U_i \neq X_i$ finitely many times. The natural topology of the combined domain is the product topology by definition.
\end{proof}
\end{mathSection}

\subsection{Dependent domains}

Another special case is combining a domain $\edomain_X$ with another $\edomain_Y$ that is dependent on it. For example, combining the domain for the temperature of a mercury column with the domain for its height. Since the height can be determined by the temperature, no new possibilities are added. The combined domain is equivalent to the independent domain $\edomain_X$ since all the observations in $\edomain_Y$ have all equivalents in it.

\begin{mathSection}
	\begin{prop}
		Let $\edomain_X$ and $\edomain_Y$ be two experimental domain such that the second depends on the first. Then $\edomain_X \times \edomain_Y \equiv \edomain_X$.
	\end{prop}
	\begin{proof}
		Since $\edomain_Y$ is dependent on $\edomain_X$, any observation in $\edomain_Y$ is equivalent to one in $\edomain_X$. The combined domain $\edomain_X \times \edomain_Y$ is generated by all observations in $\edomain_X$ and by another set of observations equivalent to a subset of $\edomain_X$. Therefore $\edomain_X \times \edomain_Y$ must be equivalent to $\edomain_X$. 
	\end{proof}
\end{mathSection}

\subsection{Incompatible domains}

The last special case we look into is when the domains are incompatible, that is all observations of one are incompatible with the observations of the other. Suppose $\edomain_X$ is the domain to classify a particual specimen as an animal and $\edomain_Y$ is the domain to classify it as a plant. If we take an observations from the first, such as \statement{the specimen is a cat (Felis catus)}, then it will be incopatible with an observations from the section, such as \statement{the speciment is catnip (Nepeta cataria)}. The combinied possibilities will be, roughly speaking, the possibilities of one plus the possibilities of the other. TODO: more precise.

In terms of the topology, the established possibilities of the combined domain is the dijoint union product of the established possibilities of the original domains and its natural topology is the disjoint union topology (or coproduct topology).

\begin{mathSection}
	\begin{defn}
		Two experimental domains $\edomain_X$ and $\edomain_Y$ are \textbf{incompatible} if all observations in one are incompatible to all observations of the other, excluding the tautology. Formally, $\obs_X \ncomp \obs_Y$ for each $\obs_X \in \edomain_X$ and $\obs_Y \in \edomain_Y$ such that $\obs_X \nequiv \tautology $ and $\obs_Y \nequiv \tautology$.
	\end{defn}
	\begin{prop}
		Let $\edomain_{X_1}$ and $\edomain_{X_2}$ be two incompatible experimental domains. Then the established possibilities of the combined domain $\edomain_X = \edomain_{X_1} \times \edomain_{X_2}$ is equal to the disjoint union of the established possibilities of the individual domains. That is $X = X_1 \cup X_2$. Notationally, we write $\edomain_{X_1} \times \edomain_{X_2} = \edomain_{X_1 \coprod X_2}$.
	\end{prop}
	\begin{proof}
		TODO
	\end{proof}
\end{mathSection}

Before ending this section, a note on category theory for those already familiar with it. A morphism of an experimental domain is an experimental relationship: $\erel : \edomain_1 \to \edomain_2$ such that $f(\obs) \equiv \obs$. It is a map that preserves the semantic content of each observation and therefore what is verified by an experimental test.

As we noted before, though, for experimental domains we do not get to choose what morphisms we have on the different domains. There is no notion of possible morphisms. If we have two one dimensional euclidean spaces, we can choose what continuous function (if any) we have between them. If we take the two experimental domain for temperature and height of the same mercury column, we have no choice. Indeed, whether there is a morphism between them is something that we have to find out, not arbitrarily decide.

The same applies to the combination of domains: if we have two one dimensional euclidean space we can decide whether to take their product (i.e. the plane) or their coproduct (i.e. the disjoint union of the two lines). While the combination of two independent domain is the categorical product and the combination of two incompatible domains is the categorical coproduct, we don't get to chose which one to apply. There is no way to combine the two experimental domain for temperature and height of the same mercury column and get the cartesian product of their possibilities. It is the semantic (and ultimately physical) relationship between them  will decide which product we have.

The point is that much of the machinery of category theory is inapplicable to experimental domains directly because products and morphisms do not always exist. Yet, we will be able to recover and use parts of it later based on the definitions provided in these last two sections. The idea is that mathematical structures such as topologies, groups, smooth manifolds, lie group and the like simply ``forget" the semantic, so the morphism in their category equates objects that are not coming from equivalent domains. Therefore, while the domains for thetemperature of two different thermometers are not equivalent, their natural topologies are equivalent because we are assuming that they are both scalar quantity that can be measured with arbitrary precision.

\section{Discrete and continuous quantities}

\begin{mathSection}
	
	\begin{defn}
		A \textbf{label} for an experimental domain $\edomain_X$ is a symbol we can use to distinguish between its possibilities. Formally, it is a tuble $(\mathcal{L}, l)$ where $\mathcal{L}$ is a topological space and $l : X \to \mathcal{L}$ is continuous function  between possibilities and elements of $\mathcal{L}$.
	\end{defn}
	
	\begin{defn}
		A \textbf{total order} on a set $\mathcal{Q}$ is a relationship $\leq : \mathcal{Q} \times \mathcal{Q} \to \mathbb{B}$ such that:
		\begin{enumerate}
			\item (antisymmetry) if $q_1 \leq q_2$ and $q_1 \leq q_2$ then $q_1 = q_2$
			\item (transitivity) if $q_1 \leq q_2$ and $q_2 \leq q_3$ then $q_1 \leq q_3$
			\item (antisymmetry) if $q_1 \leq q_2$ and $q_1 \leq q_2$ then $q_1 = q_2$
		\end{enumerate}
		
		 for an experimental domain $\edomain_X$ is a symbol we can use to distinguish between its possibilities. Formally, it is a tuble $(\mathcal{L}, l)$ where $\mathcal{L}$ is a topological space and $l : X \to \mathcal{L}$ is continuous function  between possibilities and elements of $\mathcal{L}$.
	\end{defn}
	
	\begin{defn}
		A \textbf{label} for an experimental domain $\edomain_X$ is a symbol we can use to distinguish between its possibilities. Formally, it is a tuble $(\mathcal{L}, l)$ where $\mathcal{L}$ is a topological space and $l : X \to \mathcal{L}$ is continuous function  between possibilities and elements of $\mathcal{L}$.
	\end{defn}

\end{mathSection}

\subsection{Decidable domains and discrete quantities}

The first case is when all our tests always finish with a clear success or failure and, therefore, we can both verify and refute every statement of the domain. For example, if we are able to tell whether an animal is of a particular species (e.g. \statement{that animal is a cat}), we are typically able to tell its not of that particular species (e.g. \statement{that animal is not a cat}).

\begin{mathSection}
	
	\begin{defn}
		An experimental domain $\edomain$ is \textbf{decidable} if all tests are guaranteed to terminate. Formally, for every $\obsdef{\stmt_1}{\expt_1} \in \edomain$ there exists a $\obsdef{\stmt_2}{\expt_2} \in \edomain$ such that $\stmt_1 = \NOT \stmt_2$
	\end{defn}
	
	\begin{justification}
		The idea is that if all tests always terminate, then we can always construct a test for the negation by replacing $\SUCCESS$ with $\FAILURE$ and vice-versa.
	\end{justification}
	
\end{mathSection}

In this case we can prove the following.

\begin{mathSection}
	
	\begin{prop}
		The set of possibilities $X$ for a decidable domain $\edomain$ is a countable essential set. More precisely, there exists a countable essential set $E \subseteq \edomain$ such that the set statements associated with $E$ is $X$.
	\end{prop}
	
	\begin{proof}
		The decidable domain $\edomain$ is already closed under negation, therefore for each theoretical statement $\stmt \in \tdomain$ there exists a corresponding experimental observation $\obsdef{\stmt}{\expt} \in \edomain$. We can then find a set of observations $E\subseteq \edomain$ such that their corresponding statements are the possibilities $X$.
		
		TODO
	\end{proof}
	
\end{mathSection}

This tells us that, in the case we can both verify and refute statements, we can only distinguish up to a countable set of cases. Recall that the cardinality of possibility is at most continuum, so in that case we cannot verify and refute all statements.

We can also show that a domain has a finite number of physically distinguishable possibilities is decidable.

\begin{mathSection}
	
	\begin{prop}
		An experimentally distinguishable domain with a finite set of possibilities is decidable.
	\end{prop}
	
	\begin{proof}
		TODO
	\end{proof}
	
\end{mathSection}

In terms of topology, a decidable domain corresponds to a discrete topology and the possibilities can always be labeled by assigning a different integer ot each.

\begin{mathSection}
	
	\begin{defn}
		A topology $\mathsf{T}_X$ on a set $X$ is said \textbf{discrete} if it contains every subset of $X$.
	\end{defn}
	
	\begin{defn}
		An experimental domain corresponds to a \textbf{discrete quantity} if its possibilities can be labeled by an integer. Formally, the set of possibilities $X$, with its natural topology $\mathsf{T}_X$, is homeomorphic to a subset of the integers $\mathbb{Z}$ with the discrete topology.
	\end{defn}
	
	\begin{prop}
		An experimental domain is decidable if and only if it corresponds to a discrete quantity.
	\end{prop}
	
	\begin{proof}
		TODO
	\end{proof}	
\end{mathSection}

\subsection{Arbitrary precision and continuous quantities}

\begin{mathSection}
	
	\begin{defn}
		An experimental domain $\edomain$ allows \textbf{arbitrary precision} if TODO.
	\end{defn}
	
	\begin{defn}
		The standard topology on the real numbers $\mathbb{R}$ is the one generated by the collections of sets $\mathcal{B} = \{ (a,b) \subset \mathbb{R} \; | \; a,b \in \mathbb{Q} \}$ of all open sets of rational numbers $\mathbb{Q}$.
	\end{defn}
	
	\begin{defn}
		An experimental domain corresponds to a \textbf{continuous quantity} if its possibilities can be labeled by a real number. Formally, the set of possibilities $X$, with its natural topology $\mathsf{T}_X$, is locally homeomorphic to a subset of the real $\mathbb{R}$ with its standard topology.
	\end{defn}
	
	\begin{prop}
		An experimental domain is decidable if and only if it corresponds to a discrete quantity.
	\end{prop}
	
	\begin{proof}
		TODO
	\end{proof}	
\end{mathSection}


Define arbitrary precision as all statements are intervals of rationals.

Space is real number with standard topology.

\section{REDO - Continuous functions}

\begin{prop}
	\label{setfunctions}
	Let $X$ and $Y$ be two Hausdorff topological spaces, and let $g: \mathsf{T}(Y) \rightarrow \mathsf{T}(X)$ be a mapping such that:
	\begin{enumerate}
		\item It is compatible with union and intersection $\forall V_1, V_2 \in Y$ $g(V_1 \cup V_2)=g(V_1)\cup g(V_2)$ and $g(V_1 \cap V_2)=g(V_1)\cap g(V_2)$
		\item $g(\emptyset) = \emptyset$
		\item $g(Y) = X$
	\end{enumerate}
	Then there exists a unique continuous function $f: X \rightarrow Y$ such that $g = f^{-1} |_{\mathsf{T}(Y)}$.
\end{prop}

\begin{proof}
	We claim there exists a unique extension $\bar{g}:\sigma(Y)\to\sigma(X)$ to the Borel $\sigma$-algebras of $X$ and $Y$, respectively $\sigma(X)$ and $\sigma(Y)$, such that $\bar{g}|_{\mathsf{T}(Y)}=g$ and $\bar{g}$ is compatible with union, intersection and complements. Let $\bar{g}(V) = g(V)$ for all open sets $V \in \mathsf{T}(Y)$. Let $A \in \sigma(Y)$ (not necessarily open) and $A^C$ be its complement. We must have $\bar{g}(A^C) = \bar{g}(A)^C = X\setminus \bar{g}(A)$ for $\bar{g}$ to be compatible with complements. Recall that all Borel sets in $\sigma(Y)$ and $\sigma(X)$ may be written as some combination of unions, intersections, and complements of open sets. Thus, the construction uniquely determine what $\bar{g}$ should output on any Borel set. We need only check that the output is still a Borel set. But by definition of $\bar{g}$, the outputs will be given as unions, intersections, and complements of outputs of $g$, which are open sets, and so the image of $\bar{g}$ is contained in $\sigma(X)$.  $\bar{g}$ is well defined. The function $\bar{g}$ in a sense represents extracting the maximum amount of information possible out of $g$.
	
	We claim we can define $\hat{g}:Y\to\sigma(X)$ such that $\hat{g}(y) = \bar{g}(\{y\})$. Since $Y$ is Hausdorff, every singleton $\{y\}$ is closed and is therefore a Borel set. $\bar{g}(\{y\})$ is well defined and so is $\hat{g}(y)$.
	
	We claim  $\hat{g}(y_1)\cap\hat{g}(y_2) = \emptyset$ if and only if $y_1\neq y_2$ for all $y_1,y_2\in Y$ such that $\hat{g}(y_i)\neq\emptyset$ for $i=1,2$. If $y_1\neq y_2$ we have
	$$
	\hat{g}(y_1)\cap\hat{g}(y_2) = \bar{g}(\{y_1\})\cap\bar{g}(\{y_2\}) = \bar{g}(\{y_1\}\cap\{y_2\}) = \bar{g}(\emptyset) = \emptyset.
	$$
	Conversely, if $y_1 = y_2$ we have
	$$
	\hat{g}(y_1)\cap\hat{g}(y_2) = 	\hat{g}(y_1)\cap\hat{g}(y_1) = 
	\hat{g}(y_1) \neq \emptyset.
	$$
	
	We claim we can define $f: X\to Y$ such that $f(x) = y$ if and only if $x\in \hat{g}(y)$. Since $g(Y)=X$, there exists $y\in Y$ such that $x\in\hat{g}(y)$. By the preceding claim, this $y$ is unique. $f: X\to Y$ is well defined. Note that no arbitrary choice where made so far that lead to the construction of $f$, which is therefore determined uniquely by $g$. 
	
	We claim $g = f^{-1} |_{\mathsf{T}(Y)}$. Let $V\in\mathsf{T}(Y)$. We want to show $f^{-1}(V) = g(V)$. Let $x\in f^{-1}(V)$. Then for some $y \in V$ we have $f(x)=y$. $x\in \hat{g}(y)$ by construction of $f$. $\hat{g}(y) \subset g(V)$ since $\{y\}\subset V$, so $x\in g(V)$. $f^{-1}(V) \subseteq g(V)$. Conversely, let $x\in g(V)=\bar{g}(V)$. Then for some $y\in V$, we have $x\in\bar{g}(\{y\})\subset\bar{g}(V)$. But then by definition we have $f(x)=y$, so $x\in f^{-1}(V)$. $f^{-1}(V) \supseteq g(V)$. $f^{-1}(V) = g(V)$ for all $V\in\mathsf{T}(Y)$ and therefore $f^{-1}|_{\mathsf{T}(Y)}=g$.
	
	We claim $f$ is continuous. It is so since $g = f^{-1} |_{\mathsf{T}(Y)}$ takes open sets to open sets. 
\end{proof}

The above work gives us an approach to reconstruct continuous functions given the behavior of the inverse on open sets. In the context of collecting information on observable phenomena, the function $g$ represents the total of all information possible to gather on the correlation between two variables. The fact that from $g$ we can construct a unique continuous $f$ shows us that in the infinite-resource ideal, we fully obtain the information to give exact relations between variables. Further, the result itself tells us that the interesting phenomena in our framework of experimental observations will be continuous, which is often a baseline assumption in physics. 





TODO: Introduce/define Borel algebra? In fact, we really only need infinite intersections of open sets. We could skip complements all together and just let $\bar{g}$ be defined on all open sets plus all infinite intersections of open sets. This might be slightly simpler but won't make much of a difference either way. Also, it might make more sense to absorb Lemma 1.24 and $\hat{g}$ into the proof of Proposition 1.22. 

\section{REDO - Distinguishability of functions}

For all of this to be self consistent, we must require that functions between experimentally distinguishable elements are  experimentally distinguishable themselves. That is, we must show that the set of continuous function $C(X,Y)$ from $X$ to $Y$ is a Hausdorff and second countable topological space with a suitable topology. Note that $C(X,Y)$ has the cardinality of continuum, therefore we already know it allows Hausdorff and second countable topologies, but we need to make sure we can give one that is actually physically meaningful in terms of experimental observations.

Suppose we have two sets $X$ and $Y$ of experimentally distinguishable elements (e.g. time and space). Suppose we need to distinguish elements within the set of all continuous function $C(X,Y)$ from $X$ to $Y$ (e.g. all possible trajectories). From a sub-base of $X$ (e.g. all open time intervals between rational numbers) we pick a set $U$ (e.g. between 1 and 2 seconds). From a sub-base of $Y$ (e.g. all open spatial intervals between rational numbers) we pick a set $V$ (e.g. between 1 and 2 meters). We can define the set $S(U,V) = \{f: X \rightarrow Y | f \in C(X,Y), f(U) \subset V\}$ of all the continuous functions such that their value remains within $V$ over the domain $U$ (e.g. all trajectories that between $1$ and $2$ seconds remain within $1$ and $2$ meters).

If we take all possible sets of functions constructed this way, and combine them with finite intersections and countable unions, we obtain a topology for the continuous function. The collections of all sets $S(U,V)$ forms a sub-base for this topology and is constructed from the sub-bases of $X$ and $Y$. This new sub-base is countable because the choices for $U$ and $V$ are countable themselves. This means that $C(X,Y)$ is second countable with this topology.

Now we need to show that we can distinguish between any two functions. Say we have two different functions $f_1$ and $f_2$ (i.e. two different trajectories). Since they are different, there will be at least one value $x \in X$ such that the values $f_1(x)\neq f_2(x)$ will be different (e.g. at $1.2$ seconds the first trajectory is at $1.1$ meters while the second trajectory is at $1.2$ meters). We can now find two disjoint elements $V_1$ and $V_2$ of the sub-base for $Y$ such that each includes either $f_1(x)$ or $f_2(x)$ (e.g. the intervals $(1.095, 1.105)$ and $(1.195, 1.205)$ meters). Since the functions are continuous, we can find an element $U$ of the sub-base for $X$ such that both functions remain within those ranges (e.g. between $(1.197, 1.203)$ seconds the first trajectory remains within $(1.095, 1.105)$ meters and the second trajectory remains within $(1.195, 1.205)$ meters). The sets $S(U, V_1)$ (e.g. all trajectories that between $(1.197, 1.203)$ seconds that remain within $(1.095, 1.105)$ meters) and $S(U, V_2)$ (e.g. all trajectories that between $(1.197, 1.203)$ seconds that remain within $(1.195, 1.205)$ meters) are disjoint and they each contain $f_1$ and $f_2$ respectively. We can distinguish between functions: the topology is Hausdorff.

This confirms that all the conceptual infrastructure is solid and self consistent. Sets of experimentally distinguishable elements are Hausdorff and second countable topological spaces. Maps between elements of such spaces are continuous maps as they preserve experimental distinguishability. The maps themselves are experimentally distinguishable and the can be given a Hausdorff and second countable topology. We can continues this recursively by constructing maps of maps (e.g. a map from a state to a trajectory) without ever going outside our definitions: everything remains experimental distinguishable.

\begin{mathSection}

For continuous functions to be physically distinguishable, we need to show they can always be given, as a set, given a topology that is Hausdorff and second-countable.

To that end, we introduce the basis-to-basis topology on the set of continuous functions from two topological spaces. This is the topology generated by the sets of functions that map a basis element of one element inside an element of the other space. 

\begin{defn} Let $X$ and $Y$ be two topological spaces. Let $C(X,Y)$ denote the set of all continuous functions from $X$ to $Y$. Let $\mathcal{B}_X$ and $\mathcal{B}_Y$ be two bases for $X$ and $Y$ respectively. The basis-to-basis topology $\mathsf{T}(C(X,Y), \mathcal{B}_X, \mathcal{B}_Y)$ on $C(X,Y)$ with respect to the basis $\mathcal{B}_X$ and $\mathcal{B}_Y$ is the topology generated by all sets of the form 
	$$
	V(U_X, U_Y) = \{f\in C(X,Y) : f(U_X)\subset U_Y\}
	$$
where $U_X \in \mathcal{B}_X$ and $U_Y \in \mathcal{B}_Y$.
\end{defn}

Now we need to show that if the two spaces $X$ and $Y$ are Hausdorff and second-countable, the basis-to-basis topology is Hausdorff and second-countable for a suitable choice of basis.

\begin{prop}
	Let $X$ and $Y$ be two Hausdorff and second-countable topological spaces. Let $C(X,Y)$ denote the set of all continuous functions from $X$ to $Y$. Let $\mathcal{B}_X$ and $\mathcal{B}_Y$ be two countable bases for $X$ and $Y$ respectively. The basis-to-basis topology $\mathsf{T}(C(X,Y), \mathcal{B}_X, \mathcal{B}_Y)$ on $C(X,Y)$ with respect to the basis $\mathcal{B}_X$ and $\mathcal{B}_Y$ is Hausdorff and second-countable. 
\end{prop}
\begin{proof}
	We claim $\mathsf{T}(C(X,Y), \mathcal{B}_X, \mathcal{B}_Y)$ is second-countable. We first note that the sub-basis $\{V(U_X, U_Y) \, |\,   U_X \in \mathcal{B}_X , U_Y \in \mathcal{B}_Y \}$ is countable since $\mathcal{B}_X$ and $\mathcal{B}_Y$ are countable. The collection $\mathcal{B}$ of all finite intersections is still countable, since it is in one-to-one correspondence with the collection of finite subsets of a countable set, which is still countable. Therefore $\mathcal{B}$ is a countable basis, which means $\mathsf{T}(C(X,Y), \mathcal{B}_X, \mathcal{B}_Y)$ is second-countable.
	
	We claim $\mathsf{T}(C(X,Y), \mathcal{B}_X, \mathcal{B}_Y)$ is Hausdorff. Let $f,g:X\to Y$ be distinct continuous functions. Then for some $x\in X$, we have $f(x)\neq g(x)$. Pick $V_1, V_2$ disjoint open subsets of $Y$ with $f(x)\in V_1$ and $g(x)\in V_2$. We may assume (possibly by shrinking $V_1$ or $V_2$) that both are basis elements for the topology of $Y$. Let $U=f^{-1}(V_1)\cap g^{-1}(V_2)$. Then $U$ is an open neighborhood of $x$. We may assume again that $U$ is a basis element for the topology on $X$ by shrinking it if necessary. Now, let $T_1$ to be the (sub-)basis element for basis-to-basis topology corresponding to $U$ and $V_1$. By construction, $f\in T_1$. Similarly, let $T_2$ to be the basis element for the basis-to-basis topology corresponding to $U$ and $V_2$ and containing $g$. Since $V_1$ and $V_2$ are disjoint, so are $T_1$ and $T_2$. $\mathsf{T}(\mathcal{C})$ is Hausdorff.
\end{proof}

We will also show that this is not in general equal to the open-open topology. 

\begin{prop}
	In general, the topology $\mathsf{T}(\mathcal{C})$ defined above depends on the bases for $X$ and $Y$. 
\end{prop}
\begin{proof}
	We will give an example of such a case. Let $X=Y=\mathbb{R}$ with the usual topology on $\mathbb{R}$. Let $\mathcal{B}_1$ be the basis for $\mathbb{R}$ consisting of all open intervals with rational endpoints, and let $\mathcal{B}_2 = \mathcal{B}_1\cup\{(0,\pi)\}$. We find a set open in our topology $\mathsf{T}(\mathcal{C})$ using $\mathcal{B}_2$ as our basis which is not open when we use $\mathcal{B}_1$. Consider the following set, open in our topology when using $\mathcal{B}_2$:
	$$
	V = \{f\in\mathcal{C}| f((0,\pi))\subset(0,1)\}
	$$
	This is clearly open because $(0,\pi)$ and $(0,1)$ are basis elements in $\mathcal{B}_2$. 
	
	Next, we show that when using $\mathcal{B}_1$ as our basis for $X=Y=\mathbb{R}$, no finite intersection and/or infinite union of sub-basis elements for $\mathsf{T}(\mathcal{C})$ will equal $V$. Henceforth, when we say ``open" subsets, unless otherwise stated, we will refer exclusively to the topology $\mathsf{T}(\mathcal{C})$ when using $\mathcal{B}_1$ for $\mathbb{R}$. The smallest sub-basis subsets containing $V$ are those of the form:
	$$
	B_r = \{f\in\mathcal{C} | f((0,r))\subset(0,1)\}
	$$
	for each $r\in\mathbb{Q}$ with $r<\pi$. By ``smallest" we mean any sub-basis elements containing $V$ which are not in the form of $B_r$ will contain some $B_r$. Now, any finite intersection of the $B_r$'s will be another $B_r$, but these strictly contain $V$, so we can never obtain $V$ from this sub-basis. 
	
	Similarly, the largest sub-basis sets contained within $V$ are of the form: 
	$$
	S_r = \{f\in\mathcal{C} | f((0,r))\subset(0,1)\}
	$$
	for each $r\in \mathbb{Q}$ with $r>\pi$. Let $S = \cup_{r>\pi}S_r$. This is the largest open set in our topology which is contained in $V$. Consider the function $f(x) = x/\pi$. This is continuous and is an element of $V$. But notice $f(\pi)=1$, so $f\notin S_r$ for all $r>\pi$, hence $f\notin S$. Thus, $V$ is a set which is open in $\mathsf{T}(\mathcal{C})$ when we use $\mathcal{B}_1$ for $X$ and $Y$, but not open when we use $\mathcal{B}_2$ for $X$ and $Y$. 
\end{proof}

TODO: add corollary environment for this one. 

\begin{prop}
The topology $\mathsf{T}(\mathcal{C})$ on the set of continuous functions $C(\mathbb{R},\mathbb{R})$ from $\mathbb{R}$ to itself is in general not equal to the open-open topology on $C(\mathbb{R},\mathbb{R})$.
\end{prop}
\begin{proof}
In the proof of the previous proposition, note that the basis for the open-open topology is independent of the basis used for the underlying spaces, and in particular is a superset of the basis for $\mathsf{T}(\mathcal{C})$ when using $\mathbb{B}_2$ to construct it. Hence the open-open topology is distinct from $\mathsf{T}(\mathcal{C})$ when using the basis $\mathcal{B}_1$ on $\mathbb{R}$. 
\end{proof}

TODO: the above propositions might generalize to any uncountable, second-countable space. This will be considered during the paper-writing process later. 

Thus we have shown one can start with two Hausdorff, second-countable spaces, and generate a new Hausdorff second-countable space consisting of all functions between them. Topological spaces with these properties make up our class of scientifically interesting spaces, so the space of continuous (distinguishability-preserving) functions between spaces of distinguishable quantities is again a physically distinguishable space. Because one can iterate this construction (since the relevant properties are preserved), this is a way to generate arbitrarily many new physically distinguishable spaces encoding important information about the ``lower-order" spaces (i.e. they consist of functions which encode a conversion between verifiable sets in different spaces).

\end{mathSection}

\section{Summary}

\begin{table}[h]
	\centering
\begin{tabular}{p{0.20\textwidth} p{0.7\textwidth}}
	Math/Topology & Science/Physics \\ 
	\hline 
	Hausdorff, second-countable topological space & Experimentally distinguishable space, whose points are the possible values and whose open sets represent the experimentally attainable levels of precision \\
	Open set & Verifiable set. We can verify experimentally that an element is within the set  \\ 
	Closed set & Refutable set. We can verify experimentally that an element is not in the set \\ 
	Basis of a topology & A collection of verifiable sets such that any verifiable set is determined by the basis sets\\
	Continuous \newline function &  A function between two sets of experimental distinguishable elements that preserves distinguishability \\
	Homeomorphism &  A perfect equivalence between experimentally distinguishable spaces. \\
\end{tabular} 
\caption{Topology to physics dictionary}
\end{table}

\chapter{Second chapter}

The first chapter was about testing truths about a single domain. The second chapter should about testing truths of multiple domain.

It should address
\begin{itemize}
	\item Define some domain for general statements of other domains. For example \statement{the position of this electron is between 1 and 2 meters} and \statement{an electron can have position between 1 and 2 meters}.
	\item Define the domain for relationships between two domains so we can show that experimental relationships can be themselves tested experimentally.
	\item Define processes that produce a sequence of experimental domains. For example, I produce electrons within a certain range of momentum.
	\item Define (statistical?) equivalence for processes. Define ``regular" or ``at equilibrium" processes as onces that are self-similar. Define probability
	\item Define differentiable structure on a manifold. Define distributions, measures, etc...
\end{itemize}

(Moved from previous chpater) Now that we have characterized the nature of experimental relationships, we need to show that these relationship can be tested experimentally. That is, we must be able to create an experimental domain such that the possibilities are the continuous functions between two domains. We have to do this two show that our framework is complete.

\begin{mathSection}
	\begin{axiom}
		Given two experimental tests $\expt_1$ and $\expt_2$ we can always construct another experimental test that is always successful if and only if the success of the first test $\expt_1$ implies the success of the second test is $\expt_2$. More formally, let $\expt_1, \expt_2 \in \exptSet$, there exists $\expt_3 \in \exptSet$ such that $\result(\expt_3, i) = \SUCCESS$ for all $i \in \mathbb{N}$ if and only if for all $j \in \mathbb{N}$ where $\result(\expt_1, j) = \SUCCESS$ we have $\result(\expt_2, j) = \SUCCESS$.
	\end{axiom}
	\begin{defn}
		Let $\edomain_X$ and $\edomain_Y$ be two experimental domains such that the second is dependent on the first. Let $E_X \subseteq \edomain_X$,  $E_Y \subseteq \edomain_Y$ be the two countable essential sets of the respective domains. The relationiship domain $\edomain_{C(X,Y)}$ is the experimental domain generated by the experimental statements
		$$\obs[v](\obs[e]_x, \obs[e]_y) = \statement{if $\obs[e]_x$ is true then $\obs[e]_y$ must also be true}=``\obs[e]_x \narrower \obs[e]_y"$$
		where $\obs[e]_x \in E_X$ and $ \obs[e]_y \in E_Y$.
	\end{defn}
	\begin{proof}
		We have to show that the statements $\obs[v](\obs[e]_x, \obs[e]_y)$ are indeed verifiable statements.
	\end{proof}
\end{mathSection}

\chapter{Other}


	
\end{document}