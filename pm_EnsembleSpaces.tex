
\def\>{\rangle}
\def\<{\langle}

%\DeclareMathOperator{\mix}{mix}
%\DeclareMathOperator{\component}{comp}
%\DeclareMathOperator{\cospan}{cospan}
\newcommand\mix{\mathrm{mix}}
\newcommand\component{\mathrm{comp}}
\newcommand\cospan{\mathrm{cospan}}

\newcommand{\ens}[1][e] {\mathsf{#1}} % Ensemble
\newcommand{\Ens}[1][E] {\mathcal{#1}} % Ensemble space



Here we summarize the work in progress for a general theory of states and processes that is applicable to any physical system. The general idea is to start characterizing the notion of ensemble, first with properties that are definitional requirements, and then further restring that would correspond to the classical, quantum or thermodynamic case.

We identified two arguments that can be used for the central role of ensembles in physical theories. First, in practice ensembles is all that we can prepare and measure in practice. Second, the idea of repeatability of experimental results implicitly assumes that the objects of scientific inquiry are not single instances, but the infinite collections of all reproducible instances.

\section{Working examples}

The general theory will need to be able to recover classical spaces and quantum spaces under appropriate physically meaningful assumptions. Specifically, these are the mathematical structure we will need to recover.


\subsubsection{Classical case - discrete}

The space of classical distributions over a discrete space corresponds to a symplex (\url{https://en.wikipedia.org/wiki/Simplex}). In the finite case, the pure states $\mathcal{G} = \{g_i\}_{i=1}^{n} \subset \Ens$ are finitely many and each ensemble $e = \sum p_i g_i$ is uniquely identified by a decomposition of pure states. Effectively, each ensemble is a probability distribution over the pure states. Mathematically, each point of the space is a convex combination of the vertices. The symplex has a center point, which corresponds to the maximally mixed state, a uniform distribution over all pure states.

The countably infinite case is a bit different because not all infinite sequences $\{p_i\} \in [0,1]$ converge. As we cannot create a uniform distribution over infinitely many cases, there is no center point. Effectively, there is ``hole'' in the middle. More precisely, the space is not topologically closed in the sense it does not contain all the limit points.

The uncountably infinite case is not physically relevant (i.e. no second countable discrete topology, cases are not experimentally decidable).

TODO: Understand the space of the limits. There should be at least one point for each sequence $\{p_i\}$ that converges to a finite $p < 1$. Intuitively, we can keep that part of the distribution constant while we spread the rest uniformly to all cases. Each should reach a different limit point.

\subsubsection{Classical case - continuous}

In the continuous case, the space of ensembles is the space of integrable functions over a symplectic manifold (e.g.  over phase space) that integrate to one. That is, if $X$ is a symplectic manifold, then $\Ens = L^1(X, \mu)$ where $\mu=\int \omega^n$ is the Liouville measure. The pure states are the space of delta distributions $\mathcal{G} = \{\delta_x\}_{x \in X}$, but they are not in  $\Ens$: they are limit points. If we imagine a uniform distribution over a region of the symplectic manifold, we now have two limits that are not part of the ensemble space: the limit with infinite support, and the limit of zero support. In some sense, a distribution can be understood as a convex integral of the zero support limits: $\rho(x) = \int_X \rho(y) \delta_x(y) d\mu$. Even in this case, each ensemble can be understood as a probability distribution (density in this case) over all pure states. The symplectic nature of the manifold is require to assign a frame invariant density to states and a frame invariant notion of independence between DOFs.

TODO: We should look for a more formal argument that the existence of frame-independent probability density on extreme points is linked to a symplectic structure. The notion of independence of DOF should be connected to a notion of product of convex spaces.

TODO: The pure states are not part of the space and are not extreme points. This will make it more difficult to define what a pure state is.


\subsubsection{Quantum case - finite dimensional}

For a qubit, the Bloch ball is the space of ensembles $\Ens$. That is, let $\mathcal{H}$ be a two dimensional Hilbert space. The interior of the block sphere correspond to mixtures (i.e. the space of positive semi-definite Hermitian operators with trace one $M(\mathcal{H})$) while the surface corresponds to the pure states $\mathcal{G}$ (i.e. $\{ |\psi\> \<\psi| \}_{\psi \in \mathcal{H}}$). In this case, there is no single decomposition. The general finite dimensional case works similarly. Note that the space is exactly characterized by knowing which different mixtures provide the same ensemble.

The multiple decompositions make the ensemble space behave in a way that is a hybrid between the classical discrete and continuous. Pure states are properly a part of the state, as in the discrete case, and we can describe each mixture in terms of finitely many states. However, the pure state are a continuum, therefore we can also define probability densities over the space, convex integrals. For example, for a single qubit, the maximally mixed state (the center of the sphere) can be equally described as the equal mixture of two opposite states (e.g. spin up and spin down, or spin left and spin right). However, it can also be described as the equal mixture of the whole sphere.

TODO: Note that complex projective are symplectic. Again, there should be an argument that the ability to define convex integrals in a frame invariant way requires the space to be symplectic. This would radically constrain the possible convex spaces and pick out, for example, the complex spaces from the real and the quaternionic ones.

\subsubsection{Quantum case - infinite dimensional}

The infinite dimensional can be both understood as the countably infinite dimensional version of the discrete case, or as the space of complex square integrable functions. As in the  (i.e. $L^2$) should work the same, except that there is no upper bound on the entropy, and therefore there is no maximally mixed state.

As before, the maximally mixed state is not in the convex space.

TODO: Understand the difference between Hilbert space and Schwartz space in terms of both extreme points and convex combinations/integrals. Are $S(\mathbb{R})$ and $S(\mathbb{R}^2)$ isomorphic as convex spaces?


\section{Ensemble spaces, convex spaces and convex sets}

Basic definitions for convex spaces are taken from \url{https://ncatlab.org/nlab/show/convex+space} and \url{https://arxiv.org/abs/0903.5522}. Note that we are not interested in convex spaces per se, but their use in modeling ensembles. Therefore, as is customary in the physical mathematics approach of Assumptions of Physics, we are going to be using a terminology that is specific to the problem at hand. However, nothing is settled about the terminology.

\begin{defn}
	For a real number $p \in [0,1]$, $\bar{p} = 1-p$.
\end{defn}

\begin{defn}
	An \textbf{ensemble} represents infinite copies, taken at once, of the output of a process. An \textbf{ensemble space} is a collection of ensembles that describe the same system under all processes. Formally, an ensemble space $\Ens$ is a set of elements, called ensembles, equipped with an operation $+ : [0, 1] \times \Ens \times \Ens \to \Ens$ called \textbf{mixing}, typically noted with the infix notation $p \ens_1 + \bar{p} \ens_2$, with the following properties:
	\begin{itemize}
		\item \textbf{Identity}: $1 \ens_1 + 0 \ens_2 = \ens_1$
		\item \textbf{Idempotence}:  $p \ens_1 + \bar{p} \ens_1 = \ens_1$ for all $p \in [0,1]$
		\item \textbf{Commutativity}: $p \ens_1 + \bar{p} \ens_2 = \bar{p} \ens_2 + p \ens_1$ for all $p \in [0,1]$
		\item \textbf{Associativity}: $p_1 \ens_1 + \bar{p_1}\left(\overline{\left(\frac{p_3}{\bar{p_1}}\right)}\ens_2 + \frac{p_3}{\bar{p_1}}\ens_3\right) =  \bar{p_3}\left(\frac{p_1}{\bar{p_3}} \ens_1 +  \overline{\left(\frac{p_1}{\bar{p_3}}\right)}\ens_2\right) + p_3 \ens_3$ for all $p_1, p_3 \in [0,1]$
	\end{itemize}
	Given symmetry and associativity, we can write $p_1 \ens_1 + p_2 \ens_2 + p_3 \ens_3$ where $p_2 = \bar{p_1}\overline{\left(\frac{p_3}{\bar{p_1}}\right)} = \bar{p_3}\overline{\left(\frac{p_1}{\bar{p_3}}\right)} = 1 - p_1 - p_3$. We can also extend to \textbf{convex combinations} $\sum p_i \ens_i$ where $\sum_i p_i = 1$.
\end{defn}
\begin{justification}
	Let $\ens_1$ and $\ens_2$ be the ensembles that represent the output of two different processes $P_1$ and $P_2$. Let a selector $S_p$ be a process that outputs two symbols, the first with probability $p$ and the second with probability $\bar{p}$. Then we can create another process $P$ that, depending on the selector, outputs either the output of $P_1$ and $P_2$. Therefore we are justifying in assuming the mixing operation among ensembles.
	
	If $p=1$, the output of $P$ will always be the output of $P_1$. This justifies the identity. If $P_1$ and $P_2$ are the same process, then, again, the output of $P$ will always be the output of $P_1$. This justifies the idempotence. As long as the same probability is matched to the same output, the process $P$ is identical. This justifies the symmetry. If we are mixing three processes $P_1$, $P_2$ and $P_3$, as long as the final probabilities are the same, it does not matter if we mix $P_1$ and $P_2$ first or $P_2$ and $P_1$. This justifies associativity.
\end{justification}

\begin{remark}
	All classical and quantum cases fit this definition.
\end{remark}

\begin{coro}
	An ensemble space is a convex space.
\end{coro}

\begin{defn}
	Let $\Ens$ be an ensemble space. Let $\ens[\rho] = \sum_i p_i \ens_i$ where $\ens[\rho], \{\ens_i\} \in \Ens$ and $p_i \in [0,1]$ such that $\sum p_i = 1$. We say that $\ens[\rho]$ is a \textbf{mixture} of $\{\ens_i\}$ and each $\ens_i$ is a \textbf{component} of $\ens[\rho]$. Let $\ens[\rho] = p \ens_1 + \bar{p} \ens_2$. Then we say that $\ens_2$ is a $p$-\textbf{complement} of $\ens_1$ towards $\ens[\rho]$.
\end{defn}

\begin{remark}
	While most of the literature on convex spaces focus on ``combinations'', the inverse ``decomposition'' is crucial. For example, whether a convex space is a vector space depends on properties of decomposition.
\end{remark}

\begin{defn}
	An ensemble space is \textbf{complemented} if all $p$-complements are unique.
\end{defn}

\begin{prop}
	An ensemble space embeds into a real vector space with convex combination as linear combination if and only if it is complemented.
\end{prop}
\begin{proof}
	Theorem 4 in \url{https://arxiv.org/abs/1105.1270} states that a convex space embeds into a real vector space with $c_\lambda(x,y) = \lambda x + \bar{\lambda}y$ if and only if
	$$ c_\lambda(x,y) = c_\lambda(x,z) \; \forall \lambda \in (0,1) \implies y = z.$$ This is exactly the conditions that the $\lambda$-complement is unique.	
\end{proof}

\begin{remark}
	Note that all classical and quantum cases are complemented and therefore embedded into real vector spaces. It is not yet clear whether an ensemble space must be complemented or not. It is difficult to justify as it is a claim on existence of more refined ensembles. It may very well be that this is just an assumption on the decomposition, which may fail is new physical conditions.
\end{remark}

\begin{defn}
	An ensemble is \textbf{decomposable} if it is the mixture of two or more components. An ensemble space is \textbf{infinitesimally decomposable} if all ensembles are decomposable. It is \textbf{finitely decomposable} if all ensembles can be decomposed into components that are not decomposable.
\end{defn}

\begin{remark}
	The non-decomposable ensembles are exactly the extreme points of the convex space.
\end{remark}



\subsection{Physical examples}

These are the examples that we need to keep in mind, which will need to be fully characterized in terms of convex spaces and their properties.


\section{Convex subspaces}

Since the goal is to use convex spaces to create a unified theory for all types of mechanics, we need a construction that map to the subspaces of the different state spaces

\begin{defn}
	Let $\Ens$ be an ensemble space and $X \subseteq \Ens$ be a subset. We say that $X$ is a \textbf{subspace} of $\Ens$ if it contains all the mixtures and all the components. That is, for every $\ens_1, \ens_2, \ens_3$ and $p \in (0,1)$ such that $p\ens_1 + \bar{p} \ens_2 = \ens_3$ we have:
	\begin{itemize}
	\item $\ens_1, \ens_2 \in X$ implies $\ens_3 \in X$
	\item $\ens_3 \in X$ implies $\ens_1, \ens_2 \in X$
\end{itemize}
\end{defn}

\begin{defn}
	Let $\Ens$ be an ensemble space and $X \subseteq \Ens$.  The \textbf{convex span} of $X$, noted $\cospan(X)$, is the smallest subspace containing $X$.
\end{defn}

\begin{remark}
	As defined, the convex span of two elements will include all their possible mixtures (i.e. the segment that connects them), all possible decompositions (i.e. all lines that pass through then) plus, recursively, all other mixtures and decompositions that can be reached. Physically, this makes more sense as pure states are never really realized physically, but are the idealization we use to decompose the problem and study the problem.
\end{remark}

\begin{example} Classical discrete subspaces.
	Let $\Ens$ be an $n$-simplex, the space of probability distributions over $n$ discrete cases $\ens_i$. A subspace is a convex hull of a subset of the extreme points. That is, any subspace of probability distribution over a subset of the cases. Geometrically, it is one of the sides (possibly recursively) of the simplex.
	
	To see this, first note that the convex hull of any subsets of extreme points is a subspace. In fact, it will contain all convex combinations of its elements, and any element can only be decomposed in convex combinations of the chosen extreme points. Second, note that only convex hulls of a subset of extreme points can be a subset. In fact, any element of $\Ens$ can be expressed as a non-trivial convex combination of extreme points. Therefore, if an element is present in a subspace, those extreme points that are present in its convex expression must also be in the subspace, which means the convex hull of those points is present as well.
\end{example}

\begin{example} Quantum subspaces.
	Let $\mathcal{H}$ be an $n$-dimensional Hilbert space and let $\Ens$ be the space of density matrices (i.e. positive semi-definite self-adjoint operators with trace one). A subspace of $\Ens$ is the space of density matrices of a subspace of $\mathcal{H}$. That is, any subspace is the space mixed states over a subset of the cases.
	
	To see this, first note that the space of density matrices $X$ of a subspace $U$ of $\mathcal{H}$ is a subspace of $\Ens$. In fact, $X$ it will contain all convex combinations of its elements. Moreover, any element $x \in X$ can only be decomposed in convex combination of pure states of $U$. Therefore any convex decomposition of $x$ has all its elements in $X$. Second, note that only the space of density matrices $X$ of a subspace $U$ of $\mathcal{H}$ is a subspace of $\Ens$. In fact, any element $x$ of $\Ens$ can be expressed as a non-trivial convex combination of orthogonal pure states, its eigenstates. These elements will span a subspace $U$ of $\mathcal{H}$. From those elements, we can construct an equal mixture which represents the maximally mixed states and, mathematically, is the identity operator $I/n$ divided by the number of elements. The equal mixture of any orthogonal basis of $U$ will also give the maximally mixed state. Therefore, given an element $x$, any subspace that contain $x$ will also a basis of $U$, the maximally mixed state $I/n$, all possible basis of $U$, which means all the pure states, and finally all convex combinations of the pure states, which means all possible density matrices, all possible mixed states.
	
	TODO: It is not clear whether how this generalizes to the infinite case given that the convex combinations are only defined on finitely many elements.
\end{example}

\begin{remark}
	TODO: Does this work for the classical continuous case? Let $S$ be a symplectic manifold. Let $\Ens$ be the space of probability distributions over $S$. That is, the space of continuous functions over $S$ that are integrable and integrate to one. We would like to show that a subspace of $\Ens$ is a set of functions whose support is constrained over an open region $U \subseteq S$. That is, a subspace contains all probability distributions defined over a subset of the cases. One problem is that continuity forces the function to go to zero on the boundary of $U$, and the speed of the convergence cannot be change with a finite convex combination. That is, the convex combination of functions that go down like an exponential will also go down like an exponential.
\end{remark}

\begin{remark}
	TODO: An open question is whether there is a relationship between an ensemble space being complemented (i.e. the embedding of the convex space into a vector space) and features of the convex span.
\end{remark}

\begin{defn}
	Two subspaces $X_1, X_2 \subseteq \Ens$ are \textbf{orthogonal} if they are disjoint. That is, $X_1 \cap X_2 = \emptyset$. Two ensembles $\ens_1, \ens_2 \in \Ens$ are \textbf{disjoint} if they belong to two orthogonal subspaces. That is, $\cospan(\ens_1) \cap \cospan(\ens_2) = \emptyset$.
\end{defn}

\begin{remark}
	Two classical distributions are disjoint if and only if their support is disjoint. Two quantum states are disjoint if and only if they are the mixture of states that belong to disjoint subspaces.
	
	Physically, two disjoint ensembles are distinct in the sense that they will never produce overlapping results.
\end{remark}

\begin{remark}
	TODO: The definitions that follows work only for finitely decomposable spaces (i.e. all extreme points are in the space). Ideally, we want definitions that works for all cases in the same way.
\end{remark}

\begin{defn}
	A \textbf{pure state} is an ensemble that is not decomposable. Given a subspaces $X \in \Ens$ be a subspace, it's \textbf{dimension}, noted $\dim(X)$, is the minimum number of pure states $x_i \in X$ such that $\cospan(x_i) = X$.
\end{defn}

\begin{remark}
	In the classical discrete case, the subspaces are the simplexes. The dimensionality of the subspace is the number of vertices of the simplex (i.e. dimensionality of the simplex plus one). That is, a single pure state is a subspace of dimension one; a line segment is a subspace of dimension two; and so on.
	
	In quantum mechanics, subspaces correspond to the projective spaces of subspaces of the complex vector space.
\end{remark}


\section{Entropy}

In both classical and quantum mechanics, the Shannon/Gibbs/von Neumann entropy defines the geometric structure of the space. Convex combinations also define geometric features, precisely because the entropy can be calculated from the probabilities, at least in the classical discrete case and quantum. On the continuum, we also know that being able to define a frame invariant entropy is what leads to requiring the symplectic structure. Moreover, the space of distributions over position and velocity is isomorphic, as a convex space, to the space of distributions over position and momentum. Therefore, it does not seem that, in the classical continuous case, the convex space structure is enough. Exactly what geometric information is and is not in the convex structure and the entropy is something that needs to be understood.

\begin{defn}
	Given the coefficients $\{p_i\} \in [0,1]$ such that $\sum p_i = 1$, the \textbf{entropy of the coefficients} is defined as $I(\{p_i\}) = - \sum p_i \log p_i $.
\end{defn}

\begin{ext}
	An ensemble space is equipped with an \textbf{entropy} function $S : X \to \mathbb{R}$ with the following properties
	\begin{itemize}
		\item \textbf{Continuity}
		\item \textbf{Strict concavity}: $S(p_1\rho_1 + p_2 \rho_2) \geq p_1 S(\rho_1) + p_2 S(\rho_2)$ with the equality holding if and only if $\rho_1 = \rho_2$
		\item \textbf{Coefficient bound}: $S(p_1\rho_1 + p_2 \rho_2) \leq I(p_1, p_2) + p_1 S(\rho_1) + p_2 S(\rho_2)$
	\end{itemize}
\end{ext}

\begin{remark}
	Note that the bounds for entropy can also be written as
	$$ 0 \leq S(p_1\rho_1 + p_2 \rho_2) - (p_1 S(\rho_1) + p_2 S(\rho_2)) \leq I(p_1, p_2).$$
	The term in the middle compares the entropy of the mixture to the average entropy of the components. It essentially tells us that the entropy can only increase during the mixture, and it can only increase up to the entropy of the coefficients.
	
	Note that if an ensemble can be decomposed in multiple ways, the decomposition such that the entropy of the weights is minimal provides the least upper bound.
	
	TODO: The Shannon entropy can be recovered in the discrete case with 3 minimal requirements. Are the above constraints enough to recover a unique entropy function (up to a constant) that matches the right entropy in the discrete/continuum/quantum cases? If not, is this just a question on requirements on entropy or also requirements on the space?
	
	TODO: Does the existence of an entropy function put a limit on the convex space? For example, a line is convex space with no extreme points. We can parameterize the space with a variable $x$ such that the mixture of two ensembles is identified by the average $x$. Entropy can be written as $S(x)$. Since $S(x)$ is strictly concave over an infinite range, it will tend to minus infinity either when $x$ tends to infinity or minus infinity. The entropy A function cannot be strictly concave 
\end{remark}

\begin{remark}
	We can define
	$$JSD(\rho_1, \rho_2) = S\left(\frac{1}{2}\rho_1 + \frac{1}{2} \rho_2\right) - \left(\frac{1}{2} S(\rho_1) + \frac{1}{2} S(\rho_2)\right).$$
	Both in the classical and quantum case, this corresponds to the Jensen-Shannon divergence \url{https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence}. It is connected to the Fisher-Rao metric \url{https://en.wikipedia.org/wiki/Fisher_information_metric#Relation_to_the_Jensen%E2%80%93Shannon_divergence} and its square root is a distance function.
	
	The question is whether the bounds above are enough to make the square root of the $JSD$ a distance function in the general case.
\end{remark}

\begin{defn}
	Two mixtures $x, y \in X$ are \textbf{disjoint} if $S(p_1\rho_1 + p_2 \rho_2) - (p_1 S(\rho_1) + p_2 S(\rho_2)) = I(p_1, p_2)$.
\end{defn}

\begin{remark}
	Two classical distributions are disjoint if and only if their support is disjoint. Two quantum states are disjoint if and only if they are the mixture of states that belong to disjoint subspaces.
	
	Physically, two disjoint ensembles are distinct in the sense that they will never produce overlapping results.
\end{remark}

\begin{prop}
	The thermodynamic entropy is an entropy over an ensemble space.
\end{prop}
\begin{justification}
	TODO This can be easily done in terms of information theory and statistical mechanics. An argument based on thermodynamics would be better.
\end{justification}

\begin{remark}
	Note that $JSD(\rho_1, \rho_2 = )S(p_1\rho_1 + p_2 \rho_2) - (p_1 S(\rho_1) + p_2 S(\rho_2))$ is the Jensen Shannon divergence (\url{https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence}). The square root is a distance function, and therefore makes the convex space a metric space.
\end{remark}

\subsection{Physical examples}

We review the physical examples in terms of the entropy.

\subsubsection{Classical case - discrete}

The entropy is given by $-\sum p_i \log p_i$ for both finite and countable cases. Therefore the entropy for each pure state is assumed to be zero. The entropy of the maximally mixed state is $\log n$ where $n$ is the number of pure states. The entropy increase as we go from pure states to the maximally mixed state. The level sets (i.e. the fibers) of the entropy form a series of concentric "shells".

TODO: Check that the entropy is finite for all convex combinations. Check that it diverges as we go to a limit point that is not in the ensemble space.

TODO: Is it important that all pure states have zero entropy?

\subsubsection{Classical case - continuous}

The entropy is given by $- \int \rho \log \rho d\mu$ where $\mu$ is the Liouville measure and $\rho$ is the probability density over canonical coordinates. If a different measure is used, or if the coordinates are not canonical, the formula gives the wrong result.

The entropy can be used to check whether two ensembles are overlapping and define the size of the support. That is: take $\rho \in X$; construct the set $\text{dis}(\rho)$ of all the ensembles that are disjoint from $\rho$; now construct the set $\text{con}(\rho)$ of all ensembles that are disjoint from all elements of $\text{dis}(\rho)$. These will be the set of ensembles that share the supports. Find the supremum of $\text{dis}(\rho)$ in terms of the entropy. If it doesn't exists, the support is infinite. If it does, the support is finite and the measure is $2^{\sup S(\text{con}(\rho))}$.

TODO: Study the shell of zero entropy states. For example, it should not be path connected: all uniform distributions with support of the same finite size (in terms of Liouville measure) will have the same entropy. The region, however, need not be contiguous. Since we cannot continuously transform a single region into two disjoint regions, there will be different distributions at zero entropy that cannot be transformed continuously.

\subsubsection{Quantum case}

In quantum mechanics, the entropy is the von Neumann entropy for both finite and infinite dimension. The entropy for the maximally mixed state is $\log n$ where $n$ is the dimensionality of the Hilbert space.

TODO: How exactly do the bounds of entropy interact with multiple decomposition?

